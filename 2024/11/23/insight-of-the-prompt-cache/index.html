<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
       
      <meta name="keywords" content="17哥,17g,17G,17" />
       
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>Prompt Cache 究竟是什么？ |  17哥</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
      <script src="https://use.fontawesome.com/39301eb177.js"></script>
    <link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-insight-of-the-prompt-cache"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Prompt Cache 究竟是什么？
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2024/11/23/insight-of-the-prompt-cache/" class="article-date">
  <time datetime="2024-11-23T22:17:05.000Z" itemprop="datePublished">2024-11-23</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/LLM/">LLM</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">4.1k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">16 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p><img src="/2024/11/23/insight-of-the-prompt-cache/context_caching.png" alt></p>
<p>在介绍了 <a href="/2024/10/16/What-exactly-is-attention/">Transformer</a> 模型、<a href="/2024/10/31/From-Transformer-To-GPT/">GPT</a> 模型、<a href="/2024/11/16/The-LLMs-Runtime-Inference-and-KV-Cache/">大模型的运行时推理和 KV Cache</a> 后，我们终于越来越接近于最原始的目标：OpenAI 2024 年 10 月 1 日发布的 <a target="_blank" rel="noopener" href="https://openai.com/index/api-prompt-caching/">Prompt Caching in the API</a>。这篇文章，我们就来介绍一下 <code>Prompt Cache</code> 相关技术的发展并对 OpenAI 的 <code>Prompt Caching</code> 技术方案进行简单的分析。</p>
<span id="more"></span>
<h2 id="kv-cache">KV Cache</h2>
<p>根据 <a href="/2024/11/16/The-LLMs-Runtime-Inference-and-KV-Cache/">大模型的运行时推理和 KV Cache</a> 中的介绍，如果输入 prompt 的长度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span> 个 tokens——<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>s</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">s_1, s_2,...,s_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，大模型会根据这 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span> 个 tokens 生成了后续的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 个 tokens——<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>s</mi><mrow><mi>n</mi><mo>+</mo><mn>2</mn></mrow></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>s</mi><mrow><mi>n</mi><mo>+</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{n+1}, s_{n+2}, ...,s_{n+k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>。</p>
<p>如果没有 <code>KV 缓存</code>，则每生成一个新的 token <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>n</mi><mo>+</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{n+k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>，都需要重新计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>s</mi><mrow><mi>n</mi><mo>+</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_1,s_2,...,s_{n+k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> 之间的注意力。</p>
<p>但是，在 <code>KV 缓存</code> 机制下，<code>prefill 阶段</code> 会计算输入序列中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span> 个 tokens 之间的注意力 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>0</mn></msub><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><msub><mi>k</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>v</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mtext> </mtext><mi mathvariant="normal">∣</mi><mtext> </mtext><mi>i</mi><mo>≤</mo><mi>n</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">S_0=\{(k_i, v_i)\ |\ i \le n\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace"> </span><span class="mord">∣</span><span class="mspace"> </span><span class="mord mathdefault">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">n</span><span class="mclose">}</span></span></span></span>，并将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>k</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>v</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(k_i, v_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 缓存在 <code>KV 缓存</code> 中。对于后续生成的每一个 token <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>n</mi><mo>+</mo><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi>j</mi><mo>≤</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s_{n+j}(j\le k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span>，我们将使用 <code>KV 缓存</code> 中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>j</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><msub><mi>k</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>v</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mtext> </mtext><mi mathvariant="normal">∣</mi><mtext> </mtext><mi>i</mi><mo>&lt;</mo><mi>n</mi><mo>+</mo><mi>j</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">S_j=\{(k_i, v_i)\ | \ i \lt n + j \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace"> </span><span class="mord">∣</span><span class="mspace"> </span><span class="mord mathdefault">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class="mclose">}</span></span></span></span> 来计算新 token <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>n</mi><mo>+</mo><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi>j</mi><mo>≤</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s_{n+j}(j\le k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span> 的自注意力。</p>
<p>令模型的维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">W</mi><mi>Q</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{W}^Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">Q</span></span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">W</mi><mi>K</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{W}^K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">W</mi><mi>V</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{W}^V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span></span></span> 的维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{head}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，则利用 <code>KV 缓存</code> 可以将计算注意力的浮点数计算量从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn><mi>n</mi><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><msub><mi>d</mi><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub><mo>+</mo><mn>4</mn><msup><mi>n</mi><mn>2</mn></msup><msub><mi>d</mi><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">6nd_{model}d_{head} + 4n^2d_{head}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord">6</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.964108em;vertical-align:-0.15em;"></span><span class="mord">4</span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 降低到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><msub><mi>d</mi><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub><mo>+</mo><mn>4</mn><mi>n</mi><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">6d_{model}d_{head} + 4nd_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord">6</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord">4</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>，整体的计算量降低了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mo stretchy="false">)</mo><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">100(1 - \frac{1}{n})\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord">%</span></span></span></span>。</p>
<h2 id="prompt-cache">Prompt Cache</h2>
<p><code>KV 缓存</code> 可以显著降低一个请求中的注意力的重复计算。但是，实际应用中，不同的请求也经常会有很多重复的内容，例如：</p>
<ul>
<li>
<p>根据 Prompt 模版派生的 Prompt 在请求 LLM 时通常包含：系统提示、角色指定、指令描述、样例说明、自定义的动态内容……</p>
<p class="katex-block has-jax"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>System Prompt </mtext><mi mathvariant="normal">∣</mi><mtext> Role Setting </mtext><mi mathvariant="normal">∣</mi><mtext> Instruction Description </mtext><mi mathvariant="normal">∣</mi><mtext> Few Shot </mtext><mi mathvariant="normal">∣</mi><mtext> User Query......</mtext></mrow><annotation encoding="application/x-tex">\text{System Prompt} \ | \ \text{Role Setting} \ | \ \text{Instruction Description} \ | \ \text{Few Shot} \ | \ \text{User Query......}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">System Prompt</span></span><span class="mspace"> </span><span class="mord">∣</span><span class="mspace"> </span><span class="mord text"><span class="mord">Role Setting</span></span><span class="mspace"> </span><span class="mord">∣</span><span class="mspace"> </span><span class="mord text"><span class="mord">Instruction Description</span></span><span class="mspace"> </span><span class="mord">∣</span><span class="mspace"> </span><span class="mord text"><span class="mord">Few Shot</span></span><span class="mspace"> </span><span class="mord">∣</span><span class="mspace"> </span><span class="mord text"><span class="mord">User Query......</span></span></span></span></span></span></p>
<p>这其中，系统提示词、角色设定、指令描述、具体例子等都是通用的模版内容，同一类型的任务仅在最后的用户自定义部分不同。</p>
</li>
<li>
<p>Chat Robot 之间的多轮对话，随着对话轮次的不断增加，新的对话内容会作为对话历史不断的增加到 Prompt 中并重新发送给大 LLM，当对话历史较多的时候，就会导致和大模型的每次对话都会携带大量的重复内容。</p>
</li>
<li>
<p>使用批处理方式调用 LLM 解决特定的任务，比如以使用大模型进行图片分析，此时输入的 Prompt 的前面部分内容都是一致的，只是最后要分析的图片内容不一致。</p>
</li>
</ul>
<p>如前所述，<code>KV 缓存</code> 可以解决单个请求内的自回归过程中的注意力机制的重复计算问题，提升 LLM 的性能，但是无法解决如上场景中存在的跨请求间的注意力机制的重复计算问题。<code>Prompt Cache</code> 就是解决跨请求间的注意力机制重复计算的问题，从而提升后续请求的性能，尤其是提升 <code>prefill 阶段</code> 的性能（降低 TTFT）。</p>
<ul>
<li>2024 年 5 月 14 日，谷歌为 Gemini 模型宣布了一系列的新特性，其中就包括可以降低费用的 <code>Context Caching</code>。<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></li>
<li>2024 年 7 月 1 日，月之暗面宣布启动 <code>Context Cache</code> 的公测，对于请求频繁、重复引用大量初始上下文的场景，可以降低 83% 的 TTFT 同时费用最高降低 90%。<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></li>
<li>2024 年 8 月 2 日，DeepSeek 在 API 模型上支持了硬盘 <code>Prompt Cache</code>，把本来就白菜价的 API 价格又降低了一个数量级<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>，在命中缓存的情况下，每百万输入 tokens 仅 0.014$，几乎要等同于免费了。</li>
<li>2024 年 8 月 15 日，Claude 也宣布在 Claude 3.5 Sonnet、Claude 3 Opus、Claude 3 Haiku 模型上支持 <code>Prompt Cache</code>。对于较长的 prompts，使用 <code>Prompt Cache</code> 可以把费用最高降低 90%、请求延迟最高降低 85%。<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup></li>
<li>2024 年 10 月 1 日，OpenAI 也宣布在其最新的模型版本 GPT-4o、GPT-4o mini、o1-preview、o1-mini 上支持 <code>Prompt Cache</code>，使用 <code>Prompt Cache</code> 技术，可以为开发者提供更快的请求响应速度和低至 50% 的费用。<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup></li>
</ul>
<h2 id="prompt-cache-技术方案">Prompt Cache 技术方案</h2>
<p><code>Prompt Cache</code> 并不是一种传统的缓存技术，传统的缓存技术通常用于临时存储数据以便于再次请求相同的数据时可以加速数据的访问速度。传统的缓存技术通常用于处理静态内容输出，例如网页内容，js、css、image 等静态内容，数据库查询结果……</p>
<p>在传统的缓存技术中，我们使用 <code>key-value</code> 的结构来组织并访问缓存内容，例如我们可以把某个 <code>url</code> 作为 <code>key</code>、并将其对应的网页内容作为 <code>value</code> 缓存起来，以便有其他用户再次请求该 <code>url</code> 时可以直接从缓存中提取到该网页的内容，从而加速网页的访问速度。</p>
<p>在实际中，确实存在不同用户请求的内容大致相似，因此可以利用 <code>key-value</code> 的传统缓存技术来解决一部分场景的访问速度问题，例如：</p>
<ul>
<li>Query 1：天空为什么是蓝色的？</li>
<li>Query 2：为什么天空是蓝色的？</li>
<li>Query 3：天空为什么是蓝的？</li>
<li>……</li>
</ul>
<p>但是，对于 LLM 而言，在大部分场景下，LLM 根据固定的上下文内容和可变的用户输入内容动态生成输出。因此，在大部分场景下，传统的 <code>key-value</code> 缓存技术并不适用于大模型领域。</p>
<p>根据如上的这两种场景，<code>Prompt Cache</code> 技术也基本上划分为两种：</p>
<ul>
<li>输入整体一致时，利用 <code>key-value</code> 的传统缓存技术对相似请求的输出内容进行缓存，例如  GPTCache: Semantic Cache for LLMs<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>。</li>
<li>输入前缀一致时，利用 <code>KV 缓存</code> 技术避免注意力重复计算带来的计算开销，从而提升大模型响应速度，例如耶鲁大学和谷歌研发的 Prompt Cache: Modular Attention Reuse 技术<sup class="footnote-ref"><a href="#fn1" id="fnref1:1">[1:1]</a></sup>。</li>
</ul>
<h3 id="gptcache-semantic-cache-for-llms">GPTCache: Semantic Cache for LLMs</h3>
<p>GPTCache: Semantic Cache for LLMs <sup class="footnote-ref"><a href="#fn7" id="fnref7:1">[7:1]</a></sup> 是一种典型的传统缓存技术，GPTCache 的本质是把 <code>Query-Response</code> 缓存到 Redis 中，当有语义上相似的 <code>Query</code> 时，直接从 Redis 中返回缓存的结果而不需要 LLM 再重复计算并生成结果，从而降低大模型的推理成本并提升响应性能。但是这种方式只适用于语义上非常相似的请求，对于如下的请求则不适用：</p>
<ul>
<li>Query 1：天空为什么是蓝色的？</li>
<li>Query 2：天空为什么是蓝色的，请给出详细的物理学上的解释？</li>
</ul>
<p>GPTCache 的架构如下所示<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>：</p>
<p><img src="/2024/11/23/insight-of-the-prompt-cache/17325377216331.jpg" alt></p>
<h3 id="prompt-cache-modular-attention-reuse">Prompt Cache: Modular Attention Reuse</h3>
<p>耶鲁大学和谷歌联合发布的 Prompt Cache: Modular Attention Reuse <sup class="footnote-ref"><a href="#fn1" id="fnref1:2">[1:2]</a></sup> 在本质上时基于 <code>KV 缓存</code> 的 <code>Prompt Cache</code> 技术，将请求内的 <code>KV 缓存</code> 技术扩展到了请求间，从而可以非常好的解决如下的场景：</p>
<ul>
<li>Query 1：天空为什么是蓝色的？</li>
<li>Query 2：天空为什么是蓝色的，请给出详细的物理学上的解释？</li>
</ul>
<blockquote>
<p>本节中提到的 <code>Prompt Cache</code> 均指代论文 <em>Prompt Cache: Modular Attention Reuse</em> 中的 <code>Prompt Cache</code>。</p>
</blockquote>
<p><code>Prompt Cache</code> 的基本思想是：在推理阶段，以文本片段（text segment）为单位，把频繁出现的文本段对应的注意力状态（结果）存储下来；在之后请求的推理时，如果遇到相同的文本段，就直接使用缓存的注意力状态（结果）。</p>
<p>为了实现这个目标，有两个挑战需要解决：</p>
<ul>
<li>Transformers 架构中存在位置编码，因此 tokens 之间的自注意力状态（结果）与位置有关。所以，只有当相同的文本段出现在相同位置时，才能复用该文本段的自注意力状态（结果）。</li>
<li>必须具备有效识别已经缓存了自注意力状态（结果）的文本段的能力，这样系统才能够使用这些文本段缓存的自注意力状态（结果）。</li>
</ul>
<p>为了解决如上的两个难题，<code>Prompt Cache</code> 采取了如下的技术方案和探索：</p>
<ul>
<li>论文中提到，作者通过实验证明：虽然自注意力机制和位置编码有关，但是只要保持输入 tokens 之间的相对位置不变，那么大语言模型的输出质量就不会受到影响。这意味着我们可以提取输入 prompts 的不同片段的注意力状态（结果），并将它们拼接在一起，从而构建新的语义。</li>
<li>提出了一种提示词标记语言 (<em>PML：Prompt Markup Language</em>) 以明确 prompt 的结构。PML  将可重用的文本段表示为模块，从而解决了有效识别可复用的文本段的问题。</li>
</ul>
<p>例如，如果我们有一条如下的 prompt：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PROMPT &#x3D; &quot;&quot;&quot;</span><br><span class="line">SystemPrompt</span><br><span class="line">Context</span><br><span class="line">Examples</span><br><span class="line"></span><br><span class="line">Query: q?</span><br><span class="line">Answer: </span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure>
<p>根据论文中的 PML 的定义，我们可以构建如下的 prompt schema：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;prompt schema&#x3D;&quot;TaskPrompt&quot;&gt;</span><br><span class="line">  &lt;SystemPrompt&#x2F;&gt;</span><br><span class="line">  &lt;Context&#x2F;&gt;</span><br><span class="line">  &lt;Examples&#x2F;&gt;</span><br><span class="line">  Query: q? Answer: </span><br><span class="line">&lt;&#x2F;prompt&gt;</span><br></pre></td></tr></table></figure>
<p>在推理时，<code>Prompt Cache</code> 的处理流程如下：</p>
<ul>
<li>检索缓存的注意力状态（结果）：从缓存中获取 SystemPrompt, Context, Examples 的注意力状态（结果）。</li>
<li>处理新文本：用户输入的文本都未缓存，需要重新计算注意力状态（结果），例如上例中的 <code>Query: q? Answer: </code> 就是未缓存的部分。</li>
<li>合并注意力状态（结果）：按顺序拼接 SystemPrompt + Context + Examples + UserPrompt 的注意力状态（结果）。</li>
<li>生成响应：使用合并后的注意力状态（结果）来生成 LLM 的响应。</li>
</ul>
<p>更详细的例子如下图所示：</p>
<p><img src="/2024/11/23/insight-of-the-prompt-cache/17325398113275.jpg" alt></p>
<h2 id="openai-api-中的-prompt-caching">OpenAI API 中的 Prompt Caching</h2>
<p>对于 OpenAI API 中提供的 <code>Prompt Caching</code> 技术大概率也是基于 <code>KV 缓存</code> 技术来避免跨请求间的注意力重复计算来提升 <code>prefill 阶段</code> 的性能并实现费用降低的目的。OpenAI 的 <code>Prompt Caching</code> 要求必须有精准匹配的前缀，因此我们可以推测，OpenAI 可能并没有使用耶鲁大学的 <code>Prompt Cache</code> 技术，而是采用了一种更为简便的方案。</p>
<p>根据 OpenAI 官网的介绍，OpenAI 会自动为 GPT-4o、GPT-4o-mini、o1-preview、o1-mini 模型以及这些模型的微调版本开启 <code>Prompt Caching</code> 功能。当通过 API 调用对应的模型，并且输入 prompts 的长度大于 1024 时，OpenAI 会自动为这些请求开启 <code>Prompt Caching</code> 功能，以提升模型的响应速度。</p>
<p>之所以采用 1024 个 tokens 的阈值，可能是一个权衡的结果，毕竟 <code>Prompt Caching</code> 在本质上时一种 <strong>通过空间换时间</strong> 的技术，虽然可以提升请求的响应速度，但是也会导致 GPU 内存的过渡消耗，从而影响到单个 GPU 的吞吐。因此，当请求中的 prompts 长度比较小时，<code>Prompt Caching</code> 的 ROI 就比较低了。</p>
<p>SARATHI 提出的 <code>chunked-prefills</code> 技术可以允许我们将一个 <code>prefill 阶段</code> 的请求拆分为大小相等的块，同时利用把一个 <code>prefill-chunk</code> 和多个 <code>decode</code> 构建成一个批处理请求的这种搭便车（<em>piggyback</em>）的技术来实现解码最大化批处理（decode-maximal batching），进而避免了模型在流水线并行中存在的流水线等待问题，从而提高大模型的推理性能。<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup></p>
<p><img src="/2024/11/23/insight-of-the-prompt-cache/17325284975396.jpg" alt></p>
<p>OpenAI 大概率也采用了类似 SARATHI 中的 <code>chunked-prefills</code> 技术，因此可以实现缓存不同请求间的最长前缀来达到加速计算的效果。OpenAI 在对输入 prompts 进行分块时，采用的分块大小为 128 tokens，以实现最大程度的可控性。</p>
<p>根据 OpenAI 的介绍<sup class="footnote-ref"><a href="#fn6" id="fnref6:1">[6:1]</a></sup>，当用户输入 prompts 的长度超过 1024 个 tokens 时：</p>
<ul>
<li>API 首先会计算该请求的最长前缀，并将该最长前缀的结果缓存起来（<code>KV 缓存</code>），该最长前缀的长度从 1024 开始，并且以 128 的大小逐步递增。</li>
<li>当该用户的下一个请求包含该最长前缀时，API 则可以直接复用最长前缀的注意力结果、并且依赖缓存结果仅计算最长前缀之后的 tokens 的注意力结果实现请求的加速。</li>
</ul>
<p>基于 Transformer 架构的大模型利用 <strong>因果计算</strong>（<em>causal computation</em>）来计算自注意力，所以在使用 <code>Prompt Caching</code> 时必须保证请求间存在一致的前缀。因此，OpenAI 的官方文档中说：只有当请求间存在完全一致的前缀时，才会命中 <code>Prompt Caching</code><sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>。</p>
<blockquote>
<p>Cache hits are only possible for exact prefix matches within a prompt.</p>
<p>To realize caching benefits, place static content like instructions and examples at the beginning of your prompt, and put variable content, such as user-specific information, at the end.<br>
<img src="/2024/11/23/insight-of-the-prompt-cache/17325296211790.jpg" alt></p>
</blockquote>
<p>根据 OpenAI 的官方文档，<code>Prompt Caching</code> 的流程如下<sup class="footnote-ref"><a href="#fn10" id="fnref10:1">[10:1]</a></sup>：</p>
<ul>
<li><strong>Cache Lookup</strong>：检查输入 prompts 的前缀是否位于缓存</li>
<li><strong>Cache Hit</strong>：如果找到匹配的前缀，则使用缓存结果</li>
<li><strong>Cache Miss</strong>：否则，按照完成的处理方式从头处理该请求，并将对应的结果缓存起来以备将来使用</li>
</ul>
<p>为了避免无效的缓存占用，对于缓存的最长前缀计算结果，如果没有在 5~10 分钟内再次访问该缓存结果，OpenAI 将清空该缓存。在非高峰时段，缓存可以保存长达 1 小时。</p>
<p><code>Prompt Caching</code> 可用于 1024 个或更多 tokens 的 prompts，并且缓存以 128 个 token 不断增加，也就是说请求中缓存的 tokens 数量将始终为：1024、1152、1280、1408……</p>
<p>可以通过 API 响应中的 <code>usage.prompt_tokens_details.cached_tokens</code> 字段来查看请求是否命中 <code>Prompt Caching</code> 以及命中 <code>Prompt Caching</code> 的 tokens 数量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&quot;usage&quot;: &#123;</span><br><span class="line">  &quot;prompt_tokens&quot;: 2006,</span><br><span class="line">  &quot;completion_tokens&quot;: 300,</span><br><span class="line">  &quot;total_tokens&quot;: 2306,</span><br><span class="line">  &quot;prompt_tokens_details&quot;: &#123;</span><br><span class="line">    &quot;cached_tokens&quot;: 1920</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;completion_tokens_details&quot;: &#123;</span><br><span class="line">    &quot;reasoning_tokens&quot;: 0,</span><br><span class="line">    &quot;accepted_prediction_tokens&quot;: 0,</span><br><span class="line">    &quot;rejected_prediction_tokens&quot;: 0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="举个例子🌰">举个例子🌰</h2>
<p>我有一个图片内容分析的服务，该服务允许用户输入一张图片和一段文本描述，然后判断图片内容和文本描述之间的相关性，并根据相关性给于一个打分。</p>
<p>简便期间，我使用 GPT-4o 模型来实现这个功能，整体的 prompts 得格式如下所示：</p>
<p><img src="/2024/11/23/insight-of-the-prompt-cache/pic_prompt.png" alt></p>
<p>一般而言，我会一次分析几百张图片，并且用于图片分析的 prompts 的长度非常大，平均长度在 1200 个 tokens 左右。而其中的角色设定、分析规则、打分规则的描述部分在 1000 个 tokens 左右，并且是固定不变的，变化的图片和文本miaon描述部分在 200 个 tokens 左右（其中图片固定 85 个 tokens）。所以在没有 <code>Prompt Caching</code> 之前，每次请求都会重复计算 1000 个 tokens（占比 80%），从而造成大量的重复计算，进而带来了更多的费用。</p>
<p>在 <code>Prompt Caching</code> 之后，我每次请求只需要计算 200 个 tokens（占比 20%），从而节省了 80% 的计算量和费用，具体的 GPT-4o 的 API 响应如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&quot;usage&quot;: &#123;</span><br><span class="line">  &quot;prompt_tokens&quot;: 1135, </span><br><span class="line">  &quot;completion_tokens&quot;: 284, </span><br><span class="line">  &quot;total_tokens&quot;: 1419, </span><br><span class="line">  &quot;prompt_tokens_details&quot;: &#123;</span><br><span class="line">    &quot;cached_tokens&quot;: 1024</span><br><span class="line">  &#125;, </span><br><span class="line">  &quot;completion_tokens_details&quot;: &#123;</span><br><span class="line">    &quot;reasoning_tokens&quot;: 0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上述的结果可以发现，使用 <code>Prompt Caching</code> 之后，该请求有 1024 个 tokens（占比 90%）命中了缓存，从而节省了 90% 的费用。</p>
<h2 id="参考文献">参考文献</h2>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.04934v2">Prompt Cache: Modular Attention Reuse For Low-Latency Inference</a> <a href="#fnref1" class="footnote-backref">↩︎</a> <a href="#fnref1:1" class="footnote-backref">↩︎</a> <a href="#fnref1:2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://simonwillison.net/2024/May/14/context-caching-for-google-gemini/">Context caching for Google Gemini</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://platform.moonshot.cn/blog/posts/context-caching">Context Caching 正式公测</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://api-docs.deepseek.com/news/news0802">DeepSeek API introduces Context Caching on Disk, cutting prices by an order of magnitude</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.anthropic.com/news/prompt-caching">Prompt caching with Claude</a> <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://openai.com/index/api-prompt-caching/">Prompt Caching in the API</a> <a href="#fnref6" class="footnote-backref">↩︎</a> <a href="#fnref6:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.05276v1">GPT Semantic Cache: Reducing LLM Costs and Latency via Semantic Embedding Caching</a> <a href="#fnref7" class="footnote-backref">↩︎</a> <a href="#fnref7:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://github.com/zilliztech/GPTCache">GPTCache : A Library for Creating Semantic Cache for LLM Queries</a> <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.16369">SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills</a> <a href="#fnref9" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn10" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://platform.openai.com/docs/guides/prompt-caching">Prompt caching: Reduce latency and cost with Prompt Caching</a> <a href="#fnref10" class="footnote-backref">↩︎</a> <a href="#fnref10:1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
 
      <!-- reward -->
      
      <div id="reword-out">
        <div id="reward-btn">
          打赏
        </div>
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://wangwei1237.github.io/2024/11/23/insight-of-the-prompt-cache/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM-Interface/" rel="tag">LLM Interface</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Prompt-Cache/" rel="tag">Prompt Cache</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2024/12/01/Reflections-on-the-LLMs-Technological-Evolution/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            对大模型技术演化的思考
          
        </div>
      </a>
    
    
      <a href="/2024/11/16/The-LLMs-Runtime-Inference-and-KV-Cache/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">大模型的运行时推理和 KV Cache</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "ppRS6IT7xMHmCl54L7ynIC2Z-gzGzoHsz",
    app_key: "qEmM49ZlU6LOwXCHjzMUECKu",
    path: window.location.pathname,
    avatar: "mp",
    placeholder: "快来评论吧~",
    recordIP: true,
    visitor: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2020-2025
        <i class="ri-heart-fill heart_icon"></i> Wang Wei
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <!--<span id="busuanzi_container_page_pv">本文阅读量<span id="busuanzi_value_page_pv_"></span>次</span>
  <span class="division">|</span>
  -->
  <span id="busuanzi_container_site_uv"><i class="ri-user-3-fill"></i>本站访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span id="busuanzi_container_site_pv"><i class="ri-eye-fill"></i>本站浏览次数:<span id="busuanzi_value_site_pv"></span></span>
</span>
<script>
  
</script>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="17哥"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/books">图书</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/shares">分享</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/aboutme">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/weixin.png">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->
 
    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css">
        <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script>
        
            <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js"></script>
            <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css">
        
    
 
<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>