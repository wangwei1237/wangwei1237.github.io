<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh-Hans" xml:lang="zh-Hans"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Large Language Model in Action - 1&nbsp; LLM 的前世今生</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./tokens.html" rel="next">
<link href="./preface.html" rel="prev">
<link href="./favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "没有结果",
    "search-matching-documents-text": "匹配的文档",
    "search-copy-link-title": "复制搜索链接",
    "search-hide-matches-text": "隐藏其它匹配结果",
    "search-more-match-text": "更多匹配结果",
    "search-more-matches-text": "更多匹配结果",
    "search-clear-button-title": "清除",
    "search-detached-cancel-button-title": "取消",
    "search-submit-button-title": "提交",
    "search-label": "搜索"
  }
}</script>


<meta property="og:title" content="Large Language Model in Action - 1&nbsp; LLM 的前世今生">
<meta property="og:description" content="">
<meta property="og:image" content="https://wangwei1237.github.io/LLM_in_Action/images/llm_chatgpt_wb_hs.jpg">
<meta property="og:site-name" content="Large Language Model in Action">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./favicon.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Large Language Model in Action</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="搜索"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="切换导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://wangwei1237.github.io/" rel="" target=""><i class="bi bi-house-fill" role="img">
</i> 
 <span class="menu-text">博客</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
      <i class="bi bi-bookshelf" role="img">
</i> 
 <span class="menu-text">书籍</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-">    
        <li>
    <a class="dropdown-item" href="https://zh.d2l.ai/" rel="" target="">
 <span class="dropdown-text">动手学深度学习</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://learnprompting.org/zh-Hans/docs/intro" rel="" target="">
 <span class="dropdown-text">Learn Prompting</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://pan.baidu.com/s/1dciwgbhO-lfKyRo8lOqW9Q?pwd=cm9q" rel="" target="">
 <span class="dropdown-text">Stabel Diffusion 提示词手册</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://wangwei1237.github.io/aboutme/" rel="" target=""><i class="bi bi-person-badge-fill" role="img">
</i> 
 <span class="menu-text">关于</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
    <a href="https://github.com/wangwei1237/LLM_in_Action" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="切换侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./llm_intro.html">LLM 基本概念</a></li><li class="breadcrumb-item"><a href="./llm_intro.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">LLM 的前世今生</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="切换侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="搜索"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">欢迎阅读</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">序言</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">LLM 基本概念</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="切換部分">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./llm_intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">LLM 的前世今生</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tokens.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Tokens</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./embedding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Embedding</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sft.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">微调</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prompt_engineer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">提示词工程</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hallucination.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">幻觉</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rag_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">RAG</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./agent_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Agent</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">LangChain</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="切換部分">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langchain_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">LangChain 简介</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langchain_serialization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">LangChain 序列化</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langchain_retrieval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">LangChain Retrieval</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langchain_function_call.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">LangChain 函数调用</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langchain_agent_react.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">LangChain ReAct Agent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langchain_agent_fc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">LangChain OpenAI Function Agent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langchain_agent_pae.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">LangChain PlanAndExcute Agent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langflow_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Langflow</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Embedchain</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="切換部分">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./embedchain_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Embedchain 简介</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">AutoGen</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Case Study</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="切換部分">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./case1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Case1</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">附录</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="切換部分">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">术语表</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langchain_install.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">LangChain 安装指南</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./milvus_install.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Milvus Beginner</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">目录</h2>
   
  <ul>
  <li><a href="#大语言模型族谱" id="toc-大语言模型族谱" class="nav-link active" data-scroll-target="#大语言模型族谱"><span class="header-section-number">1.1</span> 大语言模型族谱</a></li>
  <li><a href="#gpt-的贡献" id="toc-gpt-的贡献" class="nav-link" data-scroll-target="#gpt-的贡献"><span class="header-section-number">1.2</span> GPT 的贡献</a>
  <ul class="collapse">
  <li><a href="#预训练微调的模型架构" id="toc-预训练微调的模型架构" class="nav-link" data-scroll-target="#预训练微调的模型架构"><span class="header-section-number">1.2.1</span> 预训练+微调的模型架构</a></li>
  <li><a href="#迁移学习能力" id="toc-迁移学习能力" class="nav-link" data-scroll-target="#迁移学习能力"><span class="header-section-number">1.2.2</span> 迁移学习能力</a></li>
  <li><a href="#上下文学习能力和涌现" id="toc-上下文学习能力和涌现" class="nav-link" data-scroll-target="#上下文学习能力和涌现"><span class="header-section-number">1.2.3</span> 上下文学习能力和涌现</a></li>
  <li><a href="#代码能力和指令遵循能力" id="toc-代码能力和指令遵循能力" class="nav-link" data-scroll-target="#代码能力和指令遵循能力"><span class="header-section-number">1.2.4</span> 代码能力和指令遵循能力</a></li>
  </ul></li>
  <li><a href="#如何使用-llm" id="toc-如何使用-llm" class="nav-link" data-scroll-target="#如何使用-llm"><span class="header-section-number">1.3</span> 如何使用 LLM</a>
  <ul class="collapse">
  <li><a href="#传统自然语言理解任务" id="toc-传统自然语言理解任务" class="nav-link" data-scroll-target="#传统自然语言理解任务"><span class="header-section-number">1.3.1</span> 传统自然语言理解任务</a></li>
  <li><a href="#自然语言生成任务" id="toc-自然语言生成任务" class="nav-link" data-scroll-target="#自然语言生成任务"><span class="header-section-number">1.3.2</span> 自然语言生成任务</a></li>
  <li><a href="#知识密集型任务" id="toc-知识密集型任务" class="nav-link" data-scroll-target="#知识密集型任务"><span class="header-section-number">1.3.3</span> 知识密集型任务</a></li>
  <li><a href="#推理任务" id="toc-推理任务" class="nav-link" data-scroll-target="#推理任务"><span class="header-section-number">1.3.4</span> 推理任务</a></li>
  </ul></li>
  <li><a href="#llm-的缺陷" id="toc-llm-的缺陷" class="nav-link" data-scroll-target="#llm-的缺陷"><span class="header-section-number">1.4</span> LLM 的缺陷</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/wangwei1237/LLM_in_Action/edit/main/llm_intro.qmd" class="toc-action">编辑该页面</a></p><p><a href="https://github.com/wangwei1237/LLM_in_Action/issues/new" class="toc-action">报告问题</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">LLM 的前世今生</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>2022 年 11 月 30 日，OpenAI 正式发布了其面向消费用户的产品——ChatGPT。ChatGPT 一经发布便激起了圈内、圈外的广泛讨论——毕竟已经很长时间没有一种类似的技术可以引起如此广泛的讨论，ChatGPT 的发布也标志着大语言模型（LLM: Large Language Model） 时代的到来。看起来，刚刚要崛起的<code>元宇宙</code>，在这股风潮之下，也失去了往日的喧嚣。</p>
<p>根据 <a href="https://weibo.zhaoyizhe.com/superInfo.html?topic=ChatGPT">热搜引擎</a> 提供的微博热搜历史数据，我们发现，2022 年 12 月 5 日，ChatGPT 第一次登上微博热搜榜，其最后的在榜时间为 2023 年 3 月 31 日，累计在榜时长达到了 1391 分钟。</p>
<div id="fig-llm_chatgpt_wb_hs" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./images/llm_chatgpt_wb_hs.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">图&nbsp;1.1: ChatGPT登上微博热搜</figcaption>
</figure>
</div>
<p>根据 <a href="https://baike.baidu.com/starmap/view?nodeId=e0a309bf5b0f017891c7b859">百科星图</a> 可知，目前谷歌、亚马逊、百度、阿里等多个科技巨头都加入到了 <em>对话式大语言模型</em> 的研发中。</p>
<ul>
<li>2023 年 2 月 6 日，谷歌宣布将推出一款聊天机器人——Bard，2 月 9 日，谷歌 Bard 发布会试演翻车，回答内容出现错误，当日市值暴跌1000亿美元。</li>
<li>2023 年 2 月 24 日，Meta 官宣 SOTA 大语言模型 LLaMA，对非商用的研究用例开源。</li>
<li>2023 年 3 月 14 日，斯坦福发布了一个由 LLaMA 7B 微调的模型 Alpaca，性能和 GPT-3.5 不相上下。</li>
<li>2023 年 3 月 14 日，OpenAI 发布 GPT-4。</li>
<li>2023 年 3 月 16 日，百度举办“百度文心一言新闻发布会”，正式发布 <em>文心一言</em>。</li>
<li>2023 年 4 月 11 日，阿里在阿里云峰会上，正式宣布推出大语言模型 <em>通义千问</em>。</li>
<li>2023 年 7 月 18 日，Meta 官宣发布 LLaMA2。</li>
<li>2023 年 10 月 17 日，百度在 2023 年的百度世界大会上宣布发布 <em>文心 4.0</em>。</li>
<li>……</li>
</ul>
<p>根据 <span class="citation" data-cites="zhao2023survey">[<a href="references.html#ref-zhao2023survey" role="doc-biblioref">9</a>]</span>，在学术界，ChatGPT 发布之后，和大模型相关的论文的数量也呈现出爆发式增长。</p>
<div id="fig-trend_for_llm" class="quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-trend_lm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./images/treand_lm.jpg" class="img-fluid figure-img" data-ref-parent="fig-trend_for_llm"></p>
<figcaption class="figure-caption">(a) Query = “Language Model”</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-trend_llm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./images/trend_llm.jpg" class="img-fluid figure-img" data-ref-parent="fig-trend_for_llm"></p>
<figcaption class="figure-caption">(b) Query = “Large Language Model”</figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">图&nbsp;1.2: <a href="https://arxiv.org/">arXiv</a> 论文库中“大语言模型”的论文数量趋势图</figcaption><p></p>
</figure>
</div>
<section id="大语言模型族谱" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="大语言模型族谱"><span class="header-section-number">1.1</span> 大语言模型族谱</h2>
<p><span class="citation" data-cites="vaswani2023attention">[<a href="references.html#ref-vaswani2023attention" role="doc-biblioref">7</a>]</span> 可以称之为大语言模型的鼻祖和源泉，在 <span class="citation" data-cites="vaswani2023attention">[<a href="references.html#ref-vaswani2023attention" role="doc-biblioref">7</a>]</span> 中，谷歌机器翻译团队提出了由多组 Encoder/Decoder 构成的机器翻译模型 Transformer，而 Transformer 模型也成为了一切的起点。之后，大模型的发展大致走上了两条路：</p>
<ul>
<li>一条路是舍弃 Decoder 部分，仅仅使用 Encoder 部分的自编码语言模型<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>，其最出名的代表就是 Bert 家族。</li>
<li>一条路是舍弃 Encoder 部分，仅仅基于 Decoder 部分的自回归语言模型<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>，而 ChatGPT 背后的 GPT<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> 家族则属于 Decoder-only 的分支。</li>
</ul>
<p><span class="citation" data-cites="yang2023harnessing">[<a href="references.html#ref-yang2023harnessing" role="doc-biblioref">8</a>]</span> 给出了如 <a href="#fig-llm_family_tree">图&nbsp;<span>1.3</span></a> 所示的大语言模型的族谱。</p>
<div id="fig-llm_family_tree" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./images/LLMTree.jpeg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">图&nbsp;1.3: 大语言模型族谱</figcaption>
</figure>
</div>
<p>在大语言模型发展的早期，以 Bert 为代表的自编码模型突飞猛进，但是由于没有突破 Scale Law <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> 法则，因此其发展速度也凋零。反之，由于 GPT 的研究人员发现：扩大语言模型的规模可以显著提高零样本与小样本的学习的能力——也即突破了 Scale Law，以 GPT 为代表的自回归分支则更加枝繁叶茂，成为了当下大模型发展的主流分支。</p>
</section>
<section id="gpt-的贡献" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="gpt-的贡献"><span class="header-section-number">1.2</span> GPT 的贡献</h2>
<p><span class="citation" data-cites="zhao2023survey">[<a href="references.html#ref-zhao2023survey" role="doc-biblioref">9</a>]</span> 对 LLM 的相关能力和 GPT 的相关进展做了详细的描述，这里我们重点说一下 GPT 对 LLM 发展的核心贡献。</p>
<section id="预训练微调的模型架构" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="预训练微调的模型架构"><span class="header-section-number">1.2.1</span> 预训练+微调的模型架构</h3>
<p>2018 年，OpenAI 发表了论文 <span class="citation" data-cites="radford2018improving">[<a href="references.html#ref-radford2018improving" role="doc-biblioref">5</a>]</span>，这就是 GPT-1。GPT-1 提出的预训练+微调的方法可以更好的利用大量的预训练数据，从而让模型能够更好的适应各种特定任务。虽然当时还存在一些局限性，例如当时还不能根据一个给定的标题来生成一篇新闻报道，但是 GPT-1 所开创的这种 预训练+微调 的模型架构，对 NLP 的后续发展具有深远的影响。</p>
<ul>
<li>在预训练阶段，模型会在大规模无标注文本上进行无监督学习，提取通用的语言特征。</li>
<li>在微调阶段，模型会在特定任务上进行有监督的学习，以适应不同的任务需求。</li>
</ul>
</section>
<section id="迁移学习能力" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="迁移学习能力"><span class="header-section-number">1.2.2</span> 迁移学习能力</h3>
<p>为了解决 GPT-1 的问题，2019 年，OpenAI 发布了 GPT-2，论文 <span class="citation" data-cites="Radford2019LanguageMA">[<a href="references.html#ref-Radford2019LanguageMA" role="doc-biblioref">6</a>]</span> 对 GPT-2 进行了详细的阐述。通过增加模型参数和数据量，GPT-2 极大的提高了模型的泛化能力和生成能力。除了在特定任务上表现较好（例如更具标题生成文章）之外，GPT-2 还初步表现出一定的零样本或少量样本学习能力。这使得 GPT-2 能够适用于多种自然语言处理任务，例如：翻译，问答，摘要生成，文本生成等，而在 GPT-2 之前，这些特殊任务需要设计专门的模型来分别实现。GPT-2 通过实践证明通过海量数据和大量参数训练出来的词向量模型在不经过额外的特殊训练下就可以迁移到不同类别的任务。</p>
<p>GPT-2 最大的贡献也在于他通过实践验证了大模型的迁移学习能力。</p>
</section>
<section id="上下文学习能力和涌现" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="上下文学习能力和涌现"><span class="header-section-number">1.2.3</span> 上下文学习能力和涌现</h3>
<p>2020 年，OpenAI 发布了 1750 亿参数规模的、性能更加强大的 GPT-3。<span class="citation" data-cites="NEURIPS2020_1457c0d6">[<a href="references.html#ref-NEURIPS2020_1457c0d6" role="doc-biblioref">1</a>]</span> 中提到，GPT-3 提出了上下文学习（ICL：in-context learning）的概念。ICL 可以指导 LLM 理解以自然语言形式呈现的任务，利用 ICL 的能力，我们可以通过优化给 LLM 的输入以获取更好的结果。在 ICL 的加持下，<a href="prompt_engineer.html"><span>章节&nbsp;5</span></a> 中介绍的提示词工程才得以成为可能。</p>
<p>GPT-3 在多种自然语言处理任务上展现出了惊人的性能，甚至可以仅通过简单的提示词来适应不同的处理任务。而研究人员实际上没有在 GPT-3 训练完之前就预测到模型有这么强大的能力，GPT-3 的实践证明，LLM 可以具备涌现能力（Emergent Ability）。</p>
</section>
<section id="代码能力和指令遵循能力" class="level3" data-number="1.2.4">
<h3 data-number="1.2.4" class="anchored" data-anchor-id="代码能力和指令遵循能力"><span class="header-section-number">1.2.4</span> 代码能力和指令遵循能力</h3>
<p>为了进一步提升模型的性能，OpenAI 继续探索了两种主要方法：基于代码数据训练和，与人类偏好保持一致。</p>
<p>2021 年，OpenAI 在 <span class="citation" data-cites="chen2021evaluating">[<a href="references.html#ref-chen2021evaluating" role="doc-biblioref">3</a>]</span> 中推出了在大量 GitHub 代码语料库上微调的 GPT 模型——Codex。Codex 可以解决非常复杂的编程问题，并且还可以显著提高解决数学问题的性能。目前，大名鼎鼎的 <a href="https://github.com/features/copilot">Github Copilot</a> 就是基于 <a href="https://openai.com/blog/openai-codex">Codex</a> 模型而研发。</p>
<p>2022 年，OpenAI 在 <span class="citation" data-cites="ouyang2022training">[<a href="references.html#ref-ouyang2022training" role="doc-biblioref">4</a>]</span> 中推出了基于 RLHF 技术的增强版 GPT-3——InstructGPT。InstructGPT 在指令遵循方面对 GPT-3 模型做了微调，使得其更善于遵循用户的意图。</p>
<p>代码能力和指令遵循能力进一步增强了 GPT-3 模型的能力，OpenAI 将其称之为 GPT-3.5。而 ChatGPT 刚刚推出的时候，其背后默认的模型就是 GPT-3.5。</p>
<p>所以，从整个的 GPT 的历程看，从 2018 年 ~ 2022 年，在长达 5 年多的时间里，OpenAI 一步一步通过探索和实践，让大模型应该具备的相关能力一点一点的浮出水面，进入我们的视野。</p>
</section>
</section>
<section id="如何使用-llm" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="如何使用-llm"><span class="header-section-number">1.3</span> 如何使用 LLM</h2>
<p>大模型虽然好，但是我们该如何使用大模型呢？是自己训练一个大模型，还是微调（<a href="sft.html"><span>章节&nbsp;4</span></a>），亦或是用提示词工程（<a href="prompt_engineer.html"><span>章节&nbsp;5</span></a>），还是随便选择一种方案？</p>
<div id="fig-llm_action_w" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./images/llm_in_action_ways.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">图&nbsp;1.4: 使用 LLM 的不同方式，每种方式对应不同的成本，可以解决的问题也不相同</figcaption>
</figure>
</div>
<p><span class="citation" data-cites="yang2023harnessing">[<a href="references.html#ref-yang2023harnessing" role="doc-biblioref">8</a>]</span> 中给出了一种决策流程以帮助我们决策具体采用哪种方案：</p>
<div id="fig-llm_decision_flow" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./images/llm_decision_flow.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">图&nbsp;1.5: 用户选择 LLM 或微调模型的决策流程。该决策流程帮助用户评估其应用场景是否满足特定条件，并根据评估结果确定 LLM 或微调模型是否最适合其应用场景。在图中的决策过程中，Y 表示满足条件，N 表示不满足条件。最后一个条件的 Y 的黄色圆圈表示没有模型在这种应用上运行良好。</figcaption>
</figure>
</div>
<section id="传统自然语言理解任务" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="传统自然语言理解任务"><span class="header-section-number">1.3.1</span> 传统自然语言理解任务</h3>
<p>对于大多数传统自然语言理解的任务，微调模型的效果更好。</p>
<ul>
<li>文本分类</li>
<li>情感分析</li>
<li>信息检索</li>
</ul>
<p>当然 LLMs 的潜力受限于 Prompt 工程可能仍未完全释放。在一些小众的领域，如 Miscellaneous Text Classification，Adversarial NLI 等任务中 ，LLMs 由于更强的泛化能力因而具有更好的性能，但是在目前而言，对于有成熟标注的数据而言，微调模型可能仍然是对传统任务的最优解。</p>
</section>
<section id="自然语言生成任务" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="自然语言生成任务"><span class="header-section-number">1.3.2</span> 自然语言生成任务</h3>
<p>相较于自然语言理解，自然语言生成就是大模型的战场了。自然语言生成的目标主要是创建连贯、通顺、有意义的序列，LLM 对这种场景有天然的优势，例如：机器翻译、段落信息摘、写作、画图……。有时候，我们使用简单的 <code>提示词工程</code>（<a href="prompt_engineer.html"><span>章节&nbsp;5</span></a>）就可以实现强大的内容生成工作。</p>
</section>
<section id="知识密集型任务" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="知识密集型任务"><span class="header-section-number">1.3.3</span> 知识密集型任务</h3>
<p>知识密集型任务一般指强烈依赖背景知识、领域专业知识或者一般世界知识的任务，知识密集型任务区别于简单的模式识别与句法分析，需要对我们的现实世界拥有“常识”并能正确的使用。在涉及这类场景时，虽然大模型不是“百灵鸟”，但是我们可以采用 RAG（<a href="rag_intro.html"><span>章节&nbsp;7</span></a>） 的模式来增强大语言的性能。</p>
</section>
<section id="推理任务" class="level3" data-number="1.3.4">
<h3 data-number="1.3.4" class="anchored" data-anchor-id="推理任务"><span class="header-section-number">1.3.4</span> 推理任务</h3>
<p>LLM 的扩展能力可以极大的增强预训练语言模型的能力，当模型规模指数增加时，一些关键能力（如推理的能力）会逐渐随参数的扩展而被激活，LLM 的算术推理与常识推理的能力肉眼可见的异常强大。当然，随着模型规模的增长，模型还会表现出一些 Emergent Ability，例如符合操作、逻辑推导、概念理解等等。当然，虽然 LLM 具备一定的算术推理能力，但是在涉及到数学计算等场景时，我们最好还是采用 Agent（<a href="agent_intro.html"><span>章节&nbsp;8</span></a>） 调用外部工具的方式避免大模型的幻觉（<a href="hallucination.html"><span>章节&nbsp;6</span></a>）以获得始终精确的结果。</p>
</section>
</section>
<section id="llm-的缺陷" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="llm-的缺陷"><span class="header-section-number">1.4</span> LLM 的缺陷</h2>
<p>虽然 LLM 目前已经具备非常强大的性能，虽然我们已经开始在尝试着和 LLM 协作，虽然 LLM 已经开始在提升我们的工作质效方面发挥着强大的作用，但是我们还是要认识到：LLM 并非完美无暇。</p>
<p>除了性能、效率、成本等问题外，LLM 的安全问题几乎是大模型所面对的所有挑战之中的重中之重。另外，机器幻觉（<a href="hallucination.html"><span>章节&nbsp;6</span></a>）也是大模型目前还没有特别好的解决方案的主要问题，大模型输出的有偏差或有害的幻觉将会对使用者造成严重后果。</p>
<div id="fig-huanjue_llm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./images/obtuse_angle.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">图&nbsp;1.6: 幻觉的例子</figcaption>
</figure>
</div>
<p>目前，LLM 面临的主要挑战可以分为：</p>
<ul>
<li>实践验证：当前针对大模型的评估数据集往往是更像“玩具”的学术数据集，但是这些学术数据集无法完全反应现实世界中形形色色的问题与挑战，因此亟需实际的数据集在多样化、复杂的现实问题上对模型进行评估，确保模型可以应对现实世界的挑战。更多的大模型评估的内容可以参见 <span class="citation" data-cites="LLMEvaluationSurvey">[<a href="references.html#ref-LLMEvaluationSurvey" role="doc-biblioref">2</a>]</span>。</li>
<li>模型对齐：大模型的强大也引出了另一个问题——模型应该与人类的价值观对齐，确保模型行为符合预期，不会“强化”不良结果。作为一个高级的复杂系统，如果不认真处理这种道德问题，有可能会为人类酝酿一场灾难。</li>
<li>安全隐患：大模型的研究要进一步强调安全问题，消除安全隐患，需要具体的研究确保大模型的安全研发，需要更多的做好模型的可解释性、监督管理工作，安全问题应该是模型开发的重要组成部分，而非锦上添花可有可无的装饰。</li>
<li>模型的可解释性：我们针对大模型神奇现象的了解仍然十分有限，针对大模型原理性的见解仍然十分珍贵。</li>
</ul>


<div id="refs" class="references csl-bib-body" role="list" style="display: none">
<div id="ref-NEURIPS2020_1457c0d6" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">Brown, T. 等 2020. <a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf">Language Models are Few-Shot Learners</a>. <em>Advances in Neural Information Processing Systems</em> (2020), 1877–1901.</div>
</div>
<div id="ref-LLMEvaluationSurvey" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">Chang, Y. 等 2023. <a href="https://arxiv.org/abs/2307.03109">A Survey on Evaluation of Large Language Models</a>. <em>arXiv preprint arXiv:2307.03109</em>. (2023).</div>
</div>
<div id="ref-chen2021evaluating" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">Chen, M. 等 2021. <a href="https://arxiv.org/abs/2107.03374">Evaluating Large Language Models Trained on Code</a>.</div>
</div>
<div id="ref-ouyang2022training" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Ouyang, L. 等 2022. <a href="https://arxiv.org/abs/2203.02155">Training language models to follow instructions with human feedback</a>.</div>
</div>
<div id="ref-radford2018improving" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Radford, A. 等 2018. Improving language understanding by generative pre-training. (2018).</div>
</div>
<div id="ref-Radford2019LanguageMA" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">Radford, A. 等 2019. <a href="https://api.semanticscholar.org/CorpusID:160025533">Language Models are Unsupervised Multitask Learners</a>. (2019).</div>
</div>
<div id="ref-vaswani2023attention" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">Vaswani, A. 等 2023. <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>.</div>
</div>
<div id="ref-yang2023harnessing" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">Yang, J. 等 2023. <a href="https://arxiv.org/abs/2304.13712">Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</a>.</div>
</div>
<div id="ref-zhao2023survey" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">Zhao, W.X. 等 2023. <a href="https://arxiv.org/abs/2303.18223">A Survey of Large Language Models</a>.</div>
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>自编码模型：自编码语言模型通过随机Mask输入的部分单词，然后预训练的目标是预测被Mask的单词，不仅可以融入上文信息，还可以自然的融入下文信息。<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>自回归模型：自回归语言模型根据输入序列中的前面的内容来预测序列中的下一个词。自回归模型只能利用上文或者下文的信息，不能同时利用上文和下文的信息。<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>GPT，Generative Pre-trained Transformer，基于 Transformer 的生成式预训练模型。<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Scaling Laws：随着模型大小、数据集大小和用于训练的计算浮点数的增加，模型的性能会提高。为了获得模型的最佳性能，所有三个因素必须同时放大。当不受其他两个因素的制约时，模型性能与每个单独的因素都有幂律关系。<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "已复制");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "已复制");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="wangwei1237/LLM_in_Action" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./preface.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">序言</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./tokens.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Tokens</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">Copyright VII-QA. All Rights Reserved.</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>