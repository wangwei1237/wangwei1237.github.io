[
  {
    "objectID": "index.html#欢迎阅读",
    "href": "index.html#欢迎阅读",
    "title": "Large Language Model in Action",
    "section": "欢迎阅读",
    "text": "欢迎阅读\n这是一本关于 大语言模型 实践的书籍，而不是一本深入研究 大语言模型 的运行原理和底层算法的书籍。\n如果您是一位想深入学习框架、算法并对其进行优化改进的研究者，本书可能并不适合您。\n如果您想大概了解一下相关的概念，并以此来指导自己的实践，想了解目前在应用开发中有哪些工具以及这些工具的具体实践用法，那么这本书正是为您而作。\n正如这本书的题目，这本书会更偏向实践、应用，但是我们也会在数据介绍大模型相关的概念，这些概念会让您对大模型有一个初步的认识，仅此而已。如果您想深入了解相关概念的底层细节，我们也提供了对应的文献，您可以深入阅读相关的文献。\n这是一个飞速发展的时代，技术、工具的发展亦是如此——每天有新的工具产生，也会有部分技术过时——因此我们以在线书籍的方式来构建这本书以保持内容的与时俱进。这也是一本开放的书籍，如果您希望为本书贡献自己的力量，您可以点击导航栏右上角的图标进入本书的代码仓库，提交您的内容。\n这本书整体会分为三大部分：\n\nPART 1：基本概念篇，主要介绍大模型相关的基本概念\nPART 2：相关工具篇，主要介绍大模型相关的工具，LangChain, Langflow, AutoGen……\nPART 3：具体实践偏，主要介绍应用大模型的具体案例"
  },
  {
    "objectID": "index.html#版权声明",
    "href": "index.html#版权声明",
    "title": "Large Language Model in Action",
    "section": "版权声明",
    "text": "版权声明\n本书采用“保持署名—非商用”创意共享 4.0 许可证。只要保持署名和非商用，您可以自由地阅读、分享本书。\n您可以：\n\n下载、保存以及打印本翻译稿\n网络链接、转载本翻译稿的部分或者全部内容，但是必须在明显处提供读者访问本书发布网站的链接\n\n您不可以：\n\n以任何形式出售本书的电子版或者打印版\n擅自印刷、出版本书\n以纸媒出版为目的，改写、改编以及摘抄本书的内容"
  },
  {
    "objectID": "preface.html#书中的样式惯例",
    "href": "preface.html#书中的样式惯例",
    "title": "序言",
    "section": "书中的样式惯例",
    "text": "书中的样式惯例\n在本书中，遵循以下的排版约定：\n\n斜体：表示新术语、URL、电子邮件地址、文件名和文件扩展名。\n固定宽度：用于程序列表、段落中引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。\n粗体：突出显示重要文本。\n\n\n\n\n\n\n注释\n\n\n\n需要注意的事项或额外的内容补充将如此表示，包括需要注意的事情，因为它可能会影响到我们的操作。\n\n\n\n\n\n\n\n\n提示\n\n\n\n技巧类信息将如此表示， 并提供可能对我们有用或简化操作方式的内容。\n\n\n\n\n\n\n\n\n警告\n\n\n\n警告信息将如此表示，并介绍如果不注意此处的信息则可能导致损失的事项。"
  },
  {
    "objectID": "preface.html#致谢",
    "href": "preface.html#致谢",
    "title": "序言",
    "section": "致谢",
    "text": "致谢\n\n本书通过 quarto 构建，quarto 是一款非常优秀的科学、技术内容发布系统，感谢 quarto 社区的努力，加速了本书的构建进程。\n感谢在探索之路上，一起打怪升级的队友和朋友们~"
  },
  {
    "objectID": "llm_intro.html#大语言模型族谱",
    "href": "llm_intro.html#大语言模型族谱",
    "title": "1  LLM 的前世今生",
    "section": "1.1 大语言模型族谱",
    "text": "1.1 大语言模型族谱\n[7] 可以称之为大语言模型的鼻祖和源泉，在 [7] 中，谷歌机器翻译团队提出了由多组 Encoder/Decoder 构成的机器翻译模型 Transformer，而 Transformer 模型也成为了一切的起点。之后，大模型的发展大致走上了两条路：\n\n一条路是舍弃 Decoder 部分，仅仅使用 Encoder 部分的自编码语言模型1，其最出名的代表就是 Bert 家族。\n一条路是舍弃 Encoder 部分，仅仅基于 Decoder 部分的自回归语言模型2，而 ChatGPT 背后的 GPT3 家族则属于 Decoder-only 的分支。\n\n[8] 给出了如 图 1.3 所示的大语言模型的族谱。\n\n\n\n图 1.3: 大语言模型族谱\n\n\n在大语言模型发展的早期，以 Bert 为代表的自编码模型突飞猛进，但是由于没有突破 Scale Law 4 法则，因此其发展速度也凋零。反之，由于 GPT 的研究人员发现：扩大语言模型的规模可以显著提高零样本与小样本的学习的能力——也即突破了 Scale Law，以 GPT 为代表的自回归分支则更加枝繁叶茂，成为了当下大模型发展的主流分支。"
  },
  {
    "objectID": "llm_intro.html#gpt-的贡献",
    "href": "llm_intro.html#gpt-的贡献",
    "title": "1  LLM 的前世今生",
    "section": "1.2 GPT 的贡献",
    "text": "1.2 GPT 的贡献\n[9] 对 LLM 的相关能力和 GPT 的相关进展做了详细的描述，这里我们重点说一下 GPT 对 LLM 发展的核心贡献。\n\n1.2.1 预训练+微调的模型架构\n2018 年，OpenAI 发表了论文 [5]，这就是 GPT-1。GPT-1 提出的预训练+微调的方法可以更好的利用大量的预训练数据，从而让模型能够更好的适应各种特定任务。虽然当时还存在一些局限性，例如当时还不能根据一个给定的标题来生成一篇新闻报道，但是 GPT-1 所开创的这种 预训练+微调 的模型架构，对 NLP 的后续发展具有深远的影响。\n\n在预训练阶段，模型会在大规模无标注文本上进行无监督学习，提取通用的语言特征。\n在微调阶段，模型会在特定任务上进行有监督的学习，以适应不同的任务需求。\n\n\n\n1.2.2 迁移学习能力\n为了解决 GPT-1 的问题，2019 年，OpenAI 发布了 GPT-2，论文 [6] 对 GPT-2 进行了详细的阐述。通过增加模型参数和数据量，GPT-2 极大的提高了模型的泛化能力和生成能力。除了在特定任务上表现较好（例如更具标题生成文章）之外，GPT-2 还初步表现出一定的零样本或少量样本学习能力。这使得 GPT-2 能够适用于多种自然语言处理任务，例如：翻译，问答，摘要生成，文本生成等，而在 GPT-2 之前，这些特殊任务需要设计专门的模型来分别实现。GPT-2 通过实践证明通过海量数据和大量参数训练出来的词向量模型在不经过额外的特殊训练下就可以迁移到不同类别的任务。\nGPT-2 最大的贡献也在于他通过实践验证了大模型的迁移学习能力。\n\n\n1.2.3 上下文学习能力和涌现\n2020 年，OpenAI 发布了 1750 亿参数规模的、性能更加强大的 GPT-3。[1] 中提到，GPT-3 提出了上下文学习（ICL：in-context learning）的概念。ICL 可以指导 LLM 理解以自然语言形式呈现的任务，利用 ICL 的能力，我们可以通过优化给 LLM 的输入以获取更好的结果。在 ICL 的加持下，章节 5 中介绍的提示词工程才得以成为可能。\nGPT-3 在多种自然语言处理任务上展现出了惊人的性能，甚至可以仅通过简单的提示词来适应不同的处理任务。而研究人员实际上没有在 GPT-3 训练完之前就预测到模型有这么强大的能力，GPT-3 的实践证明，LLM 可以具备涌现能力（Emergent Ability）。\n\n\n1.2.4 代码能力和指令遵循能力\n为了进一步提升模型的性能，OpenAI 继续探索了两种主要方法：基于代码数据训练和，与人类偏好保持一致。\n2021 年，OpenAI 在 [3] 中推出了在大量 GitHub 代码语料库上微调的 GPT 模型——Codex。Codex 可以解决非常复杂的编程问题，并且还可以显著提高解决数学问题的性能。目前，大名鼎鼎的 Github Copilot 就是基于 Codex 模型而研发。\n2022 年，OpenAI 在 [4] 中推出了基于 RLHF 技术的增强版 GPT-3——InstructGPT。InstructGPT 在指令遵循方面对 GPT-3 模型做了微调，使得其更善于遵循用户的意图。\n代码能力和指令遵循能力进一步增强了 GPT-3 模型的能力，OpenAI 将其称之为 GPT-3.5。而 ChatGPT 刚刚推出的时候，其背后默认的模型就是 GPT-3.5。\n所以，从整个的 GPT 的历程看，从 2018 年 ~ 2022 年，在长达 5 年多的时间里，OpenAI 一步一步通过探索和实践，让大模型应该具备的相关能力一点一点的浮出水面，进入我们的视野。"
  },
  {
    "objectID": "llm_intro.html#如何使用-llm",
    "href": "llm_intro.html#如何使用-llm",
    "title": "1  LLM 的前世今生",
    "section": "1.3 如何使用 LLM",
    "text": "1.3 如何使用 LLM\n大模型虽然好，但是我们该如何使用大模型呢？是自己训练一个大模型，还是微调（章节 4），亦或是用提示词工程（章节 5），还是随便选择一种方案？\n\n\n\n图 1.4: 使用 LLM 的不同方式，每种方式对应不同的成本，可以解决的问题也不相同\n\n\n[8] 中给出了一种决策流程以帮助我们决策具体采用哪种方案：\n\n\n\n图 1.5: 用户选择 LLM 或微调模型的决策流程。该决策流程帮助用户评估其应用场景是否满足特定条件，并根据评估结果确定 LLM 或微调模型是否最适合其应用场景。在图中的决策过程中，Y 表示满足条件，N 表示不满足条件。最后一个条件的 Y 的黄色圆圈表示没有模型在这种应用上运行良好。\n\n\n\n1.3.1 传统自然语言理解任务\n对于大多数传统自然语言理解的任务，微调模型的效果更好。\n\n文本分类\n情感分析\n信息检索\n\n当然 LLMs 的潜力受限于 Prompt 工程可能仍未完全释放。在一些小众的领域，如 Miscellaneous Text Classification，Adversarial NLI 等任务中 ，LLMs 由于更强的泛化能力因而具有更好的性能，但是在目前而言，对于有成熟标注的数据而言，微调模型可能仍然是对传统任务的最优解。\n\n\n1.3.2 自然语言生成任务\n相较于自然语言理解，自然语言生成就是大模型的战场了。自然语言生成的目标主要是创建连贯、通顺、有意义的序列，LLM 对这种场景有天然的优势，例如：机器翻译、段落信息摘、写作、画图……。有时候，我们使用简单的 提示词工程（章节 5）就可以实现强大的内容生成工作。\n\n\n1.3.3 知识密集型任务\n知识密集型任务一般指强烈依赖背景知识、领域专业知识或者一般世界知识的任务，知识密集型任务区别于简单的模式识别与句法分析，需要对我们的现实世界拥有“常识”并能正确的使用。在涉及这类场景时，虽然大模型不是“百灵鸟”，但是我们可以采用 RAG（章节 7） 的模式来增强大语言的性能。\n\n\n1.3.4 推理任务\nLLM 的扩展能力可以极大的增强预训练语言模型的能力，当模型规模指数增加时，一些关键能力（如推理的能力）会逐渐随参数的扩展而被激活，LLM 的算术推理与常识推理的能力肉眼可见的异常强大。当然，随着模型规模的增长，模型还会表现出一些 Emergent Ability，例如符合操作、逻辑推导、概念理解等等。当然，虽然 LLM 具备一定的算术推理能力，但是在涉及到数学计算等场景时，我们最好还是采用 Agent（章节 8） 调用外部工具的方式避免大模型的幻觉（章节 6）以获得始终精确的结果。"
  },
  {
    "objectID": "llm_intro.html#llm-的缺陷",
    "href": "llm_intro.html#llm-的缺陷",
    "title": "1  LLM 的前世今生",
    "section": "1.4 LLM 的缺陷",
    "text": "1.4 LLM 的缺陷\n虽然 LLM 目前已经具备非常强大的性能，虽然我们已经开始在尝试着和 LLM 协作，虽然 LLM 已经开始在提升我们的工作质效方面发挥着强大的作用，但是我们还是要认识到：LLM 并非完美无暇。\n除了性能、效率、成本等问题外，LLM 的安全问题几乎是大模型所面对的所有挑战之中的重中之重。另外，机器幻觉（章节 6）也是大模型目前还没有特别好的解决方案的主要问题，大模型输出的有偏差或有害的幻觉将会对使用者造成严重后果。\n\n\n\n图 1.6: 幻觉的例子\n\n\n目前，LLM 面临的主要挑战可以分为：\n\n实践验证：当前针对大模型的评估数据集往往是更像“玩具”的学术数据集，但是这些学术数据集无法完全反应现实世界中形形色色的问题与挑战，因此亟需实际的数据集在多样化、复杂的现实问题上对模型进行评估，确保模型可以应对现实世界的挑战。更多的大模型评估的内容可以参见 [2]。\n模型对齐：大模型的强大也引出了另一个问题——模型应该与人类的价值观对齐，确保模型行为符合预期，不会“强化”不良结果。作为一个高级的复杂系统，如果不认真处理这种道德问题，有可能会为人类酝酿一场灾难。\n安全隐患：大模型的研究要进一步强调安全问题，消除安全隐患，需要具体的研究确保大模型的安全研发，需要更多的做好模型的可解释性、监督管理工作，安全问题应该是模型开发的重要组成部分，而非锦上添花可有可无的装饰。\n模型的可解释性：我们针对大模型神奇现象的了解仍然十分有限，针对大模型原理性的见解仍然十分珍贵。\n\n\n\n\n\n[1] Brown, T. 等 2020. Language Models are Few-Shot Learners. Advances in Neural Information Processing Systems (2020), 1877–1901.\n\n\n[2] Chang, Y. 等 2023. A Survey on Evaluation of Large Language Models. arXiv preprint arXiv:2307.03109. (2023).\n\n\n[3] Chen, M. 等 2021. Evaluating Large Language Models Trained on Code.\n\n\n[4] Ouyang, L. 等 2022. Training language models to follow instructions with human feedback.\n\n\n[5] Radford, A. 等 2018. Improving language understanding by generative pre-training. (2018).\n\n\n[6] Radford, A. 等 2019. Language Models are Unsupervised Multitask Learners. (2019).\n\n\n[7] Vaswani, A. 等 2023. Attention Is All You Need.\n\n\n[8] Yang, J. 等 2023. Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond.\n\n\n[9] Zhao, W.X. 等 2023. A Survey of Large Language Models."
  },
  {
    "objectID": "llm_intro.html#footnotes",
    "href": "llm_intro.html#footnotes",
    "title": "1  LLM 的前世今生",
    "section": "",
    "text": "自编码模型：自编码语言模型通过随机Mask输入的部分单词，然后预训练的目标是预测被Mask的单词，不仅可以融入上文信息，还可以自然的融入下文信息。↩︎\n自回归模型：自回归语言模型根据输入序列中的前面的内容来预测序列中的下一个词。自回归模型只能利用上文或者下文的信息，不能同时利用上文和下文的信息。↩︎\nGPT，Generative Pre-trained Transformer，基于 Transformer 的生成式预训练模型。↩︎\nScaling Laws：随着模型大小、数据集大小和用于训练的计算浮点数的增加，模型的性能会提高。为了获得模型的最佳性能，所有三个因素必须同时放大。当不受其他两个因素的制约时，模型性能与每个单独的因素都有幂律关系。↩︎"
  },
  {
    "objectID": "tokens.html#tokenizer-工具",
    "href": "tokens.html#tokenizer-工具",
    "title": "2  Tokens",
    "section": "2.1 Tokenizer 工具",
    "text": "2.1 Tokenizer 工具\n我们可以使用 OpenAI 提供的在线 Tokenizer Tool 来加深对 token 的理解和认识。\n\n\n\n图 2.1: 待 token 化的原始文本\n\n\n\n\n\n\n\n\n\n(a) token 化结果\n\n\n\n\n\n\n\n(b) 各 token 的 ID\n\n\n\n\n图 2.2: OpenAI GTP-4 tokenization 结果\n\n\n在 OpenAI 中，一个 token 大概约等于 4 个英文字母的长度，换算一下的话，大概约是 \\(\\frac{3}{4}\\) 个单词。\n当然，OpenAI 也支持对中文的 tokenization 处理。\n\n\n\n图 2.3: 待 token 化的中文原始文本\n\n\n\n\n\n\n\n\n\n(a) 中文 token 化结果\n\n\n\n\n\n\n\n(b) 各中文 token 的 ID\n\n\n\n\n图 2.4: 利用 OpenAI GTP-4 对中文进行 tokenization 的结果\n\n\n\n\n\n\n\n\n警告\n\n\n\n在 图 2.4 (a) 中，我们会发现有乱码出现，这主要是因为部分中文会包含一个或多个映射到多个 token 的 unicode 字符。在线化工具会以非标准的方式显示每个 token 中的字节。\n\n\n从 图 2.4 (a) 中，我们也会发现，对中文的 tokenization 有其独特性——并非将每个汉字都处理为一个 token，有时候一个 token 可能是一个词。例如，”北京“ 在 tokenization 之后是一个 token，其 ID 为 70090。\n如果想在代码中使用 OpenAI 的 tokenizer 工具进行 token 化处理，可以使用如下的库：\n\nPython：tiktoken\nJavaScript: dqbd/tiktoken\n\n对于文心大模型而言，我们可以使用 千帆Token计算器 来计算输入文本的 token 数量。\n\n\n\n图 2.5: 千帆Token计算器"
  },
  {
    "objectID": "tokens.html#tokenization-方式",
    "href": "tokens.html#tokenization-方式",
    "title": "2  Tokens",
    "section": "2.2 Tokenization 方式",
    "text": "2.2 Tokenization 方式\n把输入/输出文本拆分为 LLM AI 模型可以处理的、更小单元的过程，我们称之为：Token 化。如前所述，token 可以是单词、字符、子单词或符号。文本 Token 化之后，模型可以在 token 的基础上处理不同的语言、词汇和格式，并降低处理过程的计算成本和资源成本。Token 化还可以通过影响 token 的含义和上下文来影响生成文本的质量和多样性。\n目前主要有三种主流的 tokenization 算法：BPE，WordPiece，Unigram Language Model。\n\n2.2.1 BPE\nBPE（Byte Pair Encoding）最早是一种数据压缩算法，其思想是将经常一起出现的数据对替换为不在数据串中的其他字符，然后再通过一个 merge 表来恢复原始数据。\n在 2015 年，[3] 把该算法引入到 NLP 领域。2019 年，[4] 又提出了 BBPE（Byte-Level BPE）算法，将 BPE 的思想从字符级别扩展到字节级别。\nOpenAI 所采用的 tokenization 算法就是 BPE 算法。BPE 可以帮助模型处理罕见的、或者看不见的单词，并创建更紧凑和一致的文本表示。BPE 还允许模型通过组合现有单词或 token 来生成新单词或 token。词汇量越大，模型生成的文本就越多样化和富有表现力。然而，词汇表越大，模型需要的内存和计算资源就越多。因此，词汇大小的选择取决于模型的质量和效率之间的权衡。\n\n\n2.2.2 WordPiece\n[2] 提出了用于解决日语和韩语语音问题的 WordPiece。与BPE 类似，WordPiece 也是从一个基础小词表出发，通过不断合并来产生最终的词表。\nWordPiece 与 BPE 的主要的差别在于，BPE 按频率来选择合并的 token 对，而 WordPiece 按 token 间的互信息1来进行合并。WordPiece 可以较好的平衡词表大小和 OOV2 问题，但是可能会产生不太合理的、错误的切分，并且 WordPeice 对拼写错误非常敏感，同时其对前缀的支持也不够好。\n\n\n2.2.3 Unigram Language Model\n[1] 提出了 Unigram Language Model，其核心思想就是先初始化一个大词表，然后通过 unigram 语言模型计算删除不同 subword 造成的损失来代表 subword 的重要性，最后保留 loss 较大或者说重要性较高的 subword。\nULM 是一种基于语言模型的分词算法，这种语言模型可以给多种分词结果赋予概率，从而可以学到其中的噪声，其使用的训练算法可以利用所有可能的分词结果。但是，ULM 的效果与初始词表息息相关，初始词表的好还会影响到最终的结果。"
  },
  {
    "objectID": "tokens.html#token-与模型成本之间的关系",
    "href": "tokens.html#token-与模型成本之间的关系",
    "title": "2  Tokens",
    "section": "2.3 Token 与模型成本之间的关系",
    "text": "2.3 Token 与模型成本之间的关系\nTokenization 会影响 LLM 需要处理的数据量和计算次数。LLM 需要处理的 token 越多，模型消耗的内存和计算资源就越多。\n因此，运行 LLM 的成本取决于：\n\ntokenization 采用的算法和模型所使用的词汇表的大小\n输入/输出文本的长度和复杂性\n\n因此，对于不同的模型3，与模型交互时所使用的 token 数量的不同，最终所花费的成本也不同。对于 OpenAI 而言，GTP4 的费用是 GTP3 的 10 倍，对于 GPT4 而言，32K 上下文模型的费用是 4K 上下文模型费用的 2 倍4。百度的文心 4.0 大模型的费用则是之前版本的 15 倍5。\n\n对于 OpenAI 的 gpt-3.5-turbo-16k 模型而言，每 1024 个输入 token 的费用为 0.003$，每 1024 个输出 token 的费用为 0.004$。\n对于 OpenAI 的 gpt-4 模型而言，每 1024 个输入 token 的费用为 0.03$，每 1024 个输出 token 的费用为 0.06$。\n对于 OpenAI 的 gpt-4-32k 模型而言，每 1024 个输入 token 的费用为 0.06$，每 1024 个输出 token 的费用为 0.12$。\n对于百度的 ERNIE-Bot-turbo 模型而言，每 1000 个输入 token 的费用为 0.008￥，每 1000 个输出 token 的费用为 0.008￥。\n对于百度的 ERNIE-Bot 4.0 模型而言，每 1000 个输入 token 的费用为 0.12￥，每 1000 个输出 token 的费用为 0.12￥。\n\n\n\n\n\n[1] Kudo, T. 2018. Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates.\n\n\n[2] Schuster, M. 和 Nakajima, K. 2012. Japanese and Korean Voice Search.\n\n\n[3] Sennrich, R. 等 2016. Neural Machine Translation of Rare Words with Subword Units.\n\n\n[4] Wang, C. 等 2019. Neural Machine Translation with Byte-Level Subwords."
  },
  {
    "objectID": "tokens.html#footnotes",
    "href": "tokens.html#footnotes",
    "title": "2  Tokens",
    "section": "",
    "text": "在分词领域有时也被称为凝固度、内聚度，可以反映一个词内部的两个部分结合的紧密程度。↩︎\nOOV（Out-of-Vocabulary）：词粒度分词模型只能使用词表中的词来进行处理，无法处理词表之外的词汇，这就是所谓的 OOV 问题。↩︎\nOpenAI 的模型列表↩︎\nOpenAI 计费说明↩︎\n文心大模型计费说明↩︎"
  },
  {
    "objectID": "embedding.html#获取-embedding",
    "href": "embedding.html#获取-embedding",
    "title": "3  Embedding",
    "section": "3.1 获取 Embedding",
    "text": "3.1 获取 Embedding\n可以根据 Embedding-V1 API 文档 的介绍，来获取基于百度文心大模型的字符串 Embedding。\n还可以使用 列表 12.5 的方式来获取相同的基于文心大模型的 Embedding。\nembeddings = QianfanEmbeddingsEndpoint()\nquery_result = embeddings.embed_query(\"你是谁？\")\n[0.02949424833059311, -0.054236963391304016, -0.01735987327992916, \n 0.06794580817222595, -0.00020318820315878838, 0.04264984279870987, \n -0.0661700889468193, ……\n ……]"
  },
  {
    "objectID": "embedding.html#可视化",
    "href": "embedding.html#可视化",
    "title": "3  Embedding",
    "section": "3.2 可视化",
    "text": "3.2 可视化\nEmbedding 一般是一种高维数据，为了将这种高维数据可视化，我们可以使用 t-SNE [1] 算法将数据进行降维，然后再做可视化处理。\n利用 列表 12.9 对文档进行向量化，然后将向量数据存储于 Milvus 向量数据库中（默认采用的 Collection 为 LangChainCollection）。\n可以通过 Milvus 提供的 HTTP API 来查看指定的 Collection 的结构：\nhttp://{{MILVUS_URI}}/v1/vector/collections/describe?collectionName=LangChainCollection\n\n\n\n图 3.1: Milvus向量数据的结构\n\n\n\n列表 3.1: 向量数据可视化\n#encoding: utf-8\n\n\"\"\"\n@discribe: demo for the embedding visualization.\n@author: wangwei1237@gmail.com\n\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pymilvus import connections\nfrom pymilvus import Collection\nfrom sklearn.manifold import TSNE\n\nconnections.connect(\n  host='127.0.0.1',\n  port='8081'\n1)\n\n2collection = Collection(\"LangChainCollection\")\n\nres = collection.query(\n  expr = \"pk &gt;= 0\",\n  offset = 0,\n  limit = 500, \n  output_fields = [\"vector\", \"text\", \"source\", \"title\"],\n3)\n\n4vector_list = [i[\"vector\"] for i in res]\n\n5matrix = np.array(vector_list)\n\ntsne = TSNE(n_components=2, perplexity=15, random_state=42, init='random', learning_rate=200)\n6vis_dims = tsne.fit_transform(matrix)\n\n7plt.scatter(vis_dims[:, 0], vis_dims[:, 1])\nplt.title(\"embedding visualized using t-SNE\")\nplt.show()\n\n\n1\n\n初始化 Milvus 链接\n\n2\n\n选择 LangChainCollection\n\n3\n\n从 LangChainCollection 中检索特定数据\n\n4\n\n只提取结果中的 vector 字段，并生成新的列表\n\n5\n\n将 python 列表转换成矩阵\n\n6\n\n对向量数据进行降维\n\n7\n\n对低维数据进行可视化\n\n\n结果如 图 3.2 所示：\n\n\n\n图 3.2: 向量数据可视化结果\n\n\n\n\n\n\n[1] Introduction to t-SNE: 2023. https://www.datacamp.com/tutorial/introduction-t-sne."
  },
  {
    "objectID": "sft.html#为什么微调",
    "href": "sft.html#为什么微调",
    "title": "4  微调",
    "section": "4.1 为什么微调",
    "text": "4.1 为什么微调\n除了成本因素之外，微调在机器学习中具有如此重要意义的原因还包括：\n\n数据效率：微调允许使用有限的特定任务数据进行有效的模型自适应。可以使用现有的预先训练模型，并根据任务对其进行优化，而不是收集和标注新的数据集。因此，从数据处理效率层面而言，微调会节省更多的时间和资源。\n时间效率：从头开始训练模型需要很长时间，而因为微调是从模型已经学习的特征开始，因此减少了收敛所需的时间，进而加快了训练的过程，提升了训练的效率。\n知识迁移：预训练模型在最初的训练中已经从大量数据集中学习到了有价值的特征和模式。微调可以将所获得的知识转移到特定任务中，微调可以使预训练模型在特定任务上有一种增强的效果。\n专业化：微调可以允许我们自定义一个模型，使其在特定任务中表现更加出色。通过调整模型的设置，可以创建一个在特定情况下非常有效的工具。"
  },
  {
    "objectID": "sft.html#何时微调",
    "href": "sft.html#何时微调",
    "title": "4  微调",
    "section": "4.2 何时微调",
    "text": "4.2 何时微调\n虽然微调的成本比从头预训练大模型的成本要小的多的多，但是对模型进行微调仍然需要我们投入时间和精力。微调不是没有成本，只是和预训练大模型相比成本小而已。\n因此，在准备微调之前，我们最好先尝试通过提示工程（章节 5）、RAG（章节 7）、或通过类似 Agent （章节 8）的函数调用来获得更好的结果。\n\n\n\n\n\n\n注释\n\n\n\n并非所有的大模型都支持函数调用，目前 OpenAI 的 GPT 是支持函数调用的，所以如果使用 GPT，则可以直接使用函数调用 API 来实现函数调用。\n对于不具备函数调用能力的大模型，可以考虑通过 Agent 的方式（例如使用 （章节 14）的 LangChain Agent 能力）来调用外部工具或函数。\n\n\n在准备微调之前，我们需要进行仔细的分析和考虑：\n\n模型在许多任务上可能最初表现不佳，但使用正确的提示词可以改善结果，此时可能不需要微调。\n迭代微调需要创建数据集并运行训练任务，因此迭代提示词比迭代微调快得多。"
  },
  {
    "objectID": "sft.html#如何微调",
    "href": "sft.html#如何微调",
    "title": "4  微调",
    "section": "4.3 如何微调",
    "text": "4.3 如何微调\n不同平台的微调方式各不相同，所以微调的方式需要参考具体使用的平台：\n\n百度文心大模型微调方式：SFT 文档\nGPT 大模型微调方式：Fine-tuning 文档"
  },
  {
    "objectID": "sft.html#footnotes",
    "href": "sft.html#footnotes",
    "title": "4  微调",
    "section": "",
    "text": "What Large Models Cost You – There Is No Free AI Lunch↩︎"
  },
  {
    "objectID": "prompt_engineer.html#什么是提示词",
    "href": "prompt_engineer.html#什么是提示词",
    "title": "5  提示词工程",
    "section": "5.1 什么是提示词",
    "text": "5.1 什么是提示词\n在 NLP 领域，提示 是一种用于引导预训练语言模型解决特定任务的方法。提示 通常是一段文本，用于构建问题或任务的描述，以便预训练语言模型可以根据其内在知识生成合适的输出。\n如果大语言模型是一个 5 岁的小孩，那么他基本上可以做非常多的事情了，关键是我们如何与一个 5 岁的小孩进行良好的沟通，以让他可以完成我们期望的任务？其中的关键就是 提示词。你是否还能记起你和孩子在一起的很多互动场景：\n\n出门的场景\n\n快点，要迟到嘞，别磨蹭了\n紧急呼叫汪汪队到门口集合\n\n打扫卫生的场景\n\n帮爸爸收拾一下桌子\n呼叫无敌小帮手，爸爸需要支援\n\n……\n\n不同的 提示词，既可以让孩子帮我们完成工作，又可以让孩子在这个过程中得到成长和锻炼。对于 LLM 而言，也是如此。\n从 图 5.1 也能看出，提示词 的重要性。\n\n\n\n图 5.1: 2023年百度世界大会主题"
  },
  {
    "objectID": "prompt_engineer.html#什么是提示词工程",
    "href": "prompt_engineer.html#什么是提示词工程",
    "title": "5  提示词工程",
    "section": "5.2 什么是提示词工程",
    "text": "5.2 什么是提示词工程\n提示工程起源于对预训练模型如何将知识应用于具体任务的探讨。\n预训练语言模型通常在大规模语料库上进行预训练，从而学习到大量的语言知识。然而，将这些知识应用于具体任务时，往往需要对模型进行微调（SFT：Supervised Fine Tuning）。微调过程中，模型需要根据标注的任务数据学习任务相关的知识。\n这种根据专有数据进行微调的方法，在许多情况下取得了很好的效果，但仍然存在一些问题。例如：\n\n微调过程可能需要大量的标注数据，而这些数据往往难以获得。\n微调后的模型可能会存在过拟合现象，导致模型的泛化能力下降。\n\n为了解决这些问题，研究人员开始关注如何通过优化输入和问题表述来引导模型产生更好的输出结果，而无须进行昂贵的微调，这种方法被称 提示词工程，如 图 5.2 所示。\n\n\n\n图 5.2: 微调和提示词工程的关系\n\n\n通过精心设计 提示词，我们可以引导模型关注输入数据中的关键信息，从而提高模型在各种自然语言处理任务上的性能。提示词工程 的核心思想是: 将问题表述为一种容易被模型理解和解答的形式。可以通过多种方式来实现 提示词工程，例如：重述问题，给出示例或采用渐进式提示等。提示词工程 的关键在于找到一种能够充分发挥模型潜力的问题表述方式。\n提示词工程 是一种优化和设计 提示词 的技术，从而可以更好的应用预训练大语言模型，使其可以更好的解决各种任务。"
  },
  {
    "objectID": "prompt_engineer.html#一种新的职业",
    "href": "prompt_engineer.html#一种新的职业",
    "title": "5  提示词工程",
    "section": "5.3 一种新的职业",
    "text": "5.3 一种新的职业\n提示词工程 对于任何使用 LLM 的人来说都是一项关键技能。随着越来越多的组织采用 LLM 来实现任务自动化并提高其生产效能，提示词工程 更是一项需求量很大的技能和职业。作为一个新兴的领域，提示词工程 特别需要创造力和对细节的关注。提示词工程 包括但不限于：选择正确的单词、短语、符号和格式，以指导模型生成高质量的、相关的文本。一个好的提示工程师可以通过设计产生所需输出的提示来帮助组织充分利用 LLM。\n如果大家已经使用过文心一言来和文心大模型互动，那么对于 提示词 应该比较熟悉。我们来看一下如下两个 提示词 的结果：\n\n\n\n\n\n\n\n(a) 请给出描述高兴的成语。\n\n\n\n\n\n\n\n(b) 请给出5个描述高兴的成语，并给出其解释。\n\n\n\n\n图 5.3: 不同提示词的结果差异\n\n\n\n\n\n\n\n\n扩展资料\n\n\n\n更多关于提示词工程的具体实践方法可以参考：Learn Prompting 1 和 Stabel Diffusion 提示词手册 2。"
  },
  {
    "objectID": "prompt_engineer.html#footnotes",
    "href": "prompt_engineer.html#footnotes",
    "title": "5  提示词工程",
    "section": "",
    "text": "Learn Prompting↩︎\nStabel Diffusion 提示词手册↩︎"
  },
  {
    "objectID": "hallucination.html",
    "href": "hallucination.html",
    "title": "6  幻觉",
    "section": "",
    "text": "如其他技术一样，即便当前 LLM 在各个领域中有着惊人的表现，但是 LLM 也存在着缺陷和局限。而 “幻觉（Hallucination）”就是一种非常常见的缺陷。\n\n\n\n\n\n\n幻觉\n\n\n\n幻觉是自然语言生成领域的一个术语，是指模型生成了看似合理但实际上并不存在的内容。这些内容可能包含虚构的信息、存在前后矛盾的逻辑、甚至是毫无意义的内容。\n幻觉原本是心理学领域的专有名词，用于描述一种特殊类型的知觉体验——在没有外部刺激的情况下，清醒的个体的虚假感觉。\n幻觉是一种不真实的、却又非分真实的虚幻感知。模型容易生成流畅但缺乏真实性的内容，这种现象与心理学中的幻觉极为相似，因此在 LLM 领域，我们把 LLM 的这种缺陷称之为 幻觉。\n\n\n幻觉会严重影响依赖 LLM 的下游业务的表现，导致这些业务在真实场景中无法满足用户需求。大语言模型生成内容的真实性是生成式模型接下来面临的重要科学问题之一。\n幻觉分为两类：\n\n内在幻觉（Intrinsic Hallucinations）：生成的内容与输入的源信息冲突。\n\n\n\n图 6.1: 内在幻觉的例子\n\n\n外在幻觉（Extrinsic Hallucinations）：生成了与源信息无关的内容。外在幻觉可能与事实冲突，也可能不冲突。在有些场景下，事实正确的外在幻觉可能会更好，但是事情往往并非总是如此。 \n\n\n\n\n\n\n\n重要\n\n\n\n幻觉，大模型的阿克琉斯之踵。\n\n\n更多关于幻觉的详细内容可以参见：[1]，[2]。\n\n\n\n\n[1] Ji, Z. 等 2023. Survey of Hallucination in Natural Language Generation. ACM Computing Surveys. 55, 12 (2023), 1–38. DOI:https://doi.org/10.1145/3571730.\n\n\n[2] Zhang, Y. 等 2023. Siren’s Song in the AI Ocean: A Survey on Hallucination in Large Language Models. arXiv preprint arXiv:2309.01219. (2023)."
  },
  {
    "objectID": "rag_intro.html#rag-基本概念",
    "href": "rag_intro.html#rag-基本概念",
    "title": "7  RAG",
    "section": "7.1 RAG 基本概念",
    "text": "7.1 RAG 基本概念\n根据 A Survey on Retrieval-Augmented Text Generation [1] 所述：RAG 是深度学习和传统检索技术（Retrieval Technology）的有机结合，在生成式大模型时代，有着以下优势：\n\n知识库和模型分离，知识不以参数的形式存储在模型中，而是明文存储在数据库中，灵活性更高；\n文本生成转变为文本总结，生成结果的可信度更高，同时还降低了文本生成的难度；\n\n\n\n\n图 7.1: RATG 综述研究概览\n\n\n根据 图 7.1，RAG 范式有三个重要的组成部分：Retrieval Source，Retrieval Metric，Integration Method。\n\n7.1.1 RAG 的表示方法\n传统的文本生成方法可以用如下公式表示：\n\\[\\boldsymbol{y}=f(\\boldsymbol{x}) \\tag{7.1}\\]\n其中，\\(\\boldsymbol{x}\\) 代表输入的文本（字符串序列），\\(f\\) 表示模型，\\(\\boldsymbol{y}\\) 表示模型输出的文本。\nRAG 则可以用如下公式表示：\n\\[\\boldsymbol{y}=f(\\boldsymbol{x}, \\boldsymbol{z}), \\boldsymbol{z} = \\{(\\boldsymbol{x}^\\gamma, \\boldsymbol{y}^\\gamma)\\} \\tag{7.2}\\]\n其中，\\(\\boldsymbol{x}\\) 代表输入的文本（字符串序列），\\(\\boldsymbol{z}\\) 代表知识库，\\(f\\) 表示模型，\\(\\boldsymbol{x}^\\gamma\\) 表示作为输入文本 \\(\\boldsymbol{x}\\) 的检索 key，\\(\\boldsymbol{y}^\\gamma\\) 是与模型输出相关的知识。\n\n\n7.1.2 Retrieval Source 类型\n\nTraining Corpus：有标注的训练数据直接作为外部知识。\nExternal Data：支持提供训练数据之外的外部知识作为检索来源，比如于任务相关的领域数据，实现模型的快速适应。\nUnsupervised Data：前两种知识源都需要一定的人工标注来完善“检索依据-输出”的对齐工作，无监督知识源可以直接支持无标注/对齐的知识作为检索来源。\n\n\n\n7.1.3 Retrieval Metrics 类型\n\nSparse-vector Retrieval（浅层语义）：针对稀疏向量场景的度量方法，比如TF-IDF, BM25等。\nDense-vector Retrieval（深层语义）：针对稠密向量的度量方法，比如文本相似度。\nTask-specific Retrieval：在通用的度量场景下，度量得分高并不能代表召回知识准确，因此有学者提出基于特定任务优化的召回度量方法，提高度量的准确率。\n\n\n\n7.1.4 Integration Method 类型\n\nData Augmentation：直接拼接用户输入文本和知识文本，然后输入文本生成模型。\nAttention Mechanisms：引入额外的Encoder，对用户输入文本和知识文本进行注意力编码后输入文本生成模型。\nSkeleton Extraction：前两种方法都是通过文本向量化的隐式方法完成知识重点片段的抽取，Skeleton Extraction方法可以显式地完成类似工作。\n\n在 RAG 模式下，AI 应用发生了新的范式变化，从传统的 Pre-training + Fine-tune 的模式转换为了 Pre-training + Prompt 模式。这种模式的转变简化了对于不同任务而言模型训练的工作量，降低了 AI 的开发和使用门槛，同时也使得 Retriveval + Generation 成为可能。\n\n\n\n图 7.2: RAG 基本架构"
  },
  {
    "objectID": "rag_intro.html#为什么要使用-rag",
    "href": "rag_intro.html#为什么要使用-rag",
    "title": "7  RAG",
    "section": "7.2 为什么要使用 RAG",
    "text": "7.2 为什么要使用 RAG\n仅依靠大模型已经可以完成很多任务，Fine-tune 也可以起到补充领域知识的作用，为什么 RAG 仍然如此重要呢？\n\n幻觉问题：尽管大模型的参数量很大，但和人类的所有知识相比，仍然有非常大的差距。所以，大模型在生成内容时，很有可能会捏造事实，导致如 章节 6 所述的“幻觉”。因此，对于 LLMs 而言，通过搜索召回相关领域知识来作为特定领域的知识补充是非常必要的。\n语料更新时效性问题：大模型的训练数据存在时间截止的问题。尽管可以通过 Fine-tune 来为大模型加入新的知识，但大模型的的训练成本和时间依然是需要面对的严峻难题：通常需要大量的计算资源，时间也难做到天级别更新。在 RAG 模式下，向量数据库和搜索引擎数据的更新都更加容易，这有助于业务数据的实时性。\n数据泄露问题：尽管，可以利用 Fine-tune 的方式增强 LLM 在特定领域的处理能力。但是，用于 Fine-tune 的这些领域知识很可能包含个人或者公司的机密信息，且这些数据很可能通过模型而不经意间泄露出去1。RAG 可以通过增加私有数据存储的方式使得用户的数据更加安全。"
  },
  {
    "objectID": "rag_intro.html#更多内容",
    "href": "rag_intro.html#更多内容",
    "title": "7  RAG",
    "section": "7.3 更多内容",
    "text": "7.3 更多内容\n更详细、深入的内容可以参考如下几篇文章：[1]，[2]。\n\n\n\n\n[1] Li, H. 等 2022. A Survey on Retrieval-Augmented Text Generation. arXiv preprint arXiv:2202.01110. (2022).\n\n\n[2] Mialon, G. 等 2023. Augmented Language Models: a Survey. (2023)."
  },
  {
    "objectID": "rag_intro.html#footnotes",
    "href": "rag_intro.html#footnotes",
    "title": "7  RAG",
    "section": "",
    "text": "ChatGPT致三星半导体机密泄漏↩︎"
  },
  {
    "objectID": "agent_intro.html#阿克琉斯之踵",
    "href": "agent_intro.html#阿克琉斯之踵",
    "title": "8  Agent",
    "section": "8.1 阿克琉斯之踵",
    "text": "8.1 阿克琉斯之踵\n虽然 LLM 非常强大，但在某些方面，与“最简单”的计算机程序的能力相比，LLM 并没有表现的更好，例如在 计算 和 搜索 这些计算机比较擅长的场景下，LLM 的表现却却很吃力。\n\n列表 8.1: 文心大模型的计算能力测试\n#encoding: utf-8\n\n\"\"\"\n@discribe: example for Ernie's calculate ability. \n@author: wangwei1237@gmail.com\n\"\"\"\n\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.chains import LLMChain\n\ntemplate = ChatPromptTemplate.from_messages([\n    (\"user\", \"你是一个能力非凡的人工智能机器人\"),\n    (\"assistant\", \"你好~\"),\n    (\"user\", \"{user_input}\"),\n])\n\nchat = ErnieBotChat()\nchain =  LLMChain(llm=chat, prompt=template)\nres =  chain.run(user_input=\"4.1*7.9=?\")\nprint(res)\n\n列表 8.1 的执行结果如下：\n['4.1乘以7.9等于31.79。']\n但实际上，\\(4.1 * 7.9 = 32.39\\)，很明显，文心给出了错误的结果。\n\n\n\n图 8.1: 一言的计算结果\n\n\n计算机程序（例如 python 的 mumexpr 库）可以轻而易举的处理这种简单的计算，甚至处理比这更复杂的计算也不在话下。但是，面对这些计算，LLM 有时候却显得力不从心。\n在 章节 7 中，我们提到，使用 RAG 可以解决训练数据的时效性问题、LLM 的幻觉问题、专有数据的安全性问题等问题，但是对于 列表 8.1 所示的问题，我们将如何解决？\n为了让 LLM 能更好的为我们赋能，我们必须解决这个问题，而接下来要介绍的 Agent 就是一种比较好的解决方案。\n利用 Agent，我们不但可以解决如上提到的 计算 的问题，我们还可以解决更多的问题。在我看来，Agent 可以解锁 LLM 的能力限制，让 LLM 具备无穷的力量，实现我们难以想象的事情。"
  },
  {
    "objectID": "agent_intro.html#什么是-agent",
    "href": "agent_intro.html#什么是-agent",
    "title": "8  Agent",
    "section": "8.2 什么是 Agent",
    "text": "8.2 什么是 Agent\n在日常生活中，我们解决问题也不是仅依靠我们自己的能力，我们也会使用计算器进行数学计算，我们也会 百度一下 以获取相关信息，君子性非异也善假于物也。同样，Agent 使得 LLM 可以像人一样做同样的事情。\n\n\n\n图 8.2: Agent 就是能够使用各种外部工具的 LLM\n\n\n从本质上讲，Agent 是一种特殊的 LLM，这种特殊的 LLM 的特殊性在于它可以使用各种外部工具来完成我们给定的操作。\n与我们使用外部工具完成任务一样：\n\n我们首先会对任务进行思考\n然后判断我们有哪些工具可用\n接下来再选择一种我们可用的工具来实施行动\n然后我们会观察行动结果以判断如何采取下一步的行动\n我们会重复 1-4 这个过程，直到我们认为我们完成了给定的任务\n\n\n\n\n图 8.3: Agent 流程示意图\n\n\n如 图 8.3 所示，虽然 Agent 本质上是 LLM，但是其包含的 Thought 和 Tools Set 将 Agent 和 LLM 区别开来，并且这种逐步思考的方式也使得 LLM 可以通过多次推理或多次使用工具来获取更好的结果。\n根据 B 站 UP 主发布的视频：作为一款优秀的 Agent，AutoGPT 可以实现自己查询文献、学习文献，并最终完成给定论文题目写作的整个过程，而整个过程中出了最开始需要给 AutoGPT 发布任务外，其他环节则全部由 AutoGPT 自动完成。"
  },
  {
    "objectID": "agent_intro.html#sec-agent_react",
    "href": "agent_intro.html#sec-agent_react",
    "title": "8  Agent",
    "section": "8.3 ReAct 模式",
    "text": "8.3 ReAct 模式\n此处的 ReAct 既不是软件设计模式中的 reactor 模式1，也不是 Meta 公司开发的前端开发框架 react2，而是 Yao 等人在 [2]，[5] 中提出的：把 Reasoning 和 Action 与语言模型结合起来的通用范式，以解决各种语言推理和决策任务。\nReAct 使 LLM 能够以交错的方式生成 reasoning traces 和 text actions，ReAct 可以从上下文中进行推理并提取有用的信息来进行后续的 reasoning 和 action，从而影响模型的内部状态。正如 [2] 说述，ReAct 将推理阶段和行动阶段进行有效的结合，进一步提升了 LLM 的性能。\n\n\n\n图 8.4: ReAct 模型\n\n\n实际上，和 图 8.3 所示的流程是一致的。\n\n\n\n\n\n\n注释\n\n\n\nReAct 也称为 Action Agent，在 ReAct 模式系下，Agent 的下一步动作由之前的输出来决定，其本质是对 Prompt 进行优化的结果，一般可以用于规模较小的任务。"
  },
  {
    "objectID": "agent_intro.html#planandexecute-模式",
    "href": "agent_intro.html#planandexecute-模式",
    "title": "8  Agent",
    "section": "8.4 PlanAndExecute 模式",
    "text": "8.4 PlanAndExecute 模式\n如前所述，Action Agent 适用于规模较小的任务。当任务规模较大，而任务的解决又高度依赖 Agent 来驱动并完成时，Action Agent 就开始变得捉襟见肘。\n我们即希望 Agent 能够处理更加复杂的任务，又希望 Agent 具备较高的稳定性和可靠性。这中既要又要的目标导致 Agent 的提示词变得越来越大，越来越复杂。\n\n为了解决更复杂的任务，我们需要更多的工具和推理步骤，这会导致 Agent 的提示词中包含了过多的历史推理信息\n同时，为了提升 Agent 的可靠性，需要不断的优化/增加 Tool 的描述，以便 LLM 可以选择正确的工具\n\n在这种背景下，PlanAndExecute 模式应运而生。PlanAndExecute 将 计划（plan） 与 执行（execute） 分离开来。\n在 PlanAndExecute 模式下，计划 由一个 LLM 来驱动生成，而 执行 则可以由另外的 Agent 来完成:\n\n首先，使用一个 LLM 创建一个用于解决当前请求的、具有明确步骤的计划。\n然后，使用传统的 Action Agent 来解决每个步骤。\n\n\n\n\n图 8.5: PlanAndExectue Agent 基本流程\n\n\n目前，BabyAGI 也采用了类似的模式3，更多关于 PlanAndExecute 模式的底层细节，可以参考 [4]。\n\n\n\n\n\n\n注释\n\n\n\n该模式下，Agent 将大型任务分解为较小的、可管理的子目标，从而可以高效处理复杂任务。\n这种方式可以通过 计划 让 LLM 更加“按部就班”，更加可靠。但是其代价在于，这种方法需要更多的 LLM 交互，也必然具有更高的延迟。4"
  },
  {
    "objectID": "agent_intro.html#sec-multiagent",
    "href": "agent_intro.html#sec-multiagent",
    "title": "8  Agent",
    "section": "8.5 Multi-Agent",
    "text": "8.5 Multi-Agent\n到现在为止，我们所讲的 Agent 都是 Single-Agent，也就是说我们仅在这个单独的 Agent 中（没有和其他的 Agent 交互），就完成了用户提出的任务。在 [1] 中提到，Multi-Agent 是分布式 AI 领域的一个分支，强调在不同的 Agent 之间进行协作以完成用户的任务，这个时候的 Multi-Agent 主要存在于强化学习和博弈论(game theory) 的相关研究中。[3] 提出了一种新的框架，通过利用 Multi Agent 系统的能力来增强大型语言模型 LLM 的能力，在这个新的框架中，作者引入了一个协作环境，在这个环境中，Multi Agent 组件（每个组件具有独特的属性和角色，可以由不同的 LLM 来驱动）协同工作，从而可以更高效、更有效地处理复杂的任务。\n\n\n\n\n\n\nMulti Agent 的定义\n\n\n\n从本质上讲，Multi LLM Agent 是涉及到多个 LLM 驱动的 Agent 协同工作的融合体。与传统的 Single Agent 不同，Multi Agent 系统由各种 AI Agent 组成，每个 Agent 专门研究不同的领域，有助于全面解决问题。这种协作、协同效应产生了更细致和有效的解决方案。\n\n\n正如 图 8.6 所示，Multi Agent 系统可以通过不同 Agent 之间的协作来完成更为复杂的事情。\n\n\n\n图 8.6: AutoGen 的 Multi Agent 架构图5\n\n\nMulti Agent 的优势如下6：\n\n专业技能更强：在 Multi Agent 系统中，每个 Agent 都拥有各自领域的专业知识，使其能够提供深入、准确的响应。这种专业知识的广度确保了所生成的解决方案是全面和知情的。\n问题解决能力更强：复杂的问题往往需要采用不同层面的、综合的方法，Multi Agent 通过整合各个 Agent 的集体智慧，通过利用不同 Agent 各自的优势，以提供单 LLM 或者 单 Agent 难以解决的问题。正所谓：众人晒柴火焰高。\n稳定性更高：冗余和可靠性是人工智能驱动解决方案的关键因素。从架构上讲，Multi Agent 降低了单点故障的风险，如果一个 Agent 遇到问题或限制，其他 Agent 则可以介入，以确保整体系统的稳定性。\n适应性更好：在一个充满活力的世界里，适应性至关重要。Multi Agent 可以随着时间的推移而发展，新的 Agent 可以无缝集成以应对新出现的挑战。"
  },
  {
    "objectID": "agent_intro.html#参考文献",
    "href": "agent_intro.html#参考文献",
    "title": "8  Agent",
    "section": "8.6 参考文献",
    "text": "8.6 参考文献\n\n\n\n\n[1] Balaji, P.G. 和 Srinivasan, D. 2010. An Introduction to Multi-Agent Systems. Innovations in Multi-Agent Systems and Applications - 1. D. Srinivasan 和 L.C. Jain, 编. Springer Berlin Heidelberg. 1–27.\n\n\n[2] ReAct: Synergizing Reasoning and Acting in Language Models: 2022. https://react-lm.github.io/.\n\n\n[3] Talebirad, Y. 和 Nadiri, A. 2023. Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents.\n\n\n[4] Wang, L. 等 2023. Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models.\n\n\n[5] Yao, S. 等 2022. ReAct: Synergizing Reasoning and Acting in Language Models. arXiv preprint arXiv:2210.03629. (2022)."
  },
  {
    "objectID": "agent_intro.html#footnotes",
    "href": "agent_intro.html#footnotes",
    "title": "8  Agent",
    "section": "",
    "text": "Reactor Pattern↩︎\nreact 官网↩︎\nBabyAGI↩︎\nPlan-and-Execute Agents↩︎\nAutoGen↩︎\nRevolutionizing AI: The Era of Multi-Agent Large Language Models↩︎"
  },
  {
    "objectID": "assistants.html#assisant-api-的框架",
    "href": "assistants.html#assisant-api-的框架",
    "title": "9  Assistant",
    "section": "9.1 Assisant API 的框架",
    "text": "9.1 Assisant API 的框架\nOpenAI Assistant API 的架构图如 图 9.1 所示。\n\n\n\n图 9.1: OpenAI Assistant API 架构图\n\n\n在 Assistant Overview 中，已经对该图做了非常多的解释，但是在我看来，最令人兴奋的能力是访问持久化线程的能力。\n\n\n\n\n\n\n注释\n\n\n\n助理可以访问持久线程。线程通过存储消息历史记录来简化人工智能应用程序的开发，并在对话太长而超出模型的上下文长度时将其截断。\n使用 Assistant API，我们只需创建一次线程，然后我们可以在该线程内进行连续的多轮对话，而多轮对话需要的 记忆 功能，OpenAI 统统帮我们实现了（而如果使用 LangChain 或其他框架，这些都需要我们自己来实现）。我们可以轻松的实现如下的多轮会话：\n\n1 + 1 =?\n那么，再加10的结果是？\n……"
  },
  {
    "objectID": "assistants.html#assistant-运行状态",
    "href": "assistants.html#assistant-运行状态",
    "title": "9  Assistant",
    "section": "9.2 Assistant 运行状态",
    "text": "9.2 Assistant 运行状态\n和进程类似，Assistant API 创建的线程在回答用户的问题时（对应 图 9.1 中的 Run 阶段），也会存在各种状态的转换。每一次执行的具体的状态转化如 图 9.2 所示。\n\n\n\n图 9.2: Assistant API 线程每次执行的生命周期\n\n\n\n\n表格 9.1: Assistant API 中不同的状态及其含义\n\n\n状态\n状态含义\n\n\n\n\nqueued\n首次创建助理并执行或完成 required_action 时，将转变为 queued 状态。queued 状态应该立即转到 in_progress。\n\n\nin_progress\n在 in_progress 时，助理使用模型和工具执行相关操作。我们可以通过检 Run Step 来获取这次执行的具体进度。\n\n\ncompleted\n一旦这次执行成功，就会转到该状态，此时，我们可以查看助理返回的所有消息。我们还可以通过该线程继续进行下一轮的对话。\n\n\nrequires_action\n当使用 函数调用 时，一旦模型确定了要调用的函数的名称和参数，线程将转变为 required_action 状态。然后，我们必须运行这些函数并提交函数响应，才能继续运行。如果在 expires_at 时间戳达到时（创建后大约10分钟）还没有提交函数的运行结果，则此次执行将进入 expired 状态。\n\n\nexpired\n当 函数调用 的输出未在 expires_at 之前提交时，就会发生这种情况。此外，如果此次执行时间过长，超过expires_at 规定的时间时，也会转换到该状态。\n\n\ncancelling\n我们可以使用 Cancel Run API 取消 in_progress 中的某次执行。一旦取消成功，此次执行的状态将变为 cancelled。需要注意的是，Assistant API 仅仅是尝试取消，但不能保证取消成功。\n\n\ncancelled\n如果某次执行已经成功取消，则转到该状态。\n\n\nfailed\n执行失败是，转为该状态。可以通过 last_error 查看失败原因。\n\n\n\n\n因为 Assistant API 提供的线程是持久线程，因此，每当我们需要使用该线程处理用户需求时，我们最好及时的查询该线程当前的状态，以避免出现非预期的结果。"
  },
  {
    "objectID": "assistants.html#assistant-api-示例",
    "href": "assistants.html#assistant-api-示例",
    "title": "9  Assistant",
    "section": "9.3 Assistant API 示例",
    "text": "9.3 Assistant API 示例\n\n列表 9.1: Assistant API 示例\nfrom langchain.agents.openai_assistant import OpenAIAssistantRunnable\n\ninterpreter_assistant = OpenAIAssistantRunnable.create_assistant(\n    name=\"langchain assistant\",\n    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n    tools=[{\"type\": \"code_interpreter\"}],\n    model=\"gpt-4-1106-preview\",\n1)\n\n2output = interpreter_assistant.invoke({\"content\": \"What's 10 - 4 raised to the 2.7\"})\nprint(output)\n\n\"\"\"\n[ThreadMessage(id='msg_6Gj48OdMV8dQrFUPTh17UvG4', assistant_id='asst_19av1lcBjSCQ5cEk4pWqugEU', content=[MessageContentText(text=Text(annotations=[], value='The result of the expression \\\\(10 - 4^{2.7}\\\\) is approximately \\\\(-32.224\\\\).'), type='text')], created_at=1700038489, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_4wK9GIK2W0iiJlLB86DKoMQQ', thread_id='thread_Ie874bQrsaakLMpOMZe2KUav')]\n3\"\"\"\n\n4output_2 = interpreter_assistant.invoke({\"content\": \"Then, Add 10 to the result\", \"thread_id\": \"thread_Ie874bQrsaakLMpOMZe2KUav\"})\nprint(output_2) \n\n\"\"\"\n[ThreadMessage(id='msg_xRoHzvCdtqW9NRWxmE36VMZG', assistant_id='asst_mEAcerOkTv1IyggYoU3jTNMn', content=[MessageContentText(text=Text(annotations=[], value='After adding 10 to the previous result, the new result is approximately -22.224.'), type='text')], created_at=1700038760, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_ubrOtRXh6ITIRQ4BbPMk5juV', thread_id='thread_Ie874bQrsaakLMpOMZe2KUav')]\n5\"\"\"\n\n\n1\n\n创建 Assistant 线程\n\n2\n\n计算 \\(10-4^{2.7}\\)\n\n3\n\n获得结果 -32.224，同时返回线程 id 等其他信息\n\n4\n\n在当前结果基础上，继续用同一个线程执行 \\(res + 10\\)\n\n5\n\n获得结果 -22.224\n\n\n更多的 Assistant API 的使用例子，我们在 章节 16 中再介绍。"
  },
  {
    "objectID": "langchain_intro.html#langchain-的目标",
    "href": "langchain_intro.html#langchain-的目标",
    "title": "10  LangChain 简介",
    "section": "10.1 LangChain 的目标",
    "text": "10.1 LangChain 的目标\n不同的大语言模型都有各自的优势，我们可能会用 A 模型来进行自然语言理解，然后用 B 模型进行逻辑推理并获取结果……此时，如果使用大语言模型各自提供的 API 来和模型交互，那么就会存在非常多的重复工作。\n虽然大语言模型有很多，但是和大语言模型的交互流程又是非常类似（如 图 10.2 所示），如果每次和模型交互都需要重复如上的步骤，那听起来也是一件非常繁琐的事情。对于相同的提示词，我们不想每次都 ctr+c、ctr+v，这真是一件非常可怕的事情。\n\n\n\n\n\nflowchart LR\n  A(构造提示词) --&gt; B(LLMs)\n  B --&gt; C(模型生成结果)\n  C --&gt; D(结果处理)\n  D --&gt; E(最终结果)\n\n\n图 10.2: 和模型交互的流程\n\n\n\n\n和 FFmpeg 对视频的处理一样，FFmpeg 提供的 filtergraph 2机制大大增强了其音视频的处理能力，奠定其在视音频领域的地位。filtergraph 可以将不同的音视频处理能力以链条的形式组合起来，不但简化了音视频的处理流程，更让 FFmpeg 可以实现复杂的音视频处理。\n同理，和 LLMs 的单次交互并不会形成什么惊人的能量，而如果可以使用类似 filtergraph 的机制，将与 LLMs 的多次交互整合起来，那么其所释放的能量将是无穷的。\n而 LangChain 就是为了解决如上的问题而产生的。LangChain 可以提供给我们的最主要的价值如下3：\n\n组件化：LangChain 对与 LLMs 交互的流程进行了统一的抽象，同时也提供了不同 LLMs 的实现。这极大的提升了我们使用 LLMs 的效率。\n序列化：LangChain 提供的序列化的能力，可以将提示词、chain等以文件的形式而不是以代码的形式进行存储，这样可以极大的方便我们共享 提示词，并对 提示词 进行版本管理。4\n丰富的 chains 套件：LangChain 提供了丰富、用于完成特定目的、开箱即用的 chains 套件，例如用于总结文档的 StuffDocumentsChain 和 MapReduceDocumentsChain，这些套件将会降低我们使用 LLMs 的门槛。\n\n更具体的， LangChain 可以在如下的 6 大方向上给我们提供非常大的便利：\n\nLLMs & Prompt：LangChain 提供了目前市面上几乎所有 LLM 的通用接口，同时还提供了 提示词 的管理和优化能力，同时也提供了非常多的相关适用工具，以方便开发人员利用 LangChain 与 LLMs 进行交互。\nChains：LangChain 把 提示词、大语言模型、结果解析 封装成 Chain，并提供标准的接口，以便允许不同的 Chain 形成交互序列，为 AI 原生应用提供了端到端的 Chain。\nData Augemented Generation5：数据增强生成式 是一种解决预训练语料数据无法及时更新而带来的回答内容陈旧的方式。LangChain 提供了支持 数据增强生成式 的 Chain，在使用时，这些 Chain 会首先与外部数据源进行交互以获得对应数据，然后再利用获得的数据与 LLMs 进行交互。典型的应用场景如：基于特定数据源的问答机器人。\nAgent：对于一个任务，代理 主要涉及让 LLMs 来对任务进行拆分、执行该行动、并观察执行结果，代理 会重复执行这个过程，直到该任务完成为止。LangChain 为 代理 提供了标准接口，可供选择的代理，以及一些端到端的 代理 的示例。\nMemory：内存 指的是 chain 或 agent 调用之间的状态持久化。LangChain 为 内存 提供了标准接口，并提供了一系列的 内存 实现。\nEvaluation：LangChain 还提供了非常多的评估能力以允许我们可以更方便的对 LLMs 进行评估。\n\n\n\n\n\n\n\nLangChain 安装\n\n\n\nLangChain 的安装可以参见 附录 B。"
  },
  {
    "objectID": "langchain_intro.html#langchain-的基本概念",
    "href": "langchain_intro.html#langchain-的基本概念",
    "title": "10  LangChain 简介",
    "section": "10.2 LangChain 的基本概念",
    "text": "10.2 LangChain 的基本概念\n使用 LLMs 和使用电脑一样，需要一些基本的架构体系。LangChain 把整体架构体系分为两部分：输入/输出系统，大语言模型。其中，输入部分为 Prompt 相关组件，输出为 Output Parser 相关组件。具体参见 图 10.3。\n\n\n\n图 10.3: LangChain I/O\n\n\nLangChain 提供了与 LLMs 交互的通用构件：\n\nPrompts：提示词模版，提示词动态选择，提示词序列化。\nLLMs：与 LLM 交互的通用接口。\nOutput Parsers：对模型的输出信息进行解析，以输出符合特定格式的响应。\n\n\n\n\n图 10.4: LangChain I/O 示例\n\n\n\n10.2.1 Prompt Templates\n提示词模版为不同的提示词提供预定义格式。就好像目前超市售卖的洗净切好、配好相关配菜源材料的预制菜一样，提示词模版可以简化我们和 LLMs 交互的效率。\n模版会包含：指令，少量的样本示例，相关的上下文信息。如 章节 10.2.2 所述，LLMs 会分为 大语言模型 和 聊天模型 两种类型，因此，LangChain 提供了两种类型的提示词模版：prompt template、chat prompt template。\n\nprompt template：提供字符串格式的提示词。\nchat prompt template：提示聊天消息格式的提示词。\n\n\n列表 10.1: PromptTemplte 示例\nfrom langchain import PromptTemplate\n\nprompt_template = PromptTemplate.from_template(\n    \"请以轻松欢快的语气写一篇描写 {topic} 的文章，字数不超过 {count} 字。\"\n)\nres = prompt_template.format(topic=\"北京的秋天\", count=\"100\")\n\nprint(res)\n# 请以轻松欢快的语气写一篇描写 北京的秋天 的文章，字数不超过 100 字。\n\n\n列表 10.2: ChatPromptTemplte 示例\nfrom langchain.prompts import ChatPromptTemplate\n\ntemplate = ChatPromptTemplate.from_messages([\n    (\"system\", \"你是一个能力非凡的人工智能机器人，你的名字是 {name}。\"),\n    (\"human\", \"你好！\"),\n    (\"ai\", \"你好~\"),\n    (\"human\", \"{user_input}\"),\n])\n\nmessages = template.format_messages(\n    name=\"小明\",\n    user_input=\"你是谁？\"\n)\n\nprint(messages)\n# [SystemMessage(content='你是一个能力非凡的人工智能机器人，你的名字是 小明。', \n#                additional_kwargs={}), \n# HumanMessage(content='你好！', additional_kwargs={}, example=False), \n# AIMessage(content='你好~', additional_kwargs={}, example=False), \n# HumanMessage(content='你是谁？', additional_kwargs={}, example=False)]\n\n\n\n10.2.2 LLMs\nLangChain 提供了两种模型的通用接口：\n\nLLMs：模型以字符串格式的提示词作为输入，并返回字符串格式的结果。\nChat models：其背后也是由某种 LLM 来支撑，但是以聊天消息列表格式的提示词作为输入，并返回聊天消息格式的结果。\n\n\n\n\n\n\n\nLLMs & Chat Models\n\n\n\nLLM 和 聊天模式 之间的区别虽然很微妙，但是却完全不同。\nLangChain 中的 LLM 指的是纯文本 I/O 的模型，其包装的 API 将字符串提示作为输入，并输出字符串。OpenAI 的 GPT-3 就是 LLM。\n聊天模型通常由 LLM 支持，但专门针对对话进行了调整，其 API 采用聊天消息列表作为输入，而不是单个字符串。通常，这些消息都标有角色（例如，“System”，“AI”，“Human”）。聊天模型会返回一条 AI 聊天消息作为输出。OpenAI 的 GPT-4，Anthropic 的 Claude，百度的 Ernie-Bot 都是聊天模型。\n\n\n在 LangChain 中，LLM 和 聊天模式两者都实现了 BaseLanguageModel 接口，因此一般情况下，这两种模型可以混用。例如，两种模型都实现了常见的方法 predict() 和 predict_messages()。predict() 接受字符串并返回字符串，predict_messages() 接受消息并返回消息。\n\n列表 10.3: LLM 模式\nclass OpenAI(BaseOpenAI):\n    # ...\n\nclass BaseOpenAI(BaseLLM):\n    # ...\n\nclass BaseLLM(BaseLanguageModel[str], ABC):\n    # ...\n\n\n列表 10.4: 聊天模型\nclass ErnieBotChat(BaseChatModel):\n    # ...\n\nclass BaseChatModel(BaseLanguageModel[BaseMessageChunk], ABC):\n    # ...\n\n接下来，我们将 Prompt 和 LLM 整合起来，实现和大语言模型交互。\n\n列表 10.5: LLM 模型示例\nfrom langchain import PromptTemplate\nfrom langchain.llms import OpenAI\n\nprompt_template = PromptTemplate.from_template(\n    \"请以轻松欢快的语气写一篇描写 {topic} 的文章，字数不超过 {count} 字。\"\n)\nllm = OpenAI()\n\nprompt = prompt_template.format(topic=\"北京的秋天\", count=\"100\")\nres = llm.predict(prompt)\nprint(res)\n\n# 秋天来到了北京，一片金黄色的枫叶，漫山遍野。\n# 湖面上的微风，吹起柔和的秋意，空气中弥漫着淡淡的枫香。\n# 这时，每一个角落都洋溢着秋日的温馨，令人心旷神怡。\n# 古老的长城上披着红叶，熙熙攘攘的人群中，也多了几分热闹与欢畅，这就是北京的秋天\n\n由于文心聊天模型对 message 角色和条数有限制6 7，因此我们需要对 提示词 做一些修改。\n\n列表 10.6: 聊天模型示例\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.prompts import ChatPromptTemplate\n\ntemplate = ChatPromptTemplate.from_messages([\n    (\"user\", \"你是一个能力非凡的人工智能机器人，你的名字是 {name}。\"),\n    (\"assistant\", \"你好~\"),\n    (\"user\", \"{user_input}\"),\n])\nchat = ErnieBotChat()\n\nmessages = template.format_messages(\n    name=\"小明\",\n    user_input=\"你是谁？\"\n)\n\nres = chat.predict_messages(messages)\nprint(res)\n# content='我是你的新朋友小明，一个拥有先进人工智能技术的人工智能机器人。' \n# additional_kwargs={} example=False\n\n\n文心 4.0\n在 LangChain 中，要使用 文心 4.0 模型，可以在初始化 LLM 时设置 model_name 参数为 ERNIE-Bot-4。\nllm = ErnieBotChat(model_name=\"ERNIE-Bot-4\")\n\n\n\n10.2.3 Output Parsers\n大语言模型一般会输出文本内容作为响应，当然更高级的大语言模型（例如文心大模型）还可以输出图片、视频作为响应。但是，很多时候，我们希望可以获得更结构化的信息，而不仅仅是回复一串字符串文本。\n我们可以使用 提示词工程 来提示 LLMs 输出特定的格式，如 列表 10.7 所示：\n\n列表 10.7: 使用提示词工程来格式化输出内容\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.prompts import ChatPromptTemplate\n\ntemplate = ChatPromptTemplate.from_messages([\n    (\"user\", \"你是一个能力非凡的人工智能机器人，你的名字是 {name}。\"),\n    (\"assistant\", \"你好~\"),\n    (\"user\", \"{user_input}\"),\n])\nchat = ErnieBotChat()\n\nmessages = template.format_messages(\n    name=\"小明\",\n    user_input=\"请给出 10 个表示快乐的成语，并输出为 JSON 格式\"\n)\n\nres = chat.predict_messages(messages)\nprint(res)\n\n# content='```json\\n[\\n    \"乐不可支\",\n#                    \\n    \"喜从天降\",\n#                    \\n    \"笑逐颜开\",\n#                    \\n    \"手舞足蹈\",\n#                     ......\n#                    \\n    \"弹冠相庆\"\\n]\\n```' \n# additional_kwargs={} example=False\n\n但是，使用 LangChain 提供的 Output Parsers 能力，会更加的方便。\n\n列表 10.8: 使用 Output Parser 解析 LLM 结果\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.output_parsers import CommaSeparatedListOutputParser\n\ntemplate = ChatPromptTemplate.from_messages([\n    (\"user\", \"你是一个能力非凡的人工智能机器人，你的名字是 {name}。\"),\n    (\"assistant\", \"你好~\"),\n    (\"user\", \"{user_input}\"),\n])\nchat = ErnieBotChat()\n\nmessages = template.format_messages(\n    name=\"小明\",\n    user_input=\"请仅给5个表示快乐的成语并以 , 分隔，除了成语外不要输出任何其他内容\"\n)\n\nres = chat.predict_messages(messages)\nprint(res)\n# content='欢呼雀跃，手舞足蹈，笑逐颜开，心花怒放，喜笑颜开' additional_kwargs={} example=False\n\noutput_parser = CommaSeparatedListOutputParser()\nres =  output_parser.parse(res.content.replace('，', ', '))\nprint(res)\n# ['欢呼雀跃', '手舞足蹈', '笑逐颜开', '心花怒放', '喜笑颜开']\n\n\n\n\n\n\n\n警告\n\n\n\n由于文心大模型的指令遵循能力还有进一步提升的空间，因此这里的演示可能需要进行一些额外的操作，例如需要对模型返回的内容进行一些简单的字符串替换。\n2023 年 10 月 17 日，百度世界大会上发布了 文心 4.0，我们发现 文心 4.0 在 ICL、指令遵循、推理能力上都有比较大的提升。\n在 LangChain 中，要使用 文心 4.0 模型，可以在初始化 LLM 时设置 model_name 参数为 ERNIE-Bot-4。\nllm = ErnieBotChat(model_name=\"ERNIE-Bot-4\")\n\n\n\n\n10.2.4 LLMChain\n虽然一台独立的计算机也能实现很强大的功能，但是通过网络将更多的计算机链接起来，可能发挥出更大的性能。同样的，单独使用 LLMs 已经可以实现强大的功能，但是如果可以将更多次的交互有效的链接起来，则能发挥 LLMs 更大的能量。为了实现这个目标，LangChain 提供了 Chain 的概念，以实现对不同组件的一系列调用。\n在 LangChain 中，提示词、LLM、输出解析 这三者构成了 Chain，而不同的 Chain 则可以通过一定的方式链接起来，以实现强大的功能。具体如 图 10.5 所示。\n\n\n\n图 10.5: LangChain 中 Chain 的概念\n\n\n利用 Chain 的概念，我们可以对 列表 10.8 的代码进行重构，\n\n列表 10.9: 使用 chain 与文心大模型进行交互\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.output_parsers import CommaSeparatedListOutputParser\nfrom langchain.chains import LLMChain\n\ntemplate = ChatPromptTemplate.from_messages([\n    (\"user\", \"你是一个能力非凡的人工智能机器人，你的名字是 {name}。\"),\n    (\"assistant\", \"你好~\"),\n    (\"user\", \"{user_input}\"),\n])\nchat = ErnieBotChat()\n\nchain =  LLMChain(llm=chat, prompt=template, output_parser=CommaSeparatedListOutputParser())\n\nres =  chain.run(name=\"小明\", user_input=\"请仅给5个表示快乐的成语并以 , 分隔，除了成语外不要输出任何其他内容\")\n\nprint(res)\n# ['以下是五个表示快乐的成语：\\n\\n1. 喜出望外\\n2. 乐不可支\\n3. 心花怒放\\n4. 满心欢喜\\n5. 手舞足蹈']"
  },
  {
    "objectID": "langchain_intro.html#langchain-的学习资料",
    "href": "langchain_intro.html#langchain-的学习资料",
    "title": "10  LangChain 简介",
    "section": "10.3 LangChain 的学习资料",
    "text": "10.3 LangChain 的学习资料\n\nLangChain 官方文档：https://python.langchain.com/docs/get_started\nLangChain 的典型应用场景：https://python.langchain.com/docs/use_cases\nLangChain 目前集成的能力：https://python.langchain.com/docs/integrations\nLangChain AI Handbook：https://www.pinecone.io/learn/series/langchain/\nLangChain Dart：https://langchaindart.com/#/\n百度智能云千帆大模型平台：https://cloud.baidu.com/product/wenxinworkshop\nLangflow 官方文档：https://docs.langflow.org/"
  },
  {
    "objectID": "langchain_intro.html#参考文献",
    "href": "langchain_intro.html#参考文献",
    "title": "10  LangChain 简介",
    "section": "10.4 参考文献",
    "text": "10.4 参考文献"
  },
  {
    "objectID": "langchain_intro.html#footnotes",
    "href": "langchain_intro.html#footnotes",
    "title": "10  LangChain 简介",
    "section": "",
    "text": "LangChain 估值↩︎\nFFmpeg Filters Documentation↩︎\nLangChain Introdction↩︎\nPrompt Serialization↩︎\nA Complete Guide to Data Augmentation↩︎\nERNIE-Bot-turbo↩︎\n百度智能云千帆大模型平台↩︎"
  },
  {
    "objectID": "langchain_serialization.html#序列化",
    "href": "langchain_serialization.html#序列化",
    "title": "11  LangChain 序列化",
    "section": "11.1 序列化",
    "text": "11.1 序列化"
  },
  {
    "objectID": "langchain_serialization.html#langchain-hub",
    "href": "langchain_serialization.html#langchain-hub",
    "title": "11  LangChain 序列化",
    "section": "11.2 LangChain-Hub",
    "text": "11.2 LangChain-Hub"
  },
  {
    "objectID": "langchain_retrieval.html#document-loaders",
    "href": "langchain_retrieval.html#document-loaders",
    "title": "12  LangChain Retrieval",
    "section": "12.1 Document loaders",
    "text": "12.1 Document loaders\nLangChain 提供了100多种不同的文档加载器，并与该领域的其他主要供应商（如 AirByte、Unstructured）进行了集成，从而可以从任何地方（私有 s3 存储、网站）加载任何类型的文档（HTML、PDF、代码）。\n文档加载器提供了一个 load() 方法来从指定的加载源加载文档数据。文档加载器还提供了一个 lazy_load() 方法来实现现“延迟加载”，以避免一次将太多的数据加载到内存之中。\n\n列表 12.1: 加载远程网页\nfrom langchain.document_loaders.recursive_url_loader import RecursiveUrlLoader\n\nURL_ROOT = \"https://wangwei1237.github.io/\"\nloader = RecursiveUrlLoader(url=URL, max_depth=2)\ndocs = loader.load()\n\nprint(len(docs))\n\nURLS = []\nfor doc in docs:\n    url   =  doc.metadata[\"source\"]\n    title = doc.metadata[\"title\"]\n    print(url, \"-&gt;\", title)\n\n\n\n\n\n\n\n警告\n\n\n\nRecursiveUrlLoader() 对中文的抓取看起来不是非常友好，中文内容显示成了乱码。可以使用 列表 12.2 所示的方法来解决中文乱码的问题，不过这种方式的缺点是需要 load() 两次。更好的方式后续再思考。\n\n\n\n列表 12.2: 解决中文乱码的方法\nfrom langchain.document_loaders import WebBaseLoader\nfrom langchain.document_loaders.recursive_url_loader import RecursiveUrlLoader\n\nURL_ROOT = \"https://wangwei1237.github.io/\"\nloader = RecursiveUrlLoader(url=URL_ROOT, max_depth=2)\ndocs = loader.load()\n\nprint(len(docs))\n\nURLS = []\nfor doc in docs:\n    url   =  doc.metadata[\"source\"]\n    URLS.append(url)\n\nloader = WebBaseLoader(URLS)\ndocs = loader.load()\n\nprint(len(docs))\n\nfor doc in docs:\n    url   =  doc.metadata[\"source\"]\n    title =  doc.metadata[\"title\"]\n    print(url, \"-&gt;\", title)"
  },
  {
    "objectID": "langchain_retrieval.html#document-transformers",
    "href": "langchain_retrieval.html#document-transformers",
    "title": "12  LangChain Retrieval",
    "section": "12.2 Document transformers",
    "text": "12.2 Document transformers\n检索的一个关键部分是只获取文档的相关部分而非获取全部文档。为了为最终的检索提供最好的文档，我们需要对文档进行很多的转换，这里的主要方法之一是将一个大文档进行拆分。LangChain 提供了多种不同的拆分算法，并且还针对特定文档类型（代码、标记等）的拆分提供对应的优化逻辑。\n文档加载后，我们通常会对文档进行一系列的转换，以更好地适应我们的应用程序。最简单的文档转换的场景就是文档拆分成，以便可以满足模型的上下文窗口（不同模型的每次交互的最大 token 数可能不同）。\n尽管文档拆分听起来很简单，但实际应用中却有很多潜在的复杂性。理想情况下，我们希望将语义相关的文本片段放在一起。“语义相关”的含义会取决于文本的类型，例如：\n\n对于代码文件而言，我们需要将一个函数置于一个完整的拆分块中；\n普通的文本而言，可能需要将一个段落置于一个完整的拆分块中；\n……\n\n我们利用 RecursiveCharacterTextSplitter 对 列表 12.2 的文档进行拆分。\n\n列表 12.3: 使用 RecursiveCharacterTextSplitter 拆分文档\n# ...\n# ...\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 1000,\n    chunk_overlap  = 20,\n    length_function = len,\n    add_start_index = True,\n)\n\nfor doc in docs:\n    url   =  doc.metadata[\"source\"]\n    title =  doc.metadata[\"title\"]\n    print(url, \"--&gt;\", title)\n    texts = text_splitter.create_documents([doc.page_content])\n    print(texts)\n\nLangChain 也可以对不同的编程语言进行拆分，例如 cpp，go，markdown，……，具体支持的语言可以参见 列表 12.4。\n\n列表 12.4: LangChain 支持拆分的语言类型\nfrom langchain.text_splitter import Language\n\n[e.value for e in Language]\n\n#['cpp',\n# 'go',\n# 'java',\n# 'js',\n# 'php',\n# 'proto',\n# 'python',\n# 'rst',\n# 'ruby',\n# 'rust',\n# 'scala',\n# 'swift',\n# 'markdown',\n# 'latex',\n# 'html',\n# 'sol']"
  },
  {
    "objectID": "langchain_retrieval.html#text-embedding-models",
    "href": "langchain_retrieval.html#text-embedding-models",
    "title": "12  LangChain Retrieval",
    "section": "12.3 Text embedding models",
    "text": "12.3 Text embedding models\n检索的另一个关键部分是为文档创建其向量（embedding）表示。Embedding 捕获文本的语义信息，使我们能够快速、高效地查找其他相似的文本片段。LangChain 集成了 25 种不同的 embedding 供应商和方法，我们可以根据我们的具体需求从中进行选择。LangChain 还提供了一个标准接口，允许我们可以便捷的在不同的 embedding 之间进行交换。\n在 LangChain 中，Embeddings 类是用于文本向量模型的接口。目前，有很多的向量模型供应商，例如：OpenAI，Cohere，Hugging Face，……Embeddings 类的目的就是为所有这些向量模型提供统一的、标准的接口。\nEmbeddings 类可以为一段文本创建对应的向量表示，从而允许我们可以在向量空间中去考虑文本。在向量空间中，我们还可以执行语义搜索，从而允许我们在向量空间中检索最相似的文本片段。\n因为不同的向量模型供应商对文档和查询采用了不同的向量方法，Embeddings 提供了两个方法：\n\nembed_documents()：用于文档向量化\nembed_query()：用于查询向量化\n\n\n列表 12.5: 使用文心大模型的 Embedding-V1 查询向量化\nfrom langchain.embeddings import QianfanEmbeddingsEndpoint \n\nembeddings = QianfanEmbeddingsEndpoint()\nquery_result = embeddings.embed_query(\"你是谁？\")\nprint(query_result)\nprint(len(query_result))\n\n# [0.02949424833059311, -0.054236963391304016, -0.01735987327992916, \n#  0.06794580817222595, -0.00020318820315878838, 0.04264984279870987, \n#  -0.0661700889468193, ……\n# ……]\n# \n# 384\n\n\n列表 12.6: 使用文心大模型的 Embedding-V1 文档向量化\nfrom langchain.embeddings import QianfanEmbeddingsEndpoint \n\nembeddings = QianfanEmbeddingsEndpoint()\ndocs_result = embeddings.embed_documents([\n    \"你谁谁？\",\n    \"我是百度的智能助手，小度\"\n])\nprint(len(docs_result), \":\" , len(docs_result[0]))\n\n# 2 : 384\n\n\n\n\n\n\n\n使用 QianfanEmbeddingsEndpoint 的注意事项\n\n\n\nLangChain 在 0.0.300 版本之后才支持 QianfanEmbeddingsEndpoint，并且 QianfanEmbeddingsEndpoint 还依赖 qianfan python 库的支持。\n因此，在使用 QianfanEmbeddingsEndpoint 之前，需要：\n\n升级 LangChain 的版本：pip install -U langchain。\n安装 qianfan 库：pip install qianfan。"
  },
  {
    "objectID": "langchain_retrieval.html#vector-stores",
    "href": "langchain_retrieval.html#vector-stores",
    "title": "12  LangChain Retrieval",
    "section": "12.4 Vector stores",
    "text": "12.4 Vector stores\n为文档创建 embedding 之后，需要对其进行存储并实现对这些 embedding 的有效搜索，此时我们需要向量数据库的支持。LangChain 集成了 50 多种不同的向量数据库，还提供了一个标准接口，允许我们轻松的在不同的向量存储之间进行切换。\n\n\n\n图 12.2: 向量数据库检索的基本流程\n\n\n这里，我们使用 Milvus 向量数据库来进行相关的演示。Milvus 安装和使用方式可以参见：附录 C。\n利用 Milvus 对 列表 12.6 进行优化：\n\n列表 12.7: 使用 Milvus 存储千帆 Embedding-V1 的结果\nfrom langchain.document_loaders import WebBaseLoader\nfrom langchain.embeddings import QianfanEmbeddingsEndpoint\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import Milvus\n\nurl = 'https://wangwei1237.github.io/2023/02/13/duzhiliao/'\nloader = WebBaseLoader([url])\ndocs  = loader.load()\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 200,\n    chunk_overlap  = 20,\n    length_function = len,\n    add_start_index = True,\n)\ntexts = text_splitter.create_documents([docs[0].page_content])\n\nvector_db = Milvus.from_documents(\n    texts,\n    QianfanEmbeddingsEndpoint(),\n    connection_args ={\"host\": \"127.0.0.1\", \"port\": \"8081\"},\n)\n\nquery = \"什么是度知了？\"\ndocs = vector_db.similarity_search(query)\nprint(docs)\n\n列表 12.7 的运行结果中，之所以会有两条重复的结果，是因为在执行文档向量化的时候，执行了两遍。在初始化 Milvus 实例时，如果只是查询操作，可以使用如下的方式：\n\n列表 12.8: Milvus 实例初始化\nvector_db = Milvus.from_documents(\n    [],\n    QianfanEmbeddingsEndpoint(),\n    connection_args ={\"host\": \"127.0.0.1\", \"port\": \"8081\"},\n)\n\nMilvus.from_documents 会创建一个名为 LangChainCollection 的 Collection。可以使用 milvus_cli 工具来查看该 Collection 的信息，也可以使用 Milvus 提供的 http 端口来查看相关信息：\nhttp://127.0.0.1:8081/v1/vector/collections/describe?collectionName=LangChainCollection\n\n\n\n\n\n\n修改 Collection 名称\n\n\n\n为了方便使用，可以使用 collection_name 参数以实现将不同的专有数据源存储在不同的 Collection。\nvector_db = Milvus.from_documents(\n    texts,\n    QianfanEmbeddingsEndpoint(),\n    connection_args={\"host\": \"127.0.0.1\", \"port\": \"8081\"},\n1    collection_name=\"test\",\n)\n\n1\n\n设置数据存储的 Collection，类似于在关系数据库中，将数据存储在不同的表中。\n\n\n\n\n\n\n\n\n\n\n警告\n\n\n\n使用千帆进行 Embedding 时，每次 Embedding 的 token 是有长度限制的，目前的最大限制是 384 个 token。因此，我们在使用 RecursiveCharacterTextSplitter 进行文档拆分的时候要特别注意拆分后文档的长度。\nqianfan.errors.APIError: api return error, \ncode: 336003, \nmsg: embeddings max tokens per batch size is 384\n\n\n在使用时，为了方便，我们可以把 embedding 和 query 拆分为两个部分：\n\n先将数据源进行向量化，然后存储到 Milvus 中\n检索的时候，直接从 Milvus 中检索相关信息\n\n对 列表 12.6 的代码进行优化：\n\n列表 12.9: 文档向量化后存入 Milvus\n#encoding: utf-8\n\n\"\"\"\n@discribe: example for milvus embedding \n@author: wangwei1237@gmail.com\n\"\"\"\n\nfrom langchain.document_loaders import WebBaseLoader\nfrom langchain.document_loaders.recursive_url_loader import RecursiveUrlLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.document_loaders import WebBaseLoader\nfrom langchain.embeddings import QianfanEmbeddingsEndpoint\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import Milvus\nimport time\n\nURL_ROOT = \"https://wangwei1237.github.io/2023/02/13/duzhiliao/\"\nloader = RecursiveUrlLoader(url=URL_ROOT, max_depth=2)\ndocs = loader.load()\n\nURLS = []\nfor doc in docs:\n    url   =  doc.metadata[\"source\"]\n    URLS.append(url)\n\nprint(\"URLS length: \", len(URLS))\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 200,\n    chunk_overlap  = 20,\n    length_function = len,\n    add_start_index = True,\n)\n\nfor url in URLS:\n    print('-------------', url, '----------------')\n    loader = WebBaseLoader([url])\n    doc = loader.load()\n    texts = text_splitter.split_documents(doc)\n    vector_db = Milvus.from_documents(\n        texts,\n        QianfanEmbeddingsEndpoint(),\n        connection_args ={\"host\": \"127.0.0.1\", \"port\": \"8081\"},\n    )\n    print(\"    . insert \", len(texts), \" texts embeddings successful\")\n    time.sleep(5)\n\n检索相似内容的代码可以简化为：\n\n列表 12.10: 内容检索\n#encoding: utf-8\n\n\"\"\"\n@discribe: example for milvus embedding query\n@author: wangwei1237@gmail.com\n\"\"\"\n\nfrom langchain.embeddings import QianfanEmbeddingsEndpoint\nfrom langchain.vectorstores import Milvus\n\nvector_db = Milvus.from_documents(\n    [],\n    QianfanEmbeddingsEndpoint(),\n    connection_args ={\"host\": \"127.0.0.1\", \"port\": \"8081\"},\n)\n\nquery = \"什么是 RD曲线？\"\ndocs = vector_db.similarity_search(query)\nprint(docs)\n\n\n\n\n\n\n\n\n警告\n\n\n\n因为千帆向量化的 API 有 QPS 限制，因此，在使用千帆进行 embedding 时尽量控制一下 QPS。"
  },
  {
    "objectID": "langchain_retrieval.html#retrivers",
    "href": "langchain_retrieval.html#retrivers",
    "title": "12  LangChain Retrieval",
    "section": "12.5 Retrivers",
    "text": "12.5 Retrivers\n检索是 LangChain 花费精力最大的环节，LangChain 提供了许多不同的检索算法，LangChain 不但支持简单的语义检索，而且还增加了很多算法以提高语义检索的性能。\n一旦我们准备好了相关的数据，并且将这些数据存储到向量数据库（例如 Milvus），我们就可以配置一个 chain，并在 提示词 中包含这些相关数据，以便 LLM 在回答我们的问题时可以利用这些数据作为参考。\n对于参考外部数据源的 QA 而言，LangChain 提供了 4 种 chain：stuff，map_reduce，refine，map_rerank。stuff chain 把文档作为整体包含到 提示词 中，这只适用于小型文档。由于大多数 LLM 对 提示次 可以包含的 token 最大数量存在限制，因此建议使用其他三种类型的 chain。对于非 stuff chain，LangChain 将输入文档分割成更小的部分，并以不同的方式将它们提供给 LLM。这 4 种 chain 的具体信息和区别可以参见：docs/modules/chains/document。\n我们利用 QAWithSourcesChain 对 列表 12.10 进行优化，以实现一个完整的利用外部数据源的 Retrival Augment Generation（需要配合 列表 12.9）。\n\n列表 12.11: 基于 LangChain 和 Milvus 的 RAG\n#encoding: utf-8\n\n\"\"\"\n@discribe: example for RAG \n@author: wangwei1237@gmail.com\n\"\"\"\n\nfrom langchain.chains.qa_with_sources import load_qa_with_sources_chain\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.embeddings import QianfanEmbeddingsEndpoint\nfrom langchain.vectorstores import Milvus\n\nllm = ErnieBotChat()\nchain = load_qa_with_sources_chain(llm=llm, chain_type=\"refine\", return_intermediate_steps=True)\n\nquery = \"什么是度知了?\"\nvector_db = Milvus.from_documents(\n    [],\n    QianfanEmbeddingsEndpoint(),\n    connection_args ={\"host\": \"127.0.0.1\", \"port\": \"8081\"},\n)\n\ndocs = vector_db.similarity_search(query)\nprint(len(docs))\n\nres = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)\nprint(res)\n\n\n列表 12.11 的运行结果如下，结果包括 intermediate_steps 和 output_text：\n\nintermediate_steps 表示搜索过程中所指的文档\noutput_text 表示是问题的最终答案\n\n4\n\n{'intermediate_steps': \n    [\n        '根据提供的上下文信息，回答问题：\\n\\n「度知了」是一个在线问答平台，使用指南是由作者严丽编写的。该平台供了一个问答系统，用户可以在其中提出问题和获取答案。「度知了」的目的是帮助用户更好地理解和掌握知识，并提供了一个方便的途径来获取所需的信息。', \n        '根据提供的上下文信息，「度知了」是一个在线问答平台，使用指南是由作者严丽编写的。该平台提供了一个问答系统，用户可以在其中提出问题和获取答案。「度知了」的目的是帮助用户更好地理解和掌握知识，并提供了一个方便的途径来获取所需的信息。度知了基于ITU标准，依托自研的10+项专利技术，在不断实践的基础之上而形成的一款支持多端（PC，Android，iOS）评测的视频画质评测服务。\\n\\n因此，「度知了」是一个在线问答平台，提供视频画质评测服务。', \n        '根据提供的上下文信息，「度知了」是一个在线问答平台，提供视频画质评测服务。它基于ITU标准，依托自研的10+项专利技术，支持多端（PC，Android，iOS）评测。该平台旨在帮助用户更好地理解和掌握知识，并提供了一个方便的途径来获取所需的信息。「度知了」已上架各大商店应用市场，安卓端可通过华为应用商店、百度手机助手、小米应用商店、oppo应用商店、vivo应用商店直接搜索「度知了」进行安装。在APP端，用户可以通过快捷创建创建一个评测任务。', \n        \"Based on the new context, the existing answer is still accurate. The 'duzhiliao' in the original answer refers to the online platform 'Du Zhili', which provides video quality evaluation services. It is a multi-platform application (PC, Android, iOS) that uses 10+ self-developed patent technologies based on ITU standards to help users better understand and master knowledge, and provide a convenient way to obtain needed information. The platform has been uploaded to various store application markets, and users can install it through search for 'Du Zhili' on Huawei App Store, Baidu App Store, Xiaomi App Store, OPPO App Store, Vivo App Store. In the app, users can quickly create a review task.\"\n    ], \n    'output_text': \"Based on the new context, the existing answer is still accurate. The 'duzhiliao' in the original answer refers to the online platform 'Du Zhili', which provides video quality evaluation services. It is a multi-platform application (PC, Android, iOS) that uses 10+ self-developed patent technologies based on ITU standards to help users better understand and master knowledge, and provide a convenient way to obtain needed information. The platform has been uploaded to various store application markets, and users can install it through search for 'Du Zhili' on Huawei App Store, Baidu App Store, Xiaomi App Store, OPPO App Store, Vivo App Store. In the app, users can quickly create a review task.\"\n}\n为了显示 RAG 的优点，我们可以利用 列表 10.9 所示的代码向 LLM 问同样的问题：\nres =  chain.run(name=\"小明\", user_input=\"什么是度知了?\")\nprint(res)\n\n# ['度知了是一款智能问答产品，它能够理解并回答问题，提供信息和建议，主要应用在搜索、智能问答、智能语音交互等领域。\\n\\n度知了运用了文心大模型的能力，涵盖了海量数据，可以更好地理解和回答各种各样的问题。文心大模型是中国的一个大规模语言模型，它可以用于各种自然语言处理任务，包括文本分类、问答、文本摘要等。']"
  },
  {
    "objectID": "langchain_retrieval.html#retrievalqa",
    "href": "langchain_retrieval.html#retrievalqa",
    "title": "12  LangChain Retrieval",
    "section": "12.6 RetrievalQA",
    "text": "12.6 RetrievalQA\n使用 RetrievalQA 也可以实现 列表 12.11 同样的功能，并且代码整体会更简洁。\n\n列表 12.12: 基于 RetrievalQA 和 Milvus 的 RAG\n#encoding: utf-8\n\n\"\"\"\n@discribe: example for RetrivalQA.\n@author: wangwei1237@gmail.com\n\"\"\"\n\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.embeddings import QianfanEmbeddingsEndpoint\nfrom langchain.vectorstores import Milvus\nfrom langchain.chains import RetrievalQA\nfrom langchain.vectorstores.base import VectorStoreRetriever\nfrom retrieval_prompt import PROMPT_SELECTOR\n\nretriever = VectorStoreRetriever(vectorstore=Milvus(embedding_function=QianfanEmbeddingsEndpoint(),\n1                                                    connection_args={\"host\": \"127.0.0.1\", \"port\": \"8081\"}))\n\nllm = ErnieBotChat()\n2prompt = PROMPT_SELECTOR.get_prompt(llm)\n3retrievalQA = RetrievalQA.from_llm(llm=llm, prompt=prompt, retriever=retriever)\n\nquery = \"什么是度知了?\"\n\n4res = retrievalQA.run(query)\nprint(res)\n\n\n1\n\n使用 Milvus 初始化向量检索器\n\n2\n\n因为文心对 MessageList 的限制，所以此处要重写 Prompt，否则执行时会报 Message 类型错误。具体提示词的修改可以参考：列表 12.13。\n\n3\n\n使用向量检索器初始化 RetrievalQA 实例\n\n4\n\n执行 RAG 检索并提炼最终结果\n\n\n\n列表 12.13: RetrievalQA 的提示词\n# flake8: noqa\n\n\"\"\"\n@discribe: prompt for test_retrievalQA.py.\n@author: wangwei1237@gmail.com\n\"\"\"\n\nfrom langchain.chains.prompt_selector import ConditionalPromptSelector, is_chat_model\nfrom langchain.prompts import PromptTemplate\nfrom langchain.prompts.chat import (\n    ChatPromptTemplate,\n    HumanMessagePromptTemplate,\n    AIMessagePromptTemplate,\n)\n\nprompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\n{context}\n\nQuestion: {question}\nHelpful Answer:\"\"\"\nPROMPT = PromptTemplate(\n    template=prompt_template, input_variables=[\"context\", \"question\"]\n)\n\nsystem_template = \"\"\"Use the following pieces of context to answer the users question. \nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\n----------------\n{context}\"\"\"\nmessages = [\n1    HumanMessagePromptTemplate.from_template(system_template),\n2    AIMessagePromptTemplate.from_template(\"OK!\"),\n    HumanMessagePromptTemplate.from_template(\"{question}\"),\n]\nCHAT_PROMPT = ChatPromptTemplate.from_messages(messages)\n\n\nPROMPT_SELECTOR = ConditionalPromptSelector(\n    default_prompt=PROMPT, conditionals=[(is_chat_model, CHAT_PROMPT)]\n)\n\n\n1\n\n修改 SystemMessagePromptTemplate 为 HumanMessagePromptTemplate。\n\n2\n\n增加一条 AIMessagePromptTemplate 消息。\n\n\n列表 12.12 的运行结果如下所示：\n度知了是一款视频画质评测服务，基于ITU标准，依托自研的10+项专利技术，支持多端（PC、Android、iOS）评测，提供画质评测工具。"
  },
  {
    "objectID": "langchain_function_call.html#大模型的时效性",
    "href": "langchain_function_call.html#大模型的时效性",
    "title": "13  LangChain 函数调用",
    "section": "13.1 大模型的时效性",
    "text": "13.1 大模型的时效性\n当我们问大模型“明天天气怎么样”时，因为大模型训练语料的时效性问题，如果不依赖外部信息，大模型是很难回答这种问题的，如 图 13.1 所示。\n\n\n\n\n\n\n\n(a) ChatGPT\n\n\n\n\n\n\n\n(b) 文心一言\n\n\n\n\n图 13.1: 明天天气怎么样？\n\n\n而 OpenAI 大语言模型提供的 函数调用 能力，恰恰非常完美的解决了类似的问题，从而使得大语言模型可以通过 函数调用 与外部系统通信，并获取更实时的信息，以解决类似的问题。"
  },
  {
    "objectID": "langchain_function_call.html#函数调用流程",
    "href": "langchain_function_call.html#函数调用流程",
    "title": "13  LangChain 函数调用",
    "section": "13.2 函数调用流程",
    "text": "13.2 函数调用流程\nOpenAI 开发的大语言模型（例如GPT-3.5-turbo-0613，GPT-4-0613）提供了一种名为 Function Calling(函数调用) 的创新功能。函数调用 使得开发人员能够在模型中对函数进行描述，然后模型可以利用这些描述来巧妙地为函数生成调用参数。\n在 OpenAI 中，函数调用的步骤可以参考：图 13.2\n\n\n\n图 13.2: OpenAI 的函数调用流程\n\n\n\n\n\n\n\n\n注意\n\n\n\n需要特别注意的是，大语言模型本身并不会调用我们预定的 函数，大语言模型仅仅是生成我们所要调用的函数的调用参数而言，具体调用函数的动作，需要我们在自己的应用代码中来实现。2\n\n\n\n\n\n\n\n\n思考\n\n\n\n为什么模型不能直接调用函数？\n\n\n利用 函数调用，LLMs 可以很方便的将自然语言指令转变为相关的函数调用，例如：可以把“给张三发一封邮件询问下他下周五下午是否需要一杯咖啡” 这样的提示转换为 send_email(to: string, body: string) 函数调用。"
  },
  {
    "objectID": "langchain_function_call.html#openai-函数调用",
    "href": "langchain_function_call.html#openai-函数调用",
    "title": "13  LangChain 函数调用",
    "section": "13.3 OpenAI 函数调用",
    "text": "13.3 OpenAI 函数调用\n\n13.3.1 OpenAI API\n\n列表 13.1: 使用 OpenAI API 进行函数调用示例\nimport openai\nimport json\n\n# Example dummy function hard coded to return the same weather\n# In production, this could be your backend API or an external API\ndef get_current_weather(location, unit=\"celsius\"):\n    \"\"\"Get the current weather in a given location\"\"\"\n    weather_info = {\n        \"location\": location,\n        \"temperature\": \"27\",\n        \"unit\": unit,\n        \"forecast\": [\"sunny\", \"windy\"],\n    }\n    return json.dumps(weather_info)\n\ndef run_conversation():\n    # Step 1: send the conversation and available functions to GPT\n    messages = [{\"role\": \"user\", \"content\": \"北京明天天气怎么样?\"}]\n    functions = [\n        {\n            \"name\": \"get_current_weather\",\n            \"description\": \"Get the current weather in a given location\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\n                        \"type\": \"string\",\n                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n                    },\n                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n                },\n                \"required\": [\"location\"],\n            },\n        }\n    ]\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo-0613\",\n        messages=messages,\n        functions=functions,\n        function_call=\"auto\",  # auto is default, but we'll be explicit\n    )\n\n    print(\"---------step 1. the 1st LLMs response-----------\")\n    print(response)\n\n    response_message = response[\"choices\"][0][\"message\"]\n\n    # Step 2: check if GPT wanted to call a function\n    if response_message.get(\"function_call\"):\n        # Step 3: call the function\n        # Note: the JSON response may not always be valid; be sure to handle errors\n        available_functions = {\n            \"get_current_weather\": get_current_weather,\n        }  # only one function in this example, but you can have multiple\n        function_name = response_message[\"function_call\"][\"name\"]\n        fuction_to_call = available_functions[function_name]\n        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n        function_response = fuction_to_call(\n            location=function_args.get(\"location\"),\n            #unit=function_args.get(\"unit\"),\n        )\n\n        print(\"---------step 2. function response-----------\")\n        print(function_response)\n\n        # Step 4: send the info on the function call and function response to GPT\n        messages.append(response_message)  # extend conversation with assistant's reply\n        messages.append(\n            {\n                \"role\": \"function\",\n                \"name\": function_name,\n                \"content\": function_response,\n            }\n        )  # extend conversation with function response\n\n        print(\"---------step 3. final messages-----------\")\n        print(messages)\n\n        second_response = openai.ChatCompletion.create(\n            model=\"gpt-3.5-turbo-0613\",\n            messages=messages,\n        )  # get a new response from GPT where it can see the function response\n        return second_response\n\nres = run_conversation()\nprint(\"---------step 4. final LLMs response-----------\")\nprint(res)\n\n列表 13.1 的运行结果如 列表 13.2：\n\n列表 13.2: 运行结果\n---------step 1. the 1st LLMs response-----------\n{\n  \"id\": \"chatcmpl-7xnsEW2rSsec7Qd1FC60cKIT7TtuR\",\n  \"object\": \"chat.completion\",\n  \"created\": 1694487422,\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": null,\n        \"function_call\": {\n          \"name\": \"get_current_weather\",\n          \"arguments\": \"{\\n  \\\"location\\\": \\\"北京\\\"\\n}\"\n        }\n      },\n      \"finish_reason\": \"function_call\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 85,\n    \"completion_tokens\": 16,\n    \"total_tokens\": 101\n  }\n}\n---------step 2. function response-----------\n{\"location\": \"北京\", \"temperature\": \"27\", \"unit\": null, \"forecast\": [\"sunny\", \"windy\"]}\n---------step 3. final messages-----------\n[{'role': 'user', 'content': '北京明天天气怎么样?'}, &lt;OpenAIObject at 0x1082907c0&gt; JSON: {\n  \"role\": \"assistant\",\n  \"content\": null,\n  \"function_call\": {\n    \"name\": \"get_current_weather\",\n    \"arguments\": \"{\\n  \\\"location\\\": \\\"北京\\\"\\n}\"\n  }\n}, {'role': 'function', 'name': 'get_current_weather', 'content': '{\"location\": \"\\\\u5317\\\\u4eac\", \"temperature\": \"27\", \"unit\": null, \"forecast\": [\"sunny\", \"windy\"]}'}]\n---------step 4. final LLMs response-----------\n{\n  \"id\": \"chatcmpl-7xnsFw2dssMs3R0aGVMmjB0cjLugZ\",\n  \"object\": \"chat.completion\",\n  \"created\": 1694487423,\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"北京明天的天气预报是晴天，有很大的风。气温为27°C。\"\n      },\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 77,\n    \"completion_tokens\": 30,\n    \"total_tokens\": 107\n  }\n}\n\n\n\n13.3.2 OpenAI 函数调用 LLMChain\n可以参考 LangChain 官方文档以在 LangChain 中使用 OpenAI 函数调用 的能力。3\n\n列表 13.3: 使用 LangChain 实现函数调用\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.chains.openai_functions import (\n    create_openai_fn_chain,\n)\nfrom langchain.chains import LLMChain\nimport json\n\ndef get_current_weather(location: str, unit: str=\"celsius\") -&gt; str:\n    \"\"\"Get the current weather in a given location\n\n    Args:\n        location (str): location of the weather.\n        unit (str): unit of the tempuature.\n    \n    Returns:\n        str: weather in the given location.\n    \"\"\"\n\n    weather_info = {\n        \"location\": location,\n        \"temperature\": \"27\",\n        \"unit\": unit,\n        \"forecast\": [\"sunny\", \"windy\"],\n    }\n    return json.dumps(weather_info)\n\nllm = ChatOpenAI(model=\"gpt-3.5-turbo-0613\")\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"human\", \"{query}\"),\n    ]\n)\n\nchain = create_openai_fn_chain([get_current_weather], llm, prompt, verbose=True)\nres = chain.run(\"What's the weather like in Beijing tomorrow?\")\nprint(\"-------------The 1-st langchain result-------------\")\nprint(res)\n\nres_func = get_current_weather(res['location'])\n\nchain = LLMChain(llm=llm, prompt=prompt, verbose=True)\nres = chain.run(\"extract the tomorrow weather infomation from ：%s， and answer the question: %s\" % (res_func, \"What's the weather like in Beijing tomorrow?\"))\nprint(res)\n\n列表 13.3 的运行结果如下所示：\n\n列表 13.4: 运行结果\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nHuman: What's the weather like in Beijing tomorrow?\n\n&gt; Finished chain.\n-------------The 1-st langchain result-------------\n{'location': 'Beijing', 'unit': 'metric'}\n\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nHuman: extract the tomorrow weather infomation from ：{\"location\": \"Beijing\", \"temperature\": \"27\", \"unit\": \"celsius\", \"forecast\": [\"sunny\", \"windy\"]}， and answer the question: What's the weather like in Beijing tomorrow?\n\n&gt; Finished chain.\nThe weather in Beijing tomorrow is sunny and windy.\n\n\n\n\n\n\n\n注释\n\n\n\n在 create_openai_fn_chain 中，其第一个参数是一个函数列表，如果该列表只有 1 个函数时，则 create_openai_fn_chain 仅会返回大语言模型构造的调用该函数对应的参数。例如如上的例子，create_openai_fn_chain 仅返回了 {'location': 'Beijing', 'unit': 'metric'}。 而如果函数列表存在多个函数时，则会返回大语言模型分析之后所需要调用的函数名以及对应的参数，例如： {'name': 'get_current_weather', 'arguments': {'location': 'Beijing'}}。\n\n\n\n列表 13.5: create_openai_fn_chain() 传递多个函数调用示例\n# ...\ndef get_current_news(location: str) -&gt; str:\n    \"\"\"Get the current news based on the location.'\n\n    Args:\n        location (str): The location to query.\n    \n    Returs:\n        str: Current news based on the location.\n    \"\"\"\n\n    news_info = {\n        \"location\": location,\n        \"news\": [\n            \"I have a Book.\",\n            \"It's a nice day, today.\"\n        ]\n    }\n\n    return json.dumps(news_info)\n# ...\n\nchain = create_openai_fn_chain([get_current_weather, get_current_news], llm, prompt, verbose=True)\nres = chain.run(\"What's the weather like in Beijing tomorrow?\")\nprint(\"-------------The 1-st langchain result-------------\")\nprint(res)\n\n列表 13.5 的运行结果如 列表 13.6 所示：\n\n列表 13.6: 运行结果\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nHuman: What's the weather like in Beijing tomorrow?\n\n&gt; Finished chain.\n-------------The 1-st langchain result-------------\n{'name': 'get_current_weather', 'arguments': {'location': 'Beijing'}}"
  },
  {
    "objectID": "langchain_function_call.html#文心-4.0-函数调用",
    "href": "langchain_function_call.html#文心-4.0-函数调用",
    "title": "13  LangChain 函数调用",
    "section": "13.4 文心 4.0 函数调用",
    "text": "13.4 文心 4.0 函数调用\n\n13.4.1 文心 API\n在使用 文心 4.0 的函数调用之前，首先需要安装 qianfan 库：\npip install qianfan\n我们首先对本章前面提到的 get_current_news 和 get_current_weather 这两个函数实现其 JSON-Schema 描述：\n\n列表 13.7: 待调用函数的函数描述\nfunctions = [\n    {\n        \"name\": \"get_current_news\",\n        \"description\": \"Get the current news based on the location.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n                },\n            },\n            \"required\": [\"location\"],\n        },\n        \"responses\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"news\": {\n                    \"type\": \"string\",\n                    \"description\": \"The current news based on the location.\",\n                }\n            }\n        }\n    },\n    {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n                },\n                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n            },\n            \"required\": [\"location\"],\n        },\n        \"responses\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"temperature\": {\n                    \"type\": \"string\",\n                    \"description\": \"The temperature in the given location.\",\n                }\n            }\n        }\n    },\n]\n\n\n列表 13.8: 使用千帆 API 实现文心大模型的函数调用\nimport qianfan\n\nchat_comp = qianfan.ChatCompletion()\n\n1resp = chat_comp.do(model=\"ERNIE-Bot-4\",\n2                    messages=[{\"role\": \"user\", \"content\": \"北京的新闻是什么？\"}],\n3                    functions=functions)\n \nprint(resp)\n\n\n1\n\n指定采用的模型名称\n\n2\n\n和大模型交互的消息列表\n\n3\n\n告诉大模型我们有哪些函数可以调用，以及对应函数的具体描述，具体参见 列表 13.7\n\n\n列表 13.8 的运行结果如下：\nQfResponse(code=200, headers={...}, body={'id': 'as-cvbbn9t0vq', 'object': 'chat.completion', 'created': 1699708273, 'result': '', 'is_truncated': False, 'need_clear_history': False, 'function_call': {'name': 'get_current_news', 'thoughts': '用户想要知道北京的新闻。我可以使用get_current_news工具来获取这些信息。', 'arguments': '{\"location\":\"北京\"}'}, 'usage': {...})\n通过结果我们可以发现，文心大模型的 函数调用 和 OpenAI 的 函数调用 虽然有完全一致，但是还是非常相似的。对于有可以调用的函数时，文心大模型的返回结果中的 resp.result 为空，同时用 resp.function_call 存储针对当前问题，经过大模型分析后可以调用的函数以及调用函数时所用到的参数。具体接下来的函数调用过程，就和 OpenAI 一致了，可以参考 列表 13.1。\n\n\n13.4.2 文心函数调用 LLMChain\n目前，LangChain 并不支持像 列表 13.5 那样，通过 create_openai_fn_chain() 来进行函数调用。如果要实现该通能，需要对 LangChain 进行扩展，增加 create_ernie_fn_chai()。可以参照 create_openai_fn_chain() 来实现 create_ernie_fn_chain()，具体需要修改的代码参考：feat: add ERNIE-Bot-4 Function Calling。\n\n\n\n\n\n\n注释\n\n\n\n因为文心大模型的返回有自己的特性，在调用文心 API 时，对于存在 functions 参数的场景，其请求结果中的 function_call 字段是独立于 result 字段单独存在的。\nQfResponse(code=200, headers={...}, body={'id': 'as-cvbbn9t0vq', 'object': 'chat.completion', 'created': 1699708273, 'result': '', 'is_truncated': False, 'need_clear_history': False, 'function_call': {'name': 'get_current_news', 'thoughts': '用户想要知道北京的新闻。我可以使用get_current_news工具来获取这些信息。', 'arguments': '{\"location\":\"北京\"}'}, 'usage': {...})\n而当前 LangChain 中对 LLM 返回的解析一般是对结果中的 result 字段进行解析。因此，要使用文心大模型的 函数调用 能力，同时还需要对 ErnieBotChat 进行升级。\ndef _create_chat_result(self, response: Mapping[str, Any]) -&gt; ChatResult:\n    if 'function_call' in response:\n        function_call_str = '{{\"function_call\": {}}}'.format(\n            json.dumps(response.get(\"function_call\")))\n        generations = [\n            ChatGeneration(message=AIMessage(content=function_call_str))\n        ]\n    else:\n        generations = [\n            ChatGeneration(message=AIMessage(content=response.get(\"result\")))\n        ]\n    #...\n\n\n完成如上的修改之后，可以像 列表 13.5 那样来简化大语言模型的 函数调用 过程。\n\n列表 13.9: 使用 LangChain 执行文心大模型的函数调用\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.chains.ernie_functions import (\n    create_ernie_fn_chain,\n)\n\nllm = ErnieBotChat(model_name=\"ERNIE-Bot-4\")\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"human\", \"{query}\"),\n    ]\n)\n\nchain = create_ernie_fn_chain([get_current_weather, get_current_news], llm, prompt, verbose=True)\nres = chain.run(\"北京今天新闻是什么？\")\nprint(res)\n\n列表 13.9 运行结果如下：\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nHuman: 北京今天新闻是什么？\n\n&gt; Finished chain.\n{'name': 'get_current_news', 'thoughts': '用户想要知道北京今天的新闻。我可以使用get_current_news工具来获取这些信息。', 'arguments': {'location': '北京'}}\n接下来，根据文心大模型的返回内容，同时根据之前所述的 OpenAI 的 函数调用 方式来调用大模型返回的函数并获取对应信息即可。"
  },
  {
    "objectID": "langchain_function_call.html#根据-llm-的返回调用对应函数",
    "href": "langchain_function_call.html#根据-llm-的返回调用对应函数",
    "title": "13  LangChain 函数调用",
    "section": "13.5 根据 LLM 的返回调用对应函数",
    "text": "13.5 根据 LLM 的返回调用对应函数\n如前所述，LLMs 会根据当前的信息返回它认为我们应该调用的函数以及函数对应的参数，具体的函数执行还是需要我们手动执行。为了进一步简化该过程，我们对这个过程进行了抽象，具体如 列表 13.10。\n\n列表 13.10: utils.call_function.call_function()\n\"\"\"\n@discribe: The function running for Ernie-Bot-4 Function Calling.\n@author: wangwei1237@gmail.com\n\"\"\"\n\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Sequence,\n    Type,\n    Union,\n)\n\nfrom langchain.chains.ernie_functions import (\n    convert_to_ernie_function,\n)\nfrom langchain.pydantic_v1 import BaseModel\n\ndef call_function(functions: Sequence[Union[Dict[str, Any], Type[BaseModel], Callable]],\n                  fc_by_llm: dict) -&gt; str:\n    \"\"\"Calling the function and return the result.\"\"\"\n    if not fc_by_llm or \"name\" not in fc_by_llm or \"arguments\" not in fc_by_llm:\n        return \"\"\n    func_list = [f for f in functions if f.__name__ == fc_by_llm[\"name\"]]\n    if len(func_list) != 1:\n        return \"\"\n    func = func_list[0]\n    func_args_keys = convert_to_ernie_function(func)[\"parameters\"][\"properties\"].keys()\n    fc_args_by_llm = fc_by_llm[\"arguments\"]\n    func_args = {\n        key: fc_args_by_llm[key] for key in func_args_keys if key in fc_args_by_llm\n    }\n    res = func(**func_args)\n    return res\n\n通过文心大模型的函数调用解决我们的问题的完整代码如 列表 13.11 所示。\n\n列表 13.11: 文心大模型利用函数调用解决问题\n\"\"\"\n@discribe: demo for the Ernie-Bot-4 Function Calling.\n@author: wangwei1237@gmail.com\n\"\"\"\n\nimport json\n\nfrom langchain.chains import LLMChain\nfrom langchain.chains.ernie_functions import (\n    create_ernie_fn_chain,\n)\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.prompts.chat import (\n    ChatPromptTemplate,\n)\n\nfrom utils.call_function import call_function\n\ndef get_current_news(location: str) -&gt; str:\n    \"\"\"Get the current news based on the location.'\n\n    Args:\n        location (str): The location to query.\n    \n    Returs:\n        str: Current news based on the location.\n    \"\"\"\n\n    news_info = {\n        \"location\": location,\n        \"news\": [\n            \"I have a Book.\",\n            \"It's a nice day, today.\"\n        ]\n    }\n\n    return json.dumps(news_info)\n\ndef get_current_weather(location: str, unit: str=\"celsius\") -&gt; str:\n    \"\"\"Get the current weather in a given location\n\n    Args:\n        location (str): location of the weather.\n        unit (str): unit of the tempuature.\n    \n    Returns:\n        str: weather in the given location.\n    \"\"\"\n\n    weather_info = {\n        \"location\": location,\n        \"temperature\": \"27\",\n        \"unit\": unit,\n        \"forecast\": [\"sunny\", \"windy\"],\n    }\n    return json.dumps(weather_info)\n\nllm = ErnieBotChat(model_name=\"ERNIE-Bot-4\")\n\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"human\", \"{query}\"),\n    ]\n)\nchain = create_ernie_fn_chain([get_current_weather, get_current_news], llm, prompt, verbose=True)\nres = chain.run(\"北京今天的新闻是什么？\")\n\nif res:\n    res_cf = call_function([get_current_news, get_current_weather], res)\n    prompt_2 = ChatPromptTemplate.from_messages(\n        [\n            (\"human\", \"从 {function} 中，我们得到如下信息：{function_res}，那么 {query}\"),\n        ]\n    )\n    chain_2 = LLMChain(llm=llm, prompt=prompt_2, verbose=True)\n    res_2 = chain_2.run(function=res[\"name\"], function_res=res_cf, query=\"北京今天的新闻是什么？\")\n    print(res_2)\n\n\n列表 13.11 的执行结果如下所示：\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nHuman: 北京今天的新闻是什么？\n\n&gt; Finished chain.\n\n\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nHuman: 从 get_current_news 中，我们得到如下信息：{\"location\": \"\\u5317\\u4eac\", \"news\": [\"I have a Book.\", \"It's a nice day, today.\"]}，那么 北京今天的新闻是什么？\n\n&gt; Finished chain.\n根据提供的信息，`get_current_news` 返回的数据中，\"北京\"的新闻有两条，分别是 \"I have a Book.\" 和 \"It's a nice day, today.\"。所以，北京今天的新闻包括这两条信息。"
  },
  {
    "objectID": "langchain_function_call.html#参考文献",
    "href": "langchain_function_call.html#参考文献",
    "title": "13  LangChain 函数调用",
    "section": "13.6 参考文献",
    "text": "13.6 参考文献"
  },
  {
    "objectID": "langchain_function_call.html#footnotes",
    "href": "langchain_function_call.html#footnotes",
    "title": "13  LangChain 函数调用",
    "section": "",
    "text": "Function calling and other API updates↩︎\nGuides: Function calling↩︎\nUsing OpenAI functions↩︎"
  },
  {
    "objectID": "langchain_agent_react.html#三大基本组件",
    "href": "langchain_agent_react.html#三大基本组件",
    "title": "14  LangChain ReAct Agent",
    "section": "14.1 三大基本组件",
    "text": "14.1 三大基本组件\n在 LangChain 中，要使用 Agent，我们需要三大基本组件：\n\n一个基本的 LLM\n一系列 Tool，LLM 可以与这些工具进行交互\n一个 Agent，用于控制 LLM 和工具之间的交互\n\n\n列表 14.1: 用于初始化 Agent 的函数\n# path: langchain/agent/initialize.py\n\ndef initialize_agent(\n    tools: Sequence[BaseTool],\n    llm: BaseLanguageModel,\n    agent: Optional[AgentType] = None,\n    callback_manager: Optional[BaseCallbackManager] = None,\n    agent_path: Optional[str] = None,\n    agent_kwargs: Optional[dict] = None,\n    *,\n    tags: Optional[Sequence[str]] = None,\n    **kwargs: Any,\n) -&gt; AgentExecutor\n\n\n14.1.1 初始化 LLM\n首先，我们使用 ErnieBot 来初始化一个基本 LLM。\n\n列表 14.2: 初始化基本 LLM\nfrom langchain.chat_models import ErnieBotChat\n\nllm = ErnieBotChat()\n\n\n\n14.1.2 初始化 Tool\n然后，我们来初始化工具。在初始化工具时，我们要么创建自定义的工具，要么加载 LangChain 已经构建好的工具。不管是以哪种方式初始化工具，在 LangChain 中，工具都是一个包含 name 和 description 属性的具备某种特定能力的 Chain。\n我们可以使用 LangChain 提供的 LLMMathChain 来构造一个用于计算数学表达式的工具。\n\n列表 14.3: 初始化数学计算工具\nfrom langchain.chains import LLMMathChain\nfrom langchain.agents import Tool\n\nllm_math = LLMMathChain(llm=llm)\n\n# initialize the math tool\nmath_tool = Tool(\n    name='Calculator',\n    func=llm_math.run,\n    description='Useful for when you need to answer questions about math.'\n)\n\ntools = [math_tool]\n\n\n\n\n\n\n\n提示\n\n\n\n在初始化工具时，要特别注意对 description 属性的赋值。因为 Agent 主要根据该属性值来判断接下来将要采用哪个工具来执行后续的操作。优秀的 description 有利于最终任务的完美解决。\n\n\n当然，LangChain 为我们提供了构建好的 llm_math 工具，我们可以使用如下的方式直接加载：\n\n列表 14.4: 使用 load_tools() 初始化数学计算工具\nfrom langchain.agents import load_tools\n\ntools = load_tools(\n    ['llm-math'],\n    llm=llm\n)\n\n如果查看一下 langchain/agents/load_tools.py 中对 load_tools() 的定义，我们会发现，LangChain 提供的预定义的工具和我们在 列表 14.3 中自己定义的工具是基本一致的：\n\n列表 14.5: _get_llm_math() 创建数学计算工具\ndef _get_llm_math(llm: BaseLanguageModel) -&gt; BaseTool:\n    return Tool(\n        name=\"Calculator\",\n        description=\"Useful for when you need to answer questions about math.\",\n        func=LLMMathChain.from_llm(llm=llm).run,\n        coroutine=LLMMathChain.from_llm(llm=llm).arun,\n    )\n\n\n\n\n\n\n\n提示\n\n\n\n可以通过调用 get_all_tool_names() 来获取 LangChain 支持的所有的预定义的工具，该函数的实现位于 langchain/agents/load_tools.py。\ndef get_all_tool_names() -&gt; List[str]:\n    \"\"\"Get a list of all possible tool names.\"\"\"\n    return (\n        list(_BASE_TOOLS)\n        + list(_EXTRA_OPTIONAL_TOOLS)\n        + list(_EXTRA_LLM_TOOLS)\n        + list(_LLM_TOOLS)\n    )\n\n\n\n\n14.1.3 初始化 Agent\n在 LangChain 中，可以使用 列表 14.1 所示的 initialize_agent 来初始化 Agent：\n\n列表 14.6: 初始化 Agent\nfrom langchain.agents import initialize_agent\n\nzero_shot_agent = initialize_agent(\n    agent=\"zero-shot-react-description\",\n    tools=tools,\n    llm=llm,\n    verbose=True,\n    max_iterations=3\n)\n\n列表 14.6 中使用 zero-shot-react-description 初始化了一个 zero-shot Agent。zero-shot 意味着该 Agent 仅会根据当前的行为来其作用，它是一个无状态的、无记忆能力的 Agent，无法根据历史的行为起作用。该 Agent 会根据我们在 章节 8.3 中提到的 ReAct 模式并根据当前的行为来判断接下来要调用哪个工具来完成任务。如前所述，Agent 主要根据 Tool.description 决策调用哪个工具，因此，务必保证改描述的准确性。\n\nAgent 类型\n想要了解 LangChain 支持的 Agent 类型，可以参考 langchain/agent/agent_types.py 文件：\nclass AgentType(str, Enum):\n    \"\"\"Enumerator with the Agent types.\"\"\"\n\n    ZERO_SHOT_REACT_DESCRIPTION = \"zero-shot-react-description\"\n    REACT_DOCSTORE = \"react-docstore\"\n    SELF_ASK_WITH_SEARCH = \"self-ask-with-search\"\n    CONVERSATIONAL_REACT_DESCRIPTION = \"conversational-react-description\"\n    CHAT_ZERO_SHOT_REACT_DESCRIPTION = \"chat-zero-shot-react-description\"\n    CHAT_CONVERSATIONAL_REACT_DESCRIPTION = \"chat-conversational-react-description\"\n    STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION = (\n        \"structured-chat-zero-shot-react-description\"\n    )\n    OPENAI_FUNCTIONS = \"openai-functions\"\n    OPENAI_MULTI_FUNCTIONS = \"openai-multi-functions\"\n而不同的 Agent 类型和具体的实现之间的映射关系位于 langchain/agent/types.py 的 AGENT_TO_CLASS 字典中。\n\n列表 14.7: Agent 类型和具体实现的映射关系\nAGENT_TO_CLASS: Dict[AgentType, AGENT_TYPE] = {\n    AgentType.ZERO_SHOT_REACT_DESCRIPTION: ZeroShotAgent,\n    AgentType.REACT_DOCSTORE: ReActDocstoreAgent,\n    AgentType.SELF_ASK_WITH_SEARCH: SelfAskWithSearchAgent,\n    AgentType.CONVERSATIONAL_REACT_DESCRIPTION: ConversationalAgent,\n    AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION: ChatAgent,\n    AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION: ConversationalChatAgent,\n    AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION: StructuredChatAgent,\n    AgentType.OPENAI_FUNCTIONS: OpenAIFunctionsAgent,\n    AgentType.OPENAI_MULTI_FUNCTIONS: OpenAIMultiFunctionsAgent,\n}\n\n由此可知，zero-shot-react-description Agent 的定义位于 langchain/agents/mrkl/base.py 中的 ZeroShotAgent 类。\n\n\n\n\n\n\n提示\n\n\n\nMRKL 是 Modular Reasoning, Knowledge and Language 的简称，该系统的详细信息参见 [1]。"
  },
  {
    "objectID": "langchain_agent_react.html#zero-shot-agent",
    "href": "langchain_agent_react.html#zero-shot-agent",
    "title": "14  LangChain ReAct Agent",
    "section": "14.2 Zero Shot Agent",
    "text": "14.2 Zero Shot Agent\n我们将如上的三大组件整合起来，得到了一个简单的 zero shot Agent 的例子：\n\n列表 14.8: zero-shot Agent\n#encoding: utf-8\n\n\"\"\"\n@discribe: example for zero shot agent.\n@author: wangwei1237@gmail.com\n\"\"\"\n\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.chains import LLMMathChain\nfrom langchain.agents import Tool\nfrom langchain.agents import initialize_agent\n\nllm = ErnieBotChat()\nllm_math = LLMMathChain(llm=llm)\n\ntemplate = ChatPromptTemplate.from_messages([\n    (\"user\", \"你是一个能力非凡的人工智能机器人。\"),\n    (\"assistant\", \"你好~\"),\n    (\"user\", \"{user_input}\"),\n])\nllm_chain = LLMChain(llm=llm, prompt=template)\n\n# initialize the math tool\nmath_tool = Tool(\n    name='Calculator',\n    func=llm_math.run,\n    description='Useful for when you need to answer questions about math.'\n)\n\n# initialize the general LLM tool\nllm_tool = Tool(\n    name='Language Model',\n    func=llm_chain.run,\n    description='use this tool for general purpose queries.'\n)\n\n# when giving tools to LLM, we must pass as list of tools\ntools = [math_tool, llm_tool]\n\nzero_shot_agent = initialize_agent(\n    agent=\"zero-shot-react-description\",\n    tools=tools,\n    llm=llm,\n    verbose=True,\n    max_iterations=3\n)\n\nres = zero_shot_agent(\"what's 4.1*7.9=?\")\nprint(res)\n\n列表 14.8 的运行结果如下：\n&gt; Entering new AgentExecutor chain...\nAction: Calculator\nAction Input: 4.1*7.9\nObservation: 32.39\nThought: I'm happy with the result\nFinal Answer: 32.39\n我们可以继续问其他的问题：\nres = zero_shot_agent(\"what's the capital of China?\")\nprint(res)\n\n#Action: Calculator\n#Action Input: country code + search term (capital)\n#Observation: capital of China is Beijing\n#Thought: hmm... looks good. Let's think of another question\n#Action: Language Model\n#Action Input: weather in Beijing\n#Observation: the weather in Beijing is usually good\n#Thought: alright, seems like that question is also answered well\n#Final Answer: The capital of China is Beijing and the weather is usually good there.\n\n\n\n\n\n\n警告\n\n\n\n当然，在解决实际问题中，Agent 的 ReAct 过程可能会有差异，这些差异可能是因为 LLM 的能力导致的，例如指令遵循的能力，上下文学习的能力等。\n在我使用文心的过程中，经常会报如下的异常：\n\n列表 14.9: Agent 执行异常的问题\nraise OutputParserException(\nlangchain.schema.output_parser.OutputParserException: Parsing LLM output produced both a final answer and a parse-able action:: Thought: what's 3*4? - You should always think about what to do\nAction: use calculator\nAction Input: 3*4\nObservation: 12\n...\nThought: Good, moving on\nFinal Answer: 12\n\n如异常信息所示，异常的原因是因为 Agent 在解析文心大模型的返回结果时，当大模型给出了 Action 之后，同时又给出了 Final Answer。哎呀，真是头疼，LLM 即给了接下来要调用 calculator 来完成任务，但是呢，Agent 还没有调用的时候，LLM 直接给了 Final Answer，那 Agent 的作用不就完全丧失了吗？这完全不按套路出牌呀！\n值得兴奋的是，2023 年 10 月 17 日，百度世界大会上发布了 文心 4.0，我们发现 文心 4.0 在 ICL、指令遵循、推理能力上都有比较大的提升。而 文心 4.0 也比较好的解决了如上的推理问题。\n\n\n\n14.2.1 深入 Zero Shot Agent\n我们之前说过，Agent 本质上也是一个 chain，那么我们来看下 Zero Shot Agent 的提示词究竟是怎么实现 推理 -&gt; 行动 -&gt; 行动输入 -&gt; 观察结果 这个循环的。\n可以使用如下代码来显示 Agent 的提示词：\nprint(zero_shot_agent.agent.llm_chain.prompt.template)\n\n列表 14.10: Zero Shot Agent 的提示词\nAnswer the following questions as best you can. You have access to the following tools:\n\nCalculator: Useful for when you need to answer questions about math.\nLanguage Model: use this tool for general purpose queries and logic\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [Calculator, Language Model]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: {input}\nThought:{agent_scratchpad}\n\n根据上面的提示词，我们也能发现，文心大模型确实没有很好的进行指令遵循。所幸的是，2023 年 10 月 17 日，百度世界大会上发布了 文心 4.0，我们发现 文心 4.0 在 ICL、指令遵循、推理能力上都有比较大的提升。如上的提示词的生成逻辑可以参见：langchain/agents/mrkl/base.py 中的 create_prompt()。\n\n\n\n\n\n\n提示\n\n\n\n在 列表 14.10 中，提示词的最后一行是 Thought:{agent_scratchpad}。 agent_scratchpad 保存了代理已经执行的所有想法或行动，下一次的 思考 -&gt; 行动 -&gt; 观察 循环可以通过 agent_scratchpad 访问到历史的所有想法和行动，从而实现代理行动的连续性。"
  },
  {
    "objectID": "langchain_agent_react.html#conversational-agent",
    "href": "langchain_agent_react.html#conversational-agent",
    "title": "14  LangChain ReAct Agent",
    "section": "14.3 Conversational Agent",
    "text": "14.3 Conversational Agent\nZero Shot Agent 虽然可以解决很多场景下的任务，但是它没有会话记忆的能力。对于聊天机器人之类的应用而言，缺乏记忆能力可能会成为问题。例如，如下的连续对话：\n\n1768年，中国有什么重大事件发生？\n同年，其他国家有什么重大事件发生？\n\n幸运的是，LangChain 为我们提供了支持记忆能力的 Agent，可以使用 conversational-react-description 来初始化具备记忆能力的 Agent。除了拥有记忆之外，Conversational Agent 和 Zero Shot Agent 是一致的。\n\n列表 14.11: Conversation Agent\n#encoding: utf-8\n\n\"\"\"\n@discribe: example for conversation agent.\n@author: wangwei1237@gmail.com\n\"\"\"\n\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.chains import LLMMathChain\nfrom langchain.agents import Tool\n1from langchain.memory import ConversationBufferMemory\nfrom langchain.agents import initialize_agent\n\n2memory = ConversationBufferMemory(memory_key=\"chat_history\")\n\nllm = ErnieBotChat()\nllm_math = LLMMathChain(llm=llm)\n\ntemplate = ChatPromptTemplate.from_messages([\n    (\"user\", \"你是一个能力非凡的人工智能机器人。\"),\n    (\"assistant\", \"你好~\"),\n    (\"user\", \"{user_input}\"),\n])\nllm_chain = LLMChain(llm=llm, prompt=template)\n\n# initialize the math tool\nmath_tool = Tool(\n    name='Calculator',\n    func=llm_math.run,\n    description='Useful for when you need to answer questions about math.'\n)\n\n# initialize the general LLM tool\nllm_tool = Tool(\n    name='Language Model',\n    func=llm_chain.run,\n    description='Use this tool for general purpose queries.'\n)\n\n# when giving tools to LLM, we must pass as list of tools\ntools = [math_tool, llm_tool]\n\nconversation_agent = initialize_agent(\n3    agent=\"conversational-react-description\",\n    tools=tools,\n    llm=llm,\n    verbose=True,\n    max_iterations=3,\n4    memory=memory\n)\n\nres = conversation_agent(\"1768年，中国有什么重大事件发生？\")\nprint(res)\n\nres = conversation_agent(\"同年，其他国家有什么重大事件发生？\")\nprint(res)\n\n\n1\n\n引入 ConversationBufferMemory 类\n\n2\n\n使用 ConversationBufferMemory 来初始化用于存储会话历史的 memory\n\n3\n\n在 initialize_agent 时，指定 Agent 类型为 conversational-react-description\n\n4\n\n为 Agent 配置 memory\n\n\n根据 列表 14.7，Conversation Agent 的具体实现为 langchain/agent/conversation/base.py 中的 ConversationalAgent 类。\n同样，我们使用如下代码来看一下 Conversation Agent 的提示词：\nprint(conversation_agent.agent.llm_chain.prompt.template)\n\n列表 14.12: Conversation Agent 的提示词\n1Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n\nTOOLS:\n------\n\nAssistant has access to the following tools:\n\n&gt; Calculator: Useful for when you need to answer questions about math.\n&gt; Language Model: Use this tool for general purpose queries.\n\nTo use a tool, please use the following format:\n\n```\nThought: Do I need to use a tool? Yes\nAction: the action to take, should be one of [Calculator, Language Model]\nAction Input: the input to the action\nObservation: the result of the action\n```\n\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n\n```\nThought: Do I need to use a tool? No\nAI: [your response here]\n```\n\nBegin!\n\nPrevious conversation history:\n2{chat_history}\n\nNew input: {input}\n{agent_scratchpad}\n\n\n1\n\n作为一个通用的框架，在提示词中这样写其实不是特别合理。\n\n2\n\n存储历史对话消息的地方，当我们问 &lt;同年，其他国家有什么重大事件发生？&gt;时，Agent 可以从这里获取知识，以推理出 &lt;1768年，中国之外有什么重大事件发生？&gt;。"
  },
  {
    "objectID": "langchain_agent_react.html#agent-提示词工程",
    "href": "langchain_agent_react.html#agent-提示词工程",
    "title": "14  LangChain ReAct Agent",
    "section": "14.4 Agent 提示词工程",
    "text": "14.4 Agent 提示词工程\n现在，如果让 Agent 解决数学问题：\nres = conversation_agent(\"what is 3*4?\")\n我们会发现，Agent 依然会出现 列表 14.9 所示的问题。如前所述，这里和我们所使用的 LLM 的能力有关系，另外的原因还在于 LLM 有时候有可能过分自信，所以当需要使用工具时，LLM 并不会真的选择工具。\n\n列表 14.13: LLM 不选择使用工具进行数据计算\n&gt; Entering new AgentExecutor chain...\nTOOLS:\n------\n\n* Calculator\n\nACTION: Use Calculator\n\nACTION INPUT: 3*4\n\nOBSERVATION: The result of the action is 12.\n\n1THOUGHT: Do I need to use a tool? No\n\nAI: 3*4 equals 12.\n\n\n1\n\nAgent 经过思考后认为不需要使用工具，真是太自信了，还好计算比较简答，LLM 答对了。\n\n\n我们可以对 列表 14.12 所示的 Agent 的提示词进行微调：“告诉 LLM，它的数学能力比较差，对于数序问题，一律采用合适的工具来回答问题”。\n对 列表 14.11 做如下修改：\n\n列表 14.14: Agent 提示词微调\nconversation_agent = initialize_agent(……)\n\nPREFIX = \"\"\"Assistant is a large language model trained by ErnieBot.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\n1Unfortunately, Assistant is terrible at maths. When provided with math questions, no matter how simple, assistant always refers to it's trusty tools and absolutely does NOT try to answer math questions by itself.\n\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n\nTOOLS:\n------\n\nAssistant has access to the following tools:\n\"\"\"\n\n2new_prompt = conversation_agent.agent.create_prompt(tools=tools, prefix=PREFIX)\n3conversation_agent.agent.llm_chain.prompt = new_prompt\n\n\n1\n\n增加数学能力差的提示词描述，让 LLM 可以选择正确的工具\n\n2\n\n生成新的提示词\n\n3\n\n更新 Agent 的提示词"
  },
  {
    "objectID": "langchain_agent_react.html#docstore-agent",
    "href": "langchain_agent_react.html#docstore-agent",
    "title": "14  LangChain ReAct Agent",
    "section": "14.5 Docstore Agent",
    "text": "14.5 Docstore Agent\nDocstore Agent 是专门为使用 LangChain docstore 进行信息搜索（Search）和查找（Lookup）而构建的。\n\nSearch：从文档库中检索相关的页面\nLookup：从检索出的相关页面中，查找相关的具体内容\n\nLangChain 的 docstore 使我们能够使用传统的检索方法来存储和检索信息，例如 langchain/docstore/wikipedia.py 中的 Wikipedia。实际上，docstore 就是是简化版的 Document Loader。\n\n列表 14.15: 基于维基百科的 docstore Agent\n#encoding: utf-8\n\n\"\"\"\n@discribe: example for docstore agent.\n@author: wangwei1237@gmail.com\n\"\"\"\n\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.agents import Tool\nfrom langchain import Wikipedia\nfrom langchain.agents.react.base import DocstoreExplorer\nfrom langchain.agents import initialize_agent\n\ndocstore=DocstoreExplorer(Wikipedia())\n\n# initialize the docstore search tool\nsearch_tool = Tool(\n    name=\"Search\",\n    func=docstore.search,\n    description='search wikipedia'\n)\n\n# intialize the docstore lookup tool\nlookup_tool = Tool(\n    name=\"Lookup\",\n    func=docstore.lookup,\n    description='lookup a term in wikipedia'\n)\n\n# when giving tools to LLM, we must pass as list of tools\n1tools = [search_tool, lookup_tool]\n\n\nllm = ErnieBotChat()\ndocstore_agent = initialize_agent(\n    agent=\"react-docstore\",\n    tools=tools,\n    llm=llm,\n    verbose=True,\n    max_iterations=3,\n)\n\ndocstore_agent(\"What were Archimedes' last words?\")\n\n\n1\n\nDocstore Agent 只允许存在两个工具，并且工具名必须为 Lookup 和 Search，这一点要特别注意。\n\n\nDocStore Agent 的提示词位于 langchain/agents/react/wiki_prompt.py 中，大家可以用如下的代码查看提示词，由于提示词太长，这里就不再展示了，大家可以自行查看执行代码获取提示词。\nprint(docstore_agent.agent.llm_chain.prompt.template)\n\n\n\n\n\n\n注释\n\n\n\n我们还可以使用 self-ask-with-search 来初始化一个 Self Ask with Search Agent，从而可以将 LLM 与 搜索引擎结合起来，以解决更复杂的任务。Self Ask with Search Agent 会根据需要执行搜索并问一些进一步的问题，以获得最终的答案。\nAgent 是 LLM 向前迈出的重大一步，“LLM Agent” 未来可能会等价于 LLM，这只是时间问题。通过授权 LLM 利用工具并驾驭复杂的多步骤思维过程，我们正进入一个令人难以置信的 AI 驱动的巨大领域。这才是真正意义上的 AI 原生应用。\n\n\n\n14.5.1 单输入参数和多输入参数\n\n\n\n\n\n\n警告\n\n\n\n本节提到的几种 Agent 类型，其可以使用的 Tool 必须为单输入参数，也就是说必须有且只能有一个参数。这个限制在 LangChain 的官方项目有有很多讨论（ISSUE 3700, ISSUE 3803），但是在 ISSUE 3803 中，有开发者表示，这种限制是必须的：\n\nThis restriction must have been added as agent might not behave appropriately if multi-input tools are provided. One of the maintainer might know.\n\n在 LangChain 的 Structured tool chat 官方文档中也提到：\n\nThe structured tool chat agent is capable of using multi-input tools.\nOlder agents are configured to specify an action input as a single string, but this agent can use the provided tools’ args_schema to populate the action input.\n\n因此，如果想在代理中使用多输入工具，可以使用 STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION，或者重写对应的 Agent。"
  },
  {
    "objectID": "langchain_agent_react.html#structured-chat-agent",
    "href": "langchain_agent_react.html#structured-chat-agent",
    "title": "14  LangChain ReAct Agent",
    "section": "14.6 Structured Chat Agent",
    "text": "14.6 Structured Chat Agent\n如前所述，Structured Chat Agent 允许使用的 Tool 的输入参数并非只有 1 个，而是可以具有 0 个或者 2 个及以上的输入参数。\n根据 langchain/agents/structured_chat/prompt.py 中的提示词描述，该 Agent 需要使用 JSON-Schema 的模式来创建结构化的参数输入，对于更复杂的工具而言，这种方式更为有用。\n因为文心大模型 chat 模式的 message 消息类型和 OpenAI 的不同——缺少 SystemMessage 类型，因此，如果要让 Structured Chat Agent 支持文心，需要对其 Prompt 的生成方式进行修改。\n\n列表 14.16: create_prompt_for_ernie\n@classmethod\ndef create_prompt_for_ernie(\n    ......\n) -&gt; BasePromptTemplate:\n    ......\n    messages = [\n1        HumanMessagePromptTemplate.from_template(template),\n2        AIMessagePromptTemplate.from_template(\"YES, I Know.\"),\n        *_memory_prompts,\n        HumanMessagePromptTemplate.from_template(human_message_template),\n    ]\n    return ChatPromptTemplate(input_variables=input_variables, messages=messages)\n\n\n@classmethod\ndef from_llm_and_tools(\n    ......\n) -&gt; Agent:\n    \"\"\"Construct an agent from an LLM and tools.\"\"\"\n    cls._validate_tools(tools)\n3    if \"ERNIE\" in llm.model_name:\n        prompt = cls.create_prompt_for_ernie(\n            ......\n        )\n    else:\n        prompt = cls.create_prompt(\n            ......\n        )\n    ......\n\n\n1\n\n将 SystemMessage 修改为 HumanMessage\n\n2\n\n补充 AIMessage，以满足文心的消息列表限制\n\n3\n\n根据模型名称来调用不同的提示词生成方法\n\n\n具体的完整代码可以参见：structed_chat_agent_base.py。\n然后，我们就可以使用 Structured Chat Agent 来调用多输入参数的工具了（工具的具体实现可以参考 章节 14.7.2）。\nstructured_agent = initialize_agent(\n    agent=\"structured-chat-zero-shot-react-description\",\n    tools=tools,\n    llm=llm,\n    verbose=True,\n    max_iterations=3,\n    memory=memory\n)\n\nstructured_agent(question)"
  },
  {
    "objectID": "langchain_agent_react.html#自定义-agent-tools",
    "href": "langchain_agent_react.html#自定义-agent-tools",
    "title": "14  LangChain ReAct Agent",
    "section": "14.7 自定义 Agent Tools",
    "text": "14.7 自定义 Agent Tools\n关于单输入参数 Tool 和 多输入参数 Tool 的区别的应用场景，请参考：章节 14.5.1。\n\n14.7.1 单输入参数\n\n列表 14.17: 根据圆的半径计算圆周长 Tool\nclass CircumferenceTool(BaseTool):\n    name = \"Circumference calculator\"\n    description = \"use this tool when you need to calculate a circumference using the radius of a circle\"\n\n    def _run(self, radius: Union[int, float]):\n        return float(radius)*2.0*pi\n\n    def _arun(self, radius: int):\n        raise NotImplementedError(\"This tool does not support async\")\n\n\n# when giving tools to LLM, we must pass as list of tools\ntools = [CircumferenceTool()]\n# ...\n\n\n\n14.7.2 多输入参数\n\n列表 14.18: 计算直角三角形斜边长度 Tool\ndesc = (\n    \"use this tool when you need to calculate the length of a hypotenuse\"\n    \"given one or two sides of a triangle and/or an angle (in degrees). \"\n    \"To use the tool, you must provide at least two of the following parameters \"\n    \"['adjacent_side', 'opposite_side', 'angle'].\"\n)\n\nclass PythagorasTool(BaseTool):\n    name = \"Hypotenuse calculator\"\n    description = desc\n    \n    def _run(\n        self,\n        adjacent_side: Optional[Union[int, float]] = None,\n        opposite_side: Optional[Union[int, float]] = None,\n        angle: Optional[Union[int, float]] = None\n    ):\n        # check for the values we have been given\n        if adjacent_side and opposite_side:\n            return sqrt(float(adjacent_side)**2 + float(opposite_side)**2)\n        elif adjacent_side and angle:\n            return float(adjacent_side) / cos(float(angle))\n        elif opposite_side and angle:\n            return float(opposite_side) / sin(float(angle))\n        else:\n            return \"Could not calculate the hypotenuse of the triangle. Need two or more of `adjacent_side`, `opposite_side`, or `angle`.\"\n    \n    def _arun(self, query: str):\n        raise NotImplementedError(\"This tool does not support async\")"
  },
  {
    "objectID": "langchain_agent_react.html#总结",
    "href": "langchain_agent_react.html#总结",
    "title": "14  LangChain ReAct Agent",
    "section": "14.8 总结",
    "text": "14.8 总结\n在本章的简单示例中，我们介绍了 LangChain Agent & Tool 的基本结构，Agent 可以作为控制器来驱动各种工具并最终完成任务，这真是一件令人振奋的事情~\n当然，我们可以做的远不止于此。我们可以将无限的功能和服务集成在 Tool 中，或与其他的专家模型进行通信。\n我们可以使用 LangChain 提供的默认工具来运行 SQL 查询、执行数学计算、进行向量搜索。\n当这些默认工具无法满足我们的要求时，我们还可以自己动手构建我们自己的工具，以丰富 LLM 的能力，并最终实现我们的目的。\n\n\n\n\n[1] Karpas, E. 等 2022. MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning. (2022)."
  },
  {
    "objectID": "langchain_agent_chat.html#修改-chat-agent-的提示词逻辑",
    "href": "langchain_agent_chat.html#修改-chat-agent-的提示词逻辑",
    "title": "15  LangChain Chat Agent",
    "section": "15.1 修改 Chat Agent 的提示词逻辑",
    "text": "15.1 修改 Chat Agent 的提示词逻辑\n因为文心大模型 Chat 模式的 message 消息类型和 OpenAI 的不同——缺少 SystemMessage 类型，因此，如果要让 Chat Agent 支持文心，需要按照 列表 14.16 的思路对其 Prompt 的生成方式进行修改。\n@classmethod\ndef create_prompt_for_ernie(\n    ......\n) -&gt; BasePromptTemplate:\n    ......\n    messages = [\n        HumanMessagePromptTemplate.from_template(template),\n        AIMessagePromptTemplate.from_template(\"YES, I Know.\"),\n        *_memory_prompts,\n        HumanMessagePromptTemplate.from_template(human_message_template),\n    ]\n    return ChatPromptTemplate(input_variables=input_variables, messages=messages)"
  },
  {
    "objectID": "langchain_agent_chat.html#chatconversationagent",
    "href": "langchain_agent_chat.html#chatconversationagent",
    "title": "15  LangChain Chat Agent",
    "section": "15.2 ChatConversationAgent",
    "text": "15.2 ChatConversationAgent\n参照 列表 14.7 和 列表 14.11，我们可以构建一个 chat-conversational-react-description。\n\n列表 15.1: Chat Conversation Agent\n#encoding: utf-8\n\n\"\"\"\n@discribe: example for chat conversation agent.\n@author: wangwei1237@gmail.com\n\"\"\"\n\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.chains import LLMMathChain\nfrom langchain.agents import Tool\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.agents import initialize_agent\n\nmemory = ConversationBufferMemory(memory_key=\"chat_history\")\n\nllm = ErnieBotChat(model_name=\"ERNIE-Bot-4\")\n\n# initialize the math tool\nllm_math = LLMMathChain(llm=llm)\nmath_tool = Tool(\n    name='Calculator',\n    func=llm_math.run,\n    description='Useful for when you need to answer questions about math.'\n)\n\n# when giving tools to LLM, we must pass as list of tools\ntools = [math_tool]\n\nchat_conversation_agent = initialize_agent(\n    agent=\"chat-conversational-react-description\",\n    tools=tools,\n    llm=llm,\n    verbose=True,\n    max_iterations=3,\n    memory=memory\n)\n\nchat_conversation_agent(\"4.1*7.9=?\")\nchat_conversation_agent(\"2 * 2\")\n\n但是，执行 列表 15.1 时，却报错了：\nTraceback (most recent call last):\n  File \"code/test_chat_coversation_agent.py\", line 38, in &lt;module&gt;\n    chat_conversation_agent(\"4.1*7.9=?\")\n  ...\n1ValueError: variable chat_history should be a list of base messages, got\n\n1\n\nchat_history 变量必须是一个消息列表"
  },
  {
    "objectID": "langchain_agent_chat.html#messagesplaceholder",
    "href": "langchain_agent_chat.html#messagesplaceholder",
    "title": "15  LangChain Chat Agent",
    "section": "15.3 MessagesPlaceholder",
    "text": "15.3 MessagesPlaceholder\n我们说过，Agent 本质上就是 LLM，既然 列表 15.1 执行有异常，那我们就看下他的提示词究竟是怎么实现的（具体实现位于 langchain/agents/conversation_chat/base.py 的 create_prompt()）。\nmessages = [\n    SystemMessagePromptTemplate.from_template(system_message),\n1    MessagesPlaceholder(variable_name=\"chat_history\"),\n    HumanMessagePromptTemplate.from_template(final_prompt),\n    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n]\n\n1\n\n从提示词的构造方式上，chat_history 是通过 MessagesPlaceholder 构造的。而此处的 chat_history 又是通过 ConversationBufferMemory 获取的。\n\n\nmemory = ConversationBufferMemory(memory_key=\"chat_history\")\nConversationBufferMemory 返回的内容逻辑如下所示：\n@property\ndef buffer(self) -&gt; Any:\n    \"\"\"String buffer of memory.\"\"\"\n1    return self.buffer_as_messages if self.return_messages else self.buffer_as_str\n\n1\n\n根据 return_messages 来返回不同格式的记忆。\n\n\n而在 LangChain 中，return_messages 默认值为 False，因此，实际上 buffer() 返回的是字符串格式的内容。这就是导致执行异常的根本原因。\n为了解决这个问题，我们需要在初始化 ConversationBufferMemory 时，配置 return_messages = True。\n\n列表 15.2: Chat Conversation Agent\n#encoding: utf-8\n\n\"\"\"\n@discribe: example for chat conversation agent.\n@author: wangwei1237@gmail.com\n\"\"\"\n\nfrom langchain.chat_models import ErnieBotChat\nfrom langchain.chains import LLMMathChain\nfrom langchain.agents import Tool\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.agents import initialize_agent\n\n1memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n\nllm = ErnieBotChat(model_name=\"ERNIE-Bot-4\")\n\n# initialize the math tool\nllm_math = LLMMathChain(llm=llm)\nmath_tool = Tool(\n    name='Calculator',\n    func=llm_math.run,\n    description='Useful for when you need to answer questions about math.'\n)\n\n# when giving tools to LLM, we must pass as list of tools\ntools = [math_tool]\n\nchat_conversation_agent = initialize_agent(\n    agent=\"chat-conversational-react-description\",\n    tools=tools,\n    llm=llm,\n    verbose=True,\n    max_iterations=3,\n    memory=memory\n)\n\nchat_conversation_agent(\"4.1*7.9=?\")\nchat_conversation_agent(\"2 * 2\")\n\n\n1\n\n通过设置 return_messages 为 True 以返回消息列表格式的记忆内容。\n\n\n\n\n\n\n\n\n警告\n\n\n\n例如本节中提到的 LangChain 相关基建对文心大模型支持不够友好的问题，最好的修复方案还是给 LangChain 提交 PR 来解决。我们给 LangChain 提交了 PR 12921，还在等待官方的审核。如果您有比较好的想法，可以直接给 LangChain 提交 PR。"
  },
  {
    "objectID": "autogen.html#autogen-概述",
    "href": "autogen.html#autogen-概述",
    "title": "19  AutoGen",
    "section": "19.1 AutoGen 概述",
    "text": "19.1 AutoGen 概述\nAutoGen 是由微软、宾夕法尼亚州立大学和华盛顿大学联合推出的 Multi Agent 框架，我们可以使用 AutoGen 管理多个 Agent 来开发 LLM 应用程序。在 AutoGen 框架下，多个不同的 Agent 之间可以通过交互来完成任务。\n我们可以在 github/microsoft/autogen 上获取最新的 AutoGen 版本，我们也可以在这个项目的 讨论区 来进行相关技术的探讨。\nAutoGen 框架中的 Agent 是可定制的、可交互的、可人工干预的，AutoGen 框架下的 Agents 既可以是 LLM 模式，也可以是人工操作或者工具集模式。\n在我看来，AutoGen 的最大魅力来在于其允许不同 Agent 之间的可交互性以及人工干预的能力，这最大程度的促进了人机结合的可能性，为实现最终的超级 AGI 智能体迈出了一大步。\n\n\n\n图 19.1: AutoGen 示意图\n\n\n根据 图 19.1，AutoGen 有以下的几个特点：\n\n构建效率高：AutoGen 简化了开发复杂 LLM 工作流所涉及到的编排、自动化、优化等工作，能够以最小的开发成本构建基于 Multi Agents 对话的下一代 LLM 应用程序。\n可对话性：AutoGen 支持多个 Agents 之间的交互协同，并且不同的 Agents 都可以根据实际需求进行定制，我们可以使用 AutoGen 构建广泛的应用（例如，不同的 Agent 数量，不同的 Agent 拓扑结构……），以完成不同的任务。\n\n除此之外，AutoGen 还提供了增强的 LLM 推理能力、统一的 API、如错误处理、多配置推理、上下文编程等各种能力，以进一步提升开发 LLM 原生应用程序的效率。"
  },
  {
    "objectID": "autogen.html#autogen-生成股价趋势图",
    "href": "autogen.html#autogen-生成股价趋势图",
    "title": "19  AutoGen",
    "section": "19.2 AutoGen 生成股价趋势图",
    "text": "19.2 AutoGen 生成股价趋势图"
  },
  {
    "objectID": "autogen.html#autogen-vs-langchain",
    "href": "autogen.html#autogen-vs-langchain",
    "title": "19  AutoGen",
    "section": "19.3 AutoGen Vs LangChain",
    "text": "19.3 AutoGen Vs LangChain\n像 AutoGen 这样的 Multi Agent 给了我们非常大的想象空间，但是这是否意味着像如 LangChain 这样的 Single Agent 框架——直到现在，LangChain 还没有支持 Multi Agent——会过时呢？\nLangChain 的 CEO & 联合创始人 Harrison Chase 在 Reddit 上开了一个 AMA 讨论区，并在这个讨论区和大家一起讨论和 LangChain 有关的话题。\n在这个讨论区中，有个用户提了一个 LangChain 是否会支持 Multi Agent 的问题：\n\nAs far as I know, the library seems to provide support to single agents and some experimental support to other types of agent runtimes (eg. BabyAGI, AutoGPT). Do you have any plans to include multi-agent support like autogen?\n\n针对这一问题，Harrison Chase 回复道：“LangChain 是否支持 Multi Agent 主要是看 Multi Agent 是否有具体的应用场景和案例。”。\n\nYes we are considering it. The main thing blocking us from investing more is concrete use cases where multi agent frameworks are actually helpful. If you (or anyone) has ideas/suggestions we would love to hear so we can implement them!\n\n从这里可以看出，LangChain 完全是基于实用目的而开发。AutoGen 是个好东西，但是是否有合适的场景必须采用 AutoGen 才能实现呢？目前 AutoGen 给的可以应用的场景，是否用 LangChain 也可以完成呢？\n就像编程语言有面向函数编程和面相对象编程一样，LangChain 和 AutoGen 各自都有各自的战场，很难说谁会完全替代谁。\n\n\n\n图 19.2: 不同 Agents 之间的关系和编程语言元素之间关系的类比\n\n\n从本质上讲，LangChain 是一个构建 Agent 的框架，它提供了创建和部署 Agent 所需的工具和基础设施；而 AutoGen 是一个可以与多个 Agent 进行对话、交互的 Agent。\n我更喜欢 LangChain，除了 Harrison Chase 提到的应用场景的问题之外，对我而言，LangChain 提供了多模型的统一接口，这使得其他模型接入起来非常方便。而 AutoGen 目前仅支持 GPTs 类模型，虽然可以使用 FastChat 接入其他的模型，但是整个的过程还是比较繁琐的。\n当问及 LangChain 的方向时，Harrison Chase 说到：没有人可以确切的直到 LangChain 会走向何方？\n\nthink part of the fun is no one really knows where LangChain will go (or where the space will go) :)\n\n未来，当 Multi Agent 真的非常重要时，LangChain 获取也会引入 Multi Agent。"
  },
  {
    "objectID": "langflow_intro.html",
    "href": "langflow_intro.html",
    "title": "21  Langflow",
    "section": "",
    "text": "Langflow 是 LangChain 的非官方的 UI。使用 Langflow，我们可以更简便的以可视化的方式来体验 LangChain 并为基于 LangChain 的大语言应用提供原型设计能力。\n\n\n\n图 21.1: Langflow 示例\n\n\n想要深入了解 Langflow，可以阅读 Langflow 的官方文档。"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "[1] Balaji, P.G. and Srinivasan, D. 2010. An introduction to\nmulti-agent systems. Innovations in multi-agent systems and\napplications - 1. D. Srinivasan and L.C. Jain, eds. Springer Berlin\nHeidelberg. 1–27.\n\n\n[2] Brown, T. et al. 2020. Language\nmodels are few-shot learners. Advances in neural information\nprocessing systems (2020), 1877–1901.\n\n\n[3] Chang, Y. et al. 2023. A survey on evaluation of large\nlanguage models. arXiv preprint arXiv:2307.03109.\n(2023).\n\n\n[4] Chen, M. et al. 2021. Evaluating large language models\ntrained on code.\n\n\n[5] Introduction to t-SNE: 2023. https://www.datacamp.com/tutorial/introduction-t-sne.\n\n\n[6] Ji,\nZ. et al. 2023. Survey of hallucination in natural language generation.\nACM Computing Surveys. 55, 12 (2023), 1–38.\nDOI:https://doi.org/10.1145/3571730.\n\n\n[7] Karpas, E. et al. 2022. MRKL systems: A modular,\nneuro-symbolic architecture that combines large language models,\nexternal knowledge sources and discrete reasoning. (2022).\n\n\n[8] Kudo, T. 2018. Subword regularization:\nImproving neural network translation models with multiple subword\ncandidates.\n\n\n[9] Li,\nH. et al. 2022. A survey on\nretrieval-augmented text generation. arXiv preprint\narXiv:2202.01110. (2022).\n\n\n[10] Mialon, G. et al. 2023. Augmented language models: A\nsurvey. (2023).\n\n\n[11] Ouyang, L. et al. 2022. Training language models to\nfollow instructions with human feedback.\n\n\n[12] Radford, A. et al. 2018. Improving language\nunderstanding by generative pre-training. (2018).\n\n\n[13] Radford, A. et al. 2019. Language\nmodels are unsupervised multitask learners. (2019).\n\n\n[14] ReAct: Synergizing reasoning and acting in\nlanguage models: 2022. https://react-lm.github.io/.\n\n\n[15] Schuster, M. and Nakajima, K. 2012. Japanese and korean voice\nsearch.\n\n\n[16] Sennrich, R. et al. 2016. Neural machine translation of\nrare words with subword units.\n\n\n[17] Talebirad, Y. and Nadiri, A. 2023. Multi-agent collaboration:\nHarnessing the power of intelligent LLM agents.\n\n\n[18] Vaswani, A. et al. 2023. Attention is all you\nneed.\n\n\n[19] Wang, C. et al. 2019. Neural machine translation with\nbyte-level subwords.\n\n\n[20] Wang, L. et al. 2023. Plan-and-solve prompting:\nImproving zero-shot chain-of-thought reasoning by large language\nmodels.\n\n\n[21] Yang, J. et al. 2023. Harnessing the power of LLMs in\npractice: A survey on ChatGPT and beyond.\n\n\n[22] Yao, S. et al. 2022. ReAct: Synergizing reasoning and\nacting in language models. arXiv preprint arXiv:2210.03629.\n(2022).\n\n\n[23] Zhang, Y. et al. 2023. Siren’s song in the AI ocean: A\nsurvey on hallucination in large language models. arXiv preprint\narXiv:2309.01219. (2023).\n\n\n[24] Zhao, W.X. et al. 2023. A survey of large language\nmodels."
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "附录 A — 术语表",
    "section": "",
    "text": "AGI(Artificial General Intelligence)：通用人工智能\nAuto-Encoder LM：自编码语言模型\nAuto-Decoder LM：自回归语言模型\nEmbedding：向量\nEmergent Ability：涌现\nHallucination：幻觉\nICL(In Context Learning)：上下文学习\nLM(Language Model)：语言模型\nLLM(Large Language Model)：大语言模型\nNSFW(Not Safe for Work)：用于提醒内容不适合公开场合浏览\nPrompt：提示词\nPrompt Engineering：提示词工程\nRAG(Retrieval Augmented Generation)：检索式增强生成\nRATG(Retrieval Augmented Text Generation)：检索增强式文本生成\nSD(Stable Diffusion)：\nSFT(Supervised Fine Tuning): 微调 t-SNE(t-Distributed, Stochastic neighbor Embedding)：T分布和随机近邻嵌入"
  },
  {
    "objectID": "langchain_install.html",
    "href": "langchain_install.html",
    "title": "附录 B — LangChain 安装指南",
    "section": "",
    "text": "版本建议\n\n\n\n使用 LangChain，建议使用 Python 3.10版本。\n因为基于 LangChain 的生态对 Python 版本也会有不同的要求，例如 Langflow 要求 Python 版本在 3.9~3.11。因此，如果想使用 LangChain，最好采用 Python 3.10.10 版本。"
  },
  {
    "objectID": "milvus_install.html#milvus-安装",
    "href": "milvus_install.html#milvus-安装",
    "title": "附录 C — Milvus Beginner",
    "section": "C.1 Milvus 安装",
    "text": "C.1 Milvus 安装\n\nC.1.1 1. 安装 docker-ce\nhttps://docs.docker.com/engine/install/ubuntu/#install-using-the-repository。\n\n\nC.1.2 2. 安装 docker-composer\n$ curl -L \"https://github.com/docker/compose/releases/download/2.22.0/docker-compose-$(uname -s | tr 'A-Z' 'a-z')-$(uname -m)\" -o /usr/local/bin/docker-compose\n\n$ sudo chmod +x /usr/local/bin/docker-compose\n\n$ docker-compose --version\n\n\nC.1.3 3. 安装 docker-milvus 并启动\n$ mkdir milvus && cd milvus \n\n$ wget https://github.com/milvus-io/milvus/releases/download/v2.3.1/milvus-standalone-docker-compose.yml -O docker-compose.yml\n\n$ sudo docker compose up -d\n\n$ sudo docker compose ps"
  },
  {
    "objectID": "milvus_install.html#milvus-测试",
    "href": "milvus_install.html#milvus-测试",
    "title": "附录 C — Milvus Beginner",
    "section": "C.2 Milvus 测试",
    "text": "C.2 Milvus 测试\n\n\n\n\n\n\n警告\n\n\n\n为了避免不同网络环境下的端口限制，可以使用 Nginx 的 TCP Proxy 功能代理 Milvus 默认的 19530 端口和 9091 端口。具体配置参见：列表 C.1。\n\n列表 C.1: Nginx 反向代理配置\nstream {\n    server {\n        listen 8081;\n        proxy_pass 127.0.0.1:19530;\n    }\n\n    server {\n        listen 8082;\n        proxy_pass 127.0.0.1:9091;\n    }\n}\n\n\n\n\nC.2.1 安装 Milvus SDK\npython3 -m pip install pymilvus\n\n\nC.2.2 测试 Milvus\nfrom pymilvus import connections,db\n\nres = connections.connect(\n  host='127.0.0.1',\n  port='8081'\n)\n\n# database = db.create_database(\"test\")\nres = db.list_database()\nprint(res)\n\n# ['default', 'test']\n执行 docker-compose logs -f | grep 'test' 可以看到 Milvus 创建 test 数据库的日志：\n\n列表 C.2: 创建数据库日志\nmilvus-standalone  | [2023/09/26 05:30:03.922 +00:00] [INFO] [proxy/impl.go:174] [\"CreateDatabase received\"] [traceID=91fb5dbbd0a5a8028b7c048552bbbbb9] [role=proxy] [dbName=test]\nmilvus-standalone  | [2023/09/26 05:30:03.922 +00:00] [INFO] [proxy/impl.go:182] [\"CreateDatabase enqueued\"] [traceID=91fb5dbbd0a5a8028b7c048552bbbbb9] [role=proxy] [dbName=test]\nmilvus-standalone  | [2023/09/26 05:30:03.923 +00:00] [INFO] [rootcoord/root_coord.go:772] [\"received request to create database\"] [traceID=91fb5dbbd0a5a8028b7c048552bbbbb9] [role=rootcoord] [dbName=test] [msgID=444519207108608004]\nmilvus-standalone  | [2023/09/26 05:30:03.925 +00:00] [INFO] [rootcoord/meta_table.go:272] [\"create database\"] [traceID=91fb5dbbd0a5a8028b7c048552bbbbb9] [db=test] [ts=444519207108608005]\nmilvus-standalone  | [2023/09/26 05:30:03.925 +00:00] [INFO] [rootcoord/root_coord.go:804] [\"done to create database\"] [traceID=91fb5dbbd0a5a8028b7c048552bbbbb9] [role=rootcoord] [dbName=test] [msgID=444519207108608004] [ts=444519207108608005]\nmilvus-standalone  | [2023/09/26 05:30:03.925 +00:00] [INFO] [proxy/impl.go:190] [\"CreateDatabase done\"] [traceID=91fb5dbbd0a5a8028b7c048552bbbbb9] [role=proxy] [dbName=test]"
  },
  {
    "objectID": "milvus_install.html#milvus-cli",
    "href": "milvus_install.html#milvus-cli",
    "title": "附录 C — Milvus Beginner",
    "section": "C.3 Milvus CLI",
    "text": "C.3 Milvus CLI\n很多时候，使用类似 mysql 这样的客户端工具来连接数据库并进行相关操作会更便捷。Milvus 也提供了类似的客户端端工具 milvus_cli，来方便我们对 Milvus 进行相关操作。\n可以采用如下命令来安装 milvus_cli 客户端：\npip install milvus-cli\n具体的使用如图：图 C.1。\n\n\n\n图 C.1: 使用 milvus_cli 连接 Milvus\n\n\nmilvus_cli 的使用命令参考：Milvus Client Commands。\n\n\n\n\n\n\n警告\n\n\n\n在安装 milvus_cli 的时候，可能会存在依赖库的版本冲突，这可能会导致安装的 milvus_cli 无法正常使用，如图 图 C.2 所示。此时，更新相关依赖的版本，并重新安装 milvus_cli 即可。\n\n\n\n图 C.2: milvus_cli 连接超时"
  }
]